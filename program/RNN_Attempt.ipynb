{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "import time\n",
    "import gc\n",
    "from sys import getsizeof\n",
    "from scipy.signal import hilbert, hann, convolve\n",
    "from scipy.ndimage.filters import convolve1d\n",
    "from scipy import stats\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"../input/train.csv\", dtype={'acoustic_data': np.int16})\n",
    "train = pd.read_pickle('../input/train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = ['signal','ttq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ttq'] = train.ttq.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 629145480 entries, 0 to 629145479\n",
      "Data columns (total 2 columns):\n",
      "signal    int16\n",
      "ttq       float16\n",
      "dtypes: float16(1), int16(1)\n",
      "memory usage: 2.3 GB\n"
     ]
    }
   ],
   "source": [
    "train.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "sig = np.abs(train.signal.values[::100])+1\n",
    "sig=np.log(sig)\n",
    "ax1.plot(sig, 'b-')\n",
    "# Make the y-axis label, ticks and tick labels match the line color.\n",
    "# ax1.set_yscale('log')\n",
    "ax1.tick_params('y', colors='b')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(train.ttq.values[::100], 'r.')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.44260000e+04, 1.68250000e+05, 4.65157000e+05, 1.84412800e+06,\n",
       "        5.15479530e+07, 5.68223199e+08, 5.26606300e+06, 8.70130000e+05,\n",
       "        2.76218000e+05, 1.18204000e+05]),\n",
       " array([-100.,  -80.,  -60.,  -40.,  -20.,    0.,   20.,   40.,   60.,\n",
       "          80.,  100.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train.signal, range=[-100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629145480, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"../input/x_mat.npy\", x_mat)\n",
    "# np.save(\"../input/y_train.npy\", y_train)\n",
    "# np.save(\"../input/y_val.npy\", y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mat = np.load(\"../input/x_mat.npy\")\n",
    "y_train = np.load(\"../input/y_train.npy\")\n",
    "y_val = np.load(\"../input/y_val.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24624, 150000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7387.200112"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getsizeof(x_mat)/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x_mat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def gen():\n",
    "    print('generator initiated')\n",
    "    idx = 0\n",
    "    while True:\n",
    "        yield x_train[:100], y_train[:100]\n",
    "        print('generator yielded a batch %d' % idx)\n",
    "        idx += 1\n",
    "        \n",
    "tr_gen = gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt=y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = x[:10000,:,:]\n",
    "# x_val = x[n_samples:n_samples+n_vals,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=yt[:20000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.74355958, 1.356466  , 0.8       , 0.8       , 0.8       ,\n",
       "       0.8       ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = np.array([[1,2,3,4,5,6,7,8,100,10], [1,4,7,2,5,8,3,6,9,2]])\n",
    "a = np.array([1,2,5,5,5,6,7,5,5,5])\n",
    "rolling_window(a,5).std(axis=1)\n",
    "# print(pd.DataFrame(a).rolling(5).std().dropna().values.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero((np.diff(a) / a[:-1]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero((np.diff(a) / a[:-1]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.33232099,  2.25827497,  1.89006686])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4,5,6,7,8,100,10], [1,4,7,2,5,8,3,6,9,2], [1,4,4,4,4,8,3,6,9,2]])\n",
    "# a = np.array([1,2,3,4,5,6,7,8,100,10])\n",
    "b = rolling_window(a,5).std(axis=2).mean(axis=1)\n",
    "# print(pd.DataFrame(a).rolling(5).std().dropna().values.transpose())\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nonzeros = np.zeros([3])\n",
    "for i in range(3):\n",
    "    nonzeros[i] = np.mean(np.nonzero(np.diff(a[i,:])/a[i,:-1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feat = np.zeros([n, 57], dtype=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.128148794174194\n",
      "72.14348125457764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n",
      "c:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168.20471286773682\n",
      "284.0879793167114\n",
      "294.7218885421753\n",
      "302.05437898635864\n",
      "309.3798713684082\n",
      "364.1346597671509\n",
      "1143.2824532985687\n",
      "1891.4256114959717\n",
      "2814.004231929779\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "(n>0&&n<=size(x)) failed for 1st keyword n: zrfft:n=150000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-e4cb826a72bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m \u001b[0mx_feat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m37\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhilbert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[0mx_feat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m38\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvolve1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhann\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[0mx_feat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m39\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>=\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\scipy\\signal\\signaltools.py\u001b[0m in \u001b[0;36mhilbert\u001b[1;34m(x, N, axis)\u001b[0m\n\u001b[0;32m   1605\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"N must be positive.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1607\u001b[1;33m     \u001b[0mXf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfftpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1608\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1609\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\scipy\\fftpack\\basic.py\u001b[0m in \u001b[0;36mfft\u001b[1;34m(x, n, axis, overwrite_x)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mwork_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moverwrite_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: (n>0&&n<=size(x)) failed for 1st keyword n: zrfft:n=150000"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "x_feat[:,0] = x_mat.mean(axis=1)\n",
    "x_feat[:,1] = x_mat.std(axis=1)\n",
    "x_feat[:,2] = x_mat.max(axis=1)\n",
    "x_feat[:,3] = x_mat.min(axis=1)\n",
    "print(time.time()-start)\n",
    "\n",
    "x_feat[:,4] = np.diff(x_mat, axis=1).mean(axis=1)\n",
    "print(time.time()-start)\n",
    "\n",
    "nonzeros = np.zeros(n, dtype=np.float16)\n",
    "for i in range(n):\n",
    "    nonzeros[i] = np.mean(np.nonzero(np.diff(x_mat[i,:])/x_mat[i,:-1])[0])\n",
    "x_feat[:,5] = nonzeros\n",
    "print(time.time()-start)\n",
    "\n",
    "x_feat[:,6] = np.abs(x_mat).max(axis=1)\n",
    "x_feat[:,7] = np.abs(x_mat).min(axis=1)\n",
    "\n",
    "x_feat[:,8] = x_mat[:,:50000].std(axis=1)\n",
    "x_feat[:,9] = x_mat[:,:-50000].std(axis=1)\n",
    "x_feat[:,10] = x_mat[:,:10000].std(axis=1)\n",
    "x_feat[:,11] = x_mat[:,:-10000].std(axis=1)\n",
    "print(time.time()-start)\n",
    "\n",
    "x_feat[:,9] = x_mat[:,:50000].mean(axis=1)\n",
    "x_feat[:,10] = x_mat[:,:-50000].mean(axis=1)\n",
    "x_feat[:,11] = x_mat[:,:10000].mean(axis=1)\n",
    "x_feat[:,12] = x_mat[:,:-10000].mean(axis=1)\n",
    "print(time.time()-start)\n",
    "\n",
    "x_feat[:,13] = x_mat[:,:50000].min(axis=1)\n",
    "x_feat[:,14] = x_mat[:,:-50000].min(axis=1)\n",
    "x_feat[:,15] = x_mat[:,:10000].min(axis=1)\n",
    "x_feat[:,16] = x_mat[:,:-10000].min(axis=1)\n",
    "print(time.time()-start)\n",
    "\n",
    "x_feat[:,17] = x_mat[:,:50000].max(axis=1)\n",
    "x_feat[:,18] = x_mat[:,:-50000].max(axis=1)\n",
    "x_feat[:,19] = x_mat[:,:10000].max(axis=1)\n",
    "x_feat[:,20] = x_mat[:,:-10000].max(axis=1)\n",
    "print(time.time()-start)\n",
    "\n",
    "x_feat[:,21] = x_mat.max(axis=1)/np.abs(x_mat.min(axis=1))\n",
    "x_feat[:,22] = x_mat.max(axis=1) - np.abs(x_mat.min(axis=1))\n",
    "x_feat[:,23] = np.sum(np.abs(x_mat)>= 500, axis=1)\n",
    "x_feat[:,24] = np.sum(np.abs(x_mat)>= 1000, axis=1)\n",
    "print(time.time()-start)\n",
    "\n",
    "x_feat[:,25] = np.quantile(np.abs(x_mat), 0.95, axis=1)\n",
    "x_feat[:,26] = np.quantile(np.abs(x_mat), 0.05, axis=1)\n",
    "x_feat[:,27] = np.quantile(np.abs(x_mat), 0.99, axis=1)\n",
    "x_feat[:,28] = np.quantile(np.abs(x_mat), 0.01, axis=1)\n",
    "print(time.time()-start)\n",
    "\n",
    "x_feat[:,29] = np.quantile(x_mat, 0.95, axis=1)\n",
    "x_feat[:,30] = np.quantile(x_mat, 0.05, axis=1)\n",
    "x_feat[:,31] = np.quantile(x_mat, 0.99, axis=1)\n",
    "x_feat[:,32] = np.quantile(x_mat, 0.01, axis=1)\n",
    "print(time.time()-start)\n",
    "\n",
    "x_feat[:,33] = np.abs(x_mat).mean(axis=1)\n",
    "x_feat[:,34] = stats.kurtosis(x_mat, axis=1)\n",
    "x_feat[:,35] = stats.skew(x_mat, axis=1)\n",
    "x_feat[:,36] = np.median(x_mat, axis=1)\n",
    "print(time.time()-start)\n",
    "\n",
    "x_feat[:,37] = np.abs(hilbert(x_mat)).mean(axis=1)\n",
    "x_feat[:,38] = convolve1d(x_mat, hann(150), mode=\"constant\").mean(axis=1)\n",
    "x_feat[:,39] = np.sum(np.abs(x_mat)>= 250, axis=1)\n",
    "x_feat[:,40] = np.sum(np.abs(x_mat)>= 100, axis=1)\n",
    "print(time.time()-start)\n",
    "print('Begin Rolling')\n",
    "\n",
    "j=40\n",
    "\n",
    "for version in ['std', 'mean']:\n",
    "    for window in [10,100,1000]:\n",
    "        if version == 'std':\n",
    "            x_roll = x.rolling_window(x_mat, window).std(axis=2)\n",
    "        if version == 'mean':\n",
    "            x_roll = x.rolling_window(x_mat, window).mean(axis=2)\n",
    "\n",
    "        x_feat[:, j+1] = x_roll.mean(axis=1)\n",
    "        x_feat[:, j+2] = x_roll.std(axis=1)\n",
    "        x_feat[:, j+3] = x_roll.max(axis=1)\n",
    "        x_feat[:, j+4] = x_roll.min(axis=1)\n",
    "        j = j+4\n",
    "\n",
    "        x_feat[:, j+1] = np.quantile(x_roll, 0.01, axis=1)\n",
    "        x_feat[:, j+2] = np.quantile(x_roll, 0.99, axis=1)\n",
    "        x_feat[:, j+3] = np.quantile(x_roll, 0.05, axis=1)\n",
    "        x_feat[:, j+4] = np.quantile(x_roll, 0.95, axis=1)\n",
    "        j=j+4\n",
    "        print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import jit, guvectorize\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def nb_sort(x):\n",
    "    return np.sort(x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1mInvalid use of BoundFunction(array.sort for array(int16, 2d, C)) with parameters ()\n * parameterized\u001b[0m\n\u001b[0m\u001b[1m[1] During: resolving callee type: BoundFunction(array.sort for array(int16, 2d, C))\u001b[0m\n\u001b[0m\u001b[1m[2] During: typing of call at <ipython-input-92-a712befc6ff8> (3)\n\u001b[0m\n\u001b[1m\nFile \"<ipython-input-92-a712befc6ff8>\", line 3:\u001b[0m\n\u001b[1mdef nb_sort(x):\n\u001b[1m    return x.sort()\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[0mSpecialize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minvoke\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m         '''\n\u001b[1;32m--> 765\u001b[1;33m         \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m         \u001b[0mcfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgriddim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblockdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msharedmem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m         \u001b[0mcfg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36mspecialize\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    774\u001b[0m         argtypes = tuple(\n\u001b[0;32m    775\u001b[0m             [self.typingctx.resolve_argument_type(a) for a in args])\n\u001b[1;32m--> 776\u001b[1;33m         \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    777\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, sig)\u001b[0m\n\u001b[0;32m    790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargetoptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'link'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             kernel = compile_kernel(self.py_func, argtypes,\n\u001b[1;32m--> 792\u001b[1;33m                                     **self.targetoptions)\n\u001b[0m\u001b[0;32m    793\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefinitions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36mcompile_kernel\u001b[1;34m(pyfunc, args, link, debug, inline, fastmath, extensions, max_registers)\u001b[0m\n\u001b[0;32m     60\u001b[0m def compile_kernel(pyfunc, args, link, debug=False, inline=False,\n\u001b[0;32m     61\u001b[0m                    fastmath=False, extensions=[], max_registers=None):\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mcres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompile_cuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvoid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfndesc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mllvm_func_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     lib, kernel = cres.target_context.prepare_cuda_kernel(cres.library, fname,\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36mcompile_cuda\u001b[1;34m(pyfunc, return_type, args, debug, inline)\u001b[0m\n\u001b[0;32m     49\u001b[0m                                   \u001b[0mreturn_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                                   \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                                   locals={})\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mlibrary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[1;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[0;32m    924\u001b[0m     pipeline = pipeline_class(typingctx, targetctx, library,\n\u001b[0;32m    925\u001b[0m                               args, return_type, flags, locals)\n\u001b[1;32m--> 926\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_extra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlifted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlifted_from\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compile_bytecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompile_ir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc_ir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlifted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlifted_from\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    855\u001b[0m         \"\"\"\n\u001b[0;32m    856\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc_ir\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_compile_ir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36m_compile_core\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefine_pipelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m         \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 844\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;31m# Early pipeline completion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, status)\u001b[0m\n\u001b[0;32m    253\u001b[0m                     \u001b[1;31m# No more fallback pipelines?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_final_pipeline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mpatched_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m                     \u001b[1;31m# Go to next fallback pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, status)\u001b[0m\n\u001b[0;32m    244\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                     \u001b[0mevent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstage_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m                     \u001b[0mstage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0m_EarlyPipelineCompletion\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36mstage_nopython_frontend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    483\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m                 self.locals)\n\u001b[0m\u001b[0;32m    486\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypemap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtypemap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\compiler.py\u001b[0m in \u001b[0;36mtype_inference_stage\u001b[1;34m(typingctx, interp, args, return_type, locals)\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[0minfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_constraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m         \u001b[0minfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m         \u001b[0mtypemap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcalltypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numba\\typeinfer.py\u001b[0m in \u001b[0;36mpropagate\u001b[1;34m(self, raise_errors)\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_errors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1mInvalid use of BoundFunction(array.sort for array(int16, 2d, C)) with parameters ()\n * parameterized\u001b[0m\n\u001b[0m\u001b[1m[1] During: resolving callee type: BoundFunction(array.sort for array(int16, 2d, C))\u001b[0m\n\u001b[0m\u001b[1m[2] During: typing of call at <ipython-input-92-a712befc6ff8> (3)\n\u001b[0m\n\u001b[1m\nFile \"<ipython-input-92-a712befc6ff8>\", line 3:\u001b[0m\n\u001b[1mdef nb_sort(x):\n\u001b[1m    return x.sort()\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb_sort(x_mat[0:10000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.89 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-113, -112, -111, ...,  132,  136,  136],\n",
       "       [ -92,  -86,  -85, ...,  106,  106,  111],\n",
       "       [-181, -175, -162, ...,  211,  214,  215],\n",
       "       ...,\n",
       "       [-185, -185, -180, ...,  179,  188,  193],\n",
       "       [-115, -112, -100, ...,  105,  106,  110],\n",
       "       [ -85,  -82,  -78, ...,  101,  101,  105]], dtype=int16)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "np.sort(x_mat[0:1000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.43 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([11.  , 11.  , 12.  , 12.  , 13.  , 11.  , 10.  ,  9.  , 12.  ,\n",
       "        9.  , 12.  , 10.  , 10.  , 12.  , 10.  , 10.  , 11.  , 11.  ,\n",
       "       12.  , 11.  , 10.  , 10.  , 12.  , 12.  , 12.  , 11.  , 12.  ,\n",
       "       11.  , 10.  , 13.  , 10.  , 11.  , 12.  , 11.  , 12.  ,  9.  ,\n",
       "        9.  , 12.  , 11.  , 10.  , 10.  , 11.  , 12.  , 12.  , 11.  ,\n",
       "       12.  , 10.  , 11.  , 12.  , 10.  , 13.  , 12.  , 12.  , 10.  ,\n",
       "        9.  , 12.  , 11.  , 11.  , 10.  , 10.  , 10.  , 12.  , 11.  ,\n",
       "       11.  , 10.  , 10.  , 10.  , 10.  , 10.  , 15.  , 11.  , 10.  ,\n",
       "       11.  , 10.  , 12.  , 10.  , 12.  , 12.  , 10.  , 12.  , 10.  ,\n",
       "       10.  , 10.  , 10.  , 12.  , 10.  , 11.  , 10.  , 12.  , 11.  ,\n",
       "       12.  , 10.  , 12.  , 11.  ,  9.  , 12.  , 11.  , 10.  ,  9.  ,\n",
       "       11.  , 13.  , 13.  , 12.  , 12.  , 13.  ,  9.  , 12.  , 11.  ,\n",
       "       11.  , 12.  , 12.  , 10.  , 10.  , 13.  , 10.  ,  9.  , 12.  ,\n",
       "        9.  , 10.  , 11.  , 12.  , 10.  , 14.  , 12.  ,  9.  , 10.  ,\n",
       "       10.  , 14.  , 12.  ,  9.  , 10.  , 10.  , 35.  , 12.  , 11.  ,\n",
       "        9.  , 11.  , 10.  , 10.  , 11.  , 10.  , 13.  , 11.  , 12.  ,\n",
       "       11.  , 11.  ,  9.  ,  9.  , 11.  ,  9.  , 10.  , 13.  , 12.  ,\n",
       "       11.  , 12.  , 10.  , 12.  , 11.  , 10.  , 12.  ,  9.  , 10.  ,\n",
       "       12.  , 14.  , 10.  , 12.  , 11.  , 12.  ,  9.  ,  9.  , 11.  ,\n",
       "       12.  , 15.  , 13.  , 10.  , 11.  , 13.  , 12.  , 12.  , 10.  ,\n",
       "       10.  , 11.  ,  9.  , 11.  , 14.  , 11.  , 11.  , 13.  , 11.  ,\n",
       "       10.  , 11.  , 12.  , 12.  ,  9.  , 11.  , 10.  , 10.  , 13.  ,\n",
       "       10.  , 13.  , 11.  , 12.  , 14.  , 10.  , 12.  , 10.  , 12.  ,\n",
       "       11.  , 10.  , 12.  ,  9.  , 10.  , 11.  , 10.  , 12.  , 12.  ,\n",
       "       10.  , 12.  , 40.  , 13.  , 11.  , 10.  , 10.  , 11.  , 13.  ,\n",
       "       10.  , 11.  ,  9.  , 12.  , 11.  , 10.  ,  9.  , 10.  , 17.  ,\n",
       "        9.  , 11.  , 10.  , 10.  , 13.  , 11.  , 10.  , 13.  , 10.  ,\n",
       "       13.  , 10.  , 12.  , 10.  , 12.  , 10.  , 10.  ,  9.  , 11.  ,\n",
       "        9.  , 10.  , 10.  ,  9.  , 10.  , 12.  , 11.  , 11.  , 10.  ,\n",
       "       12.  , 13.  , 14.  , 12.  , 12.  , 11.  ,  9.  , 13.  , 12.  ,\n",
       "       11.  , 12.  , 10.  , 11.  ,  9.  , 13.  , 10.  ,  9.  , 11.  ,\n",
       "       10.  , 10.  , 11.  , 10.  , 11.  , 11.  , 11.  , 10.  , 10.  ,\n",
       "       13.  , 12.  , 10.  , 11.  ,  9.  , 10.  , 11.  , 11.  , 12.  ,\n",
       "       10.  , 10.  , 10.  , 10.  , 12.  , 11.  , 10.  , 11.  , 10.  ,\n",
       "        9.  , 12.  , 10.  , 10.  , 10.  ,  9.  , 12.  , 11.  , 12.  ,\n",
       "       12.  , 10.  , 11.  , 10.  , 13.  , 12.  , 13.  , 11.  , 11.  ,\n",
       "       12.  , 11.  , 10.  , 12.  , 11.  , 12.  , 12.  , 10.  , 11.  ,\n",
       "       10.  , 14.  , 12.  , 10.  ,  9.  , 14.  , 15.  , 12.  , 10.  ,\n",
       "       13.  , 10.  , 10.  ,  9.  , 12.  , 12.  , 12.  , 11.  , 11.  ,\n",
       "       10.  , 11.  , 12.  , 13.  , 12.  , 10.  , 11.  , 10.  , 11.  ,\n",
       "        9.  , 10.  , 12.  , 10.  , 13.  , 12.  , 10.  , 10.  , 12.  ,\n",
       "       11.  , 11.  , 10.  , 11.  ,  9.  , 11.  , 11.  ,  9.  , 12.  ,\n",
       "        9.  , 10.  , 11.  , 12.  , 12.  ,  9.  , 12.  , 10.  ,  9.  ,\n",
       "       14.  , 12.  , 12.  , 10.  , 12.  , 11.  , 11.  , 13.  ,  9.  ,\n",
       "       12.  , 10.  , 13.  , 13.  ,  9.  , 12.  , 10.  , 13.  , 12.  ,\n",
       "        9.  , 12.  , 10.  , 11.  , 13.  , 11.  , 11.  , 14.  , 12.  ,\n",
       "       10.  , 13.  , 16.  ,  9.  , 11.  , 10.  ,  9.  , 10.  , 10.  ,\n",
       "       12.  , 11.  , 12.  , 10.  , 13.  , 10.  , 10.  , 12.  , 12.  ,\n",
       "       13.  , 12.  , 10.  ,  9.  ,  9.  , 11.  , 12.  , 10.  , 11.  ,\n",
       "       10.  , 10.  ,  9.  , 13.  , 11.  , 12.  , 12.  , 10.  , 13.  ,\n",
       "       12.  , 11.  , 10.  , 12.  , 11.  , 13.  , 11.  , 10.  , 12.  ,\n",
       "       10.  , 11.  , 12.  , 13.  , 11.  , 11.  , 11.  , 12.  , 14.  ,\n",
       "       10.  , 13.  , 10.  , 11.  , 12.  , 12.  , 11.  , 12.  , 13.  ,\n",
       "       10.  ,  9.  , 11.  ,  9.  , 13.  , 12.  , 10.  , 11.  , 10.  ,\n",
       "       11.  , 13.  , 11.  , 10.  , 11.  , 10.  ,  9.  , 10.  , 12.  ,\n",
       "       10.  , 10.  , 10.  , 12.  , 10.  , 10.  , 10.  ,  9.  , 13.  ,\n",
       "       11.  , 13.  ,  9.  , 11.  , 11.  , 10.  , 13.  , 12.  , 12.  ,\n",
       "       10.  , 11.  ,  9.  , 10.  , 11.  , 12.  , 11.  , 12.  , 11.  ,\n",
       "       11.  , 10.  , 11.  , 14.  , 10.  , 11.  , 12.  , 11.  , 11.  ,\n",
       "       11.  , 13.  , 11.  , 12.  , 11.  , 13.  , 10.  , 13.  , 11.  ,\n",
       "       11.  , 11.  ,  9.  , 11.  , 11.  , 10.  , 14.  , 11.  , 13.  ,\n",
       "       15.  , 14.  , 10.  , 11.  , 12.  , 11.  , 10.  , 11.  , 12.  ,\n",
       "       10.  , 10.  , 10.  , 12.  , 11.  ,  9.  , 11.  , 10.  , 10.  ,\n",
       "       10.  , 11.  ,  9.  , 10.  , 12.  , 10.  , 12.  , 10.  , 10.  ,\n",
       "       11.  ,  9.  , 11.  , 11.  , 10.  , 13.  , 13.  , 10.  , 11.  ,\n",
       "       11.  , 10.  , 12.  , 10.  , 10.  , 16.  , 13.  , 12.  , 10.  ,\n",
       "       14.  , 11.  , 11.  , 10.  , 12.  , 11.  , 13.  , 11.  , 10.  ,\n",
       "       10.  , 10.  , 11.  ,  9.  , 12.  , 10.  , 12.  , 12.  , 12.  ,\n",
       "       10.  , 14.  , 14.  , 10.  , 11.  , 10.  , 12.  , 12.  , 12.  ,\n",
       "       10.  ,  9.  , 11.  , 14.  , 13.  , 12.  , 10.  , 11.  , 11.  ,\n",
       "       10.  , 13.  , 11.  , 10.  , 13.  , 10.  , 12.  , 12.  , 12.  ,\n",
       "        9.  , 12.  , 11.  , 11.  , 10.  , 11.  ,  9.  , 10.  , 13.  ,\n",
       "       10.  , 10.  , 10.  , 10.  , 10.  , 10.  , 10.  , 12.  , 12.  ,\n",
       "       12.  , 10.  , 10.  , 12.  , 10.  , 11.  , 12.  , 17.  ,  9.  ,\n",
       "       11.  , 13.  , 11.  , 10.  , 11.  ,  9.  , 10.  , 11.  ,  9.  ,\n",
       "       12.  , 11.  ,  9.  , 13.  , 12.  , 11.  , 36.  , 11.  , 10.  ,\n",
       "        9.  ,  9.  , 11.  , 10.  , 10.  , 11.  , 12.  , 10.  , 10.  ,\n",
       "       12.  , 17.  , 13.  , 11.  , 10.  , 12.  , 13.  , 12.  , 12.  ,\n",
       "       10.  , 10.  , 10.  , 10.  , 12.  , 13.  , 11.  , 10.  , 10.  ,\n",
       "       11.  , 11.  , 13.  , 11.  , 11.  ,  9.  , 11.  , 11.  , 10.  ,\n",
       "       12.  , 13.  , 12.  , 12.  , 10.  , 11.  , 13.  ,  9.  , 11.  ,\n",
       "       10.  ,  9.  , 10.  , 12.  , 12.  , 11.  , 12.  , 13.  , 11.  ,\n",
       "       15.  , 11.  , 14.  , 11.  , 13.  , 10.  , 12.  , 10.  , 12.  ,\n",
       "       11.  , 11.  , 13.  , 12.  , 10.  ,  9.  , 10.  , 10.  , 12.  ,\n",
       "       14.  , 10.  ,  9.  , 10.  , 12.  , 11.  , 10.  ,  9.  , 13.  ,\n",
       "       12.  , 11.  ,  9.  , 10.  , 10.  , 10.  , 10.  , 10.  , 10.  ,\n",
       "       11.  , 12.  , 13.  , 10.  , 11.  , 10.  , 10.  , 14.  , 10.  ,\n",
       "       11.  , 13.  , 13.  , 12.  , 13.  , 12.  , 11.  ,  9.  , 14.  ,\n",
       "       10.  , 10.  , 12.  , 14.  , 12.  ,  9.  , 12.  , 11.  , 12.  ,\n",
       "       12.  , 11.  , 10.  , 10.  , 13.  , 12.  , 11.  , 13.  , 12.  ,\n",
       "       13.  , 10.  , 12.  , 12.  , 13.  , 10.  , 10.  , 12.  , 14.  ,\n",
       "       10.  , 11.  , 14.  , 12.  , 12.  ,  9.  , 10.  , 10.  , 10.  ,\n",
       "       12.  , 14.  , 11.  , 11.  , 10.  , 10.  , 10.  , 10.  , 10.  ,\n",
       "       12.  , 10.  , 11.  , 16.  , 10.  , 11.  , 12.  , 12.  , 12.  ,\n",
       "       10.  ,  9.  , 12.  ,  9.  , 13.  , 12.  , 13.  , 10.  , 11.  ,\n",
       "       12.  ,  9.  , 10.  , 12.  , 11.  , 11.  , 10.  , 11.  , 11.  ,\n",
       "       13.  , 10.  , 11.  , 17.  , 12.  , 12.  , 10.  , 11.  , 11.  ,\n",
       "       12.  , 11.  , 11.  , 11.  , 11.  , 10.  , 13.  , 13.  , 12.  ,\n",
       "       10.  , 15.  , 10.  , 11.  , 12.  , 12.  , 11.  , 11.  , 10.  ,\n",
       "       10.  , 10.  , 11.  , 10.  , 13.  , 12.  , 11.  , 10.  , 11.  ,\n",
       "       13.  , 12.  , 11.  , 12.  , 10.  ,  9.  , 10.  , 10.  , 12.  ,\n",
       "       10.  , 12.  , 11.  ,  9.  , 11.  , 12.  , 12.  , 11.  , 11.  ,\n",
       "       11.  , 10.  , 10.  , 11.  , 11.  , 12.  , 12.  ,  9.  , 12.  ,\n",
       "       11.  , 17.  , 11.  , 40.  , 10.  , 10.  , 11.  ,  9.  , 10.  ,\n",
       "       11.  , 10.  , 13.  , 10.  , 12.  , 12.  , 10.  , 11.  , 11.  ,\n",
       "       11.  , 11.  , 10.  , 10.  , 10.  , 12.  , 11.  , 11.  , 10.  ,\n",
       "       12.  , 11.  , 11.  , 10.  , 13.  , 10.05, 10.  , 11.  , 13.  ,\n",
       "       10.  , 12.  , 12.  ,  9.  , 12.  , 11.  , 13.  , 10.  , 11.  ,\n",
       "       11.  , 20.  , 10.  ,  9.  ,  9.  , 12.  , 12.  , 12.  , 11.  ,\n",
       "       12.  , 12.  , 13.  , 12.  , 10.  , 10.  , 11.  ,  9.  , 39.  ,\n",
       "       11.  , 12.  , 11.  ,  9.  , 12.  , 10.  , 12.  , 12.  , 12.  ,\n",
       "       10.  ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "np.quantile(x_mat[:1000,:], 0.95, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7.03305804,  6.74145629,  7.9775095 ,  8.33338103,  7.95542766,\n",
       "        7.01956221,  6.10815285,  5.7882232 ,  6.98702133,  5.54646962,\n",
       "        7.59498721,  6.20991377,  5.96771685,  7.58268163,  5.99605696,\n",
       "        6.17796847,  6.95722954,  7.15438777,  7.57267104,  7.323966  ,\n",
       "        6.29331493,  6.11165434,  8.0514689 ,  7.75072485,  7.85893198,\n",
       "        6.9367802 ,  7.53475357,  6.67851071,  6.48103157,  7.923745  ,\n",
       "        5.98011156,  6.95906275,  7.8512384 ,  6.64754081,  7.21616592,\n",
       "        5.94023248,  5.64202102,  8.81141327,  6.85573738,  6.51716399,\n",
       "        6.33897162,  6.88762388,  7.39329658,  7.57301635,  7.20732206,\n",
       "        7.37848736,  6.03317381,  7.09375817,  7.35677025,  6.29642871,\n",
       "        8.34568266,  7.33719867,  7.95807203,  6.56941082,  5.76332312,\n",
       "        7.65611803,  6.70149815,  6.91830378,  6.72383196,  5.935185  ,\n",
       "        6.13027949,  7.7267737 ,  6.78121743,  6.96881852,  6.28851263,\n",
       "        5.87123762,  6.16340922,  5.93008188,  6.5982806 ,  9.72518655,\n",
       "        6.61212455,  6.54071613,  6.9659855 ,  5.97372647,  7.80694171,\n",
       "        6.03301379,  7.79925411,  7.29223214,  6.40687529,  7.08308072,\n",
       "        6.43278419,  5.93350809,  6.28625927,  6.24530426,  7.63617784,\n",
       "        5.9672198 ,  6.96667139,  5.97837629,  7.33814171,  7.03076373,\n",
       "        7.55373642,  5.89270702,  7.42793478,  7.35362244,  5.75119739,\n",
       "        7.73555733,  6.62955622,  6.46153705,  5.52854835,  6.86822881,\n",
       "        8.22420386,  7.94520361,  7.42903798,  8.10392549,  7.91112354,\n",
       "        5.44637722,  7.46711902,  6.60848737,  6.64183404,  7.66080987,\n",
       "        7.86626294,  5.95395559,  6.13008382,  7.83378744,  6.16888302,\n",
       "        5.78943008,  7.4722257 ,  5.58718743,  6.33596564,  7.7683538 ,\n",
       "        7.47836802,  5.8407569 ,  8.63580689,  7.93896742,  5.81901528,\n",
       "        6.38417816,  6.43360135,  8.71932904,  7.86092701,  5.77901837,\n",
       "        6.04880956,  6.30857306, 41.38382167,  7.3442722 ,  6.82223703,\n",
       "        5.81164684,  6.88313495,  6.1250098 ,  6.61396699,  6.91870006,\n",
       "        5.95889518,  8.17738528,  6.72895876,  7.33697647,  7.03882385,\n",
       "        7.00134796,  5.89264079,  5.5802492 ,  6.99227816,  5.88677927,\n",
       "        6.43663146,  8.7116766 ,  7.74612898,  7.71226814,  7.62596345,\n",
       "        6.2621575 ,  7.41103417,  6.59636228,  6.21181711,  7.27297706,\n",
       "        5.63439188,  5.79539803,  7.58547076,  9.01974014,  6.35086657,\n",
       "        7.6527359 ,  6.97991443,  8.09829132,  5.6060727 ,  5.61240883,\n",
       "        7.00895625,  7.50762267, 10.46121353,  8.48734925,  6.44022766,\n",
       "        6.81025038,  8.1509698 ,  7.8876923 ,  7.8944433 ,  6.59628687,\n",
       "        6.43197116,  7.1010143 ,  5.74099921,  6.61640121,  9.407342  ,\n",
       "        6.98517707,  7.00101805,  8.31260153,  6.85374908,  6.05353212,\n",
       "        7.08803389,  7.94950651,  7.93376108,  5.62547387,  6.97396485,\n",
       "        6.49417658,  6.60066781,  8.23465296,  5.8917794 ,  8.03729019,\n",
       "        6.97290296,  7.5763196 ,  9.0439776 ,  6.61926703,  7.81509817,\n",
       "        6.29118052,  7.60003609,  6.69299739,  6.24235005,  7.37935383,\n",
       "        5.73791251,  6.43113578,  7.09622957,  5.92949343,  7.81365656,\n",
       "        7.7857973 ,  6.46324843,  7.4666312 , 42.2307399 ,  8.27609512,\n",
       "        6.97189254,  6.54313244,  6.21709939,  7.04576616,  7.93671291,\n",
       "        5.97255993,  7.25391296,  5.78076193,  7.90342561,  6.6678098 ,\n",
       "        6.60127315,  5.74739052,  6.20564327, 10.1666686 ,  5.6005263 ,\n",
       "        7.07962705,  6.00448893,  5.9613151 ,  7.93733837,  7.17876846,\n",
       "        6.03615416,  8.07931514,  6.08831502,  8.24467509,  6.08801859,\n",
       "        7.28832741,  6.68831108,  7.52739942,  6.42042591,  5.93945132,\n",
       "        5.74002441,  7.32119605,  5.78366549,  6.50584123,  6.42302036,\n",
       "        5.71344397,  6.34650847,  7.7668954 ,  6.70704501,  7.12283332,\n",
       "        6.66369597,  7.29320542,  8.67743533,  8.81287483,  7.35712604,\n",
       "        7.65099029,  6.90650376,  5.38776438,  8.29579993,  7.23717025,\n",
       "        7.61596039,  7.29797364,  6.16567958,  6.62865592,  5.70564719,\n",
       "        8.38028869,  5.84670958,  5.58334132,  6.82677969,  5.91889179,\n",
       "        6.03830046,  7.37209436,  6.17457448,  7.55921212,  7.0082222 ,\n",
       "        7.15464841,  5.95152676,  6.2103942 ,  8.63577338,  7.36178808,\n",
       "        6.00277885,  6.87431757,  5.83962235,  6.29233153,  6.55254643,\n",
       "        6.89966379,  7.51690835,  6.34271258,  6.24318096,  5.8473274 ,\n",
       "        6.60255508,  8.11118809,  7.38609448,  6.37327364,  6.70757048,\n",
       "        6.31007508,  5.53441574,  7.67829009,  6.25367867,  6.08457541,\n",
       "        6.30704628,  5.92506855,  8.39836073,  6.89094741,  7.34947617,\n",
       "        7.22520259,  6.22633567,  7.23116045,  6.30066069,  9.08279833,\n",
       "        7.49385158,  8.07101262,  7.30945427,  6.78564734,  7.75148831,\n",
       "        7.3039597 ,  6.6505579 ,  7.2808161 ,  6.68985153,  7.55700955,\n",
       "        7.89729776,  6.12547823,  7.08086087,  6.29143768,  8.7701496 ,\n",
       "        7.31521933,  6.4309934 ,  5.70749418, 10.29144544,  9.71511004,\n",
       "        7.56749296,  6.34861069,  8.22255185,  5.87884738,  6.42259732,\n",
       "        5.7498937 ,  7.71322411,  7.39863452,  7.31223692,  6.93180556,\n",
       "        6.58386332,  5.92428215,  6.99289617,  7.51492538,  8.00427811,\n",
       "        8.02698868,  6.62721292,  6.72274812,  6.09220307,  7.00324432,\n",
       "        5.81335725,  6.17969869,  7.53676694,  6.48730112,  8.26456798,\n",
       "        7.7035008 ,  6.52154208,  5.85949716,  7.50501468,  6.792171  ,\n",
       "        6.9867979 ,  6.12260964,  6.56724906,  5.82120906,  7.1500903 ,\n",
       "        7.24220471,  5.72802465,  7.39032717,  5.77834552,  6.11053897,\n",
       "        6.84597441,  7.3480275 ,  7.50718663,  5.65190588,  7.52833619,\n",
       "        6.08512799,  5.60330579,  9.13991945,  7.07273298,  7.9920261 ,\n",
       "        6.30501056,  7.34970804,  6.62993342,  6.70079815,  7.98967936,\n",
       "        5.60906184,  7.60538523,  6.22175035,  8.28609063,  7.87481188,\n",
       "        5.85550646,  7.72951932,  6.08105629,  8.89623624,  7.74599097,\n",
       "        5.61603657,  7.37054161,  6.40324559,  7.0929174 ,  8.02722054,\n",
       "        7.01693052,  6.62426217,  9.01982495,  7.90609901,  6.43307809,\n",
       "        8.00313268, 12.64824996,  5.66181784,  7.18631399,  5.89185513,\n",
       "        5.82211569,  6.47811093,  6.3153116 ,  7.30611733,  7.03914194,\n",
       "        7.72450168,  6.2022778 ,  8.40469353,  6.28299526,  5.97486936,\n",
       "        7.23723289,  7.41759885,  8.08363209,  7.25745304,  6.50049354,\n",
       "        5.65508158,  5.83194036,  7.12687514,  7.3078277 ,  6.52220606,\n",
       "        7.2181335 ,  6.66535771,  6.4799075 ,  5.75723262,  7.97608284,\n",
       "        6.84000358,  7.40126568,  7.7673593 ,  5.94538396,  8.00508829,\n",
       "        7.74221614,  6.48205898,  5.95821429,  7.44613011,  6.53617765,\n",
       "        8.4481455 ,  7.32312755,  6.33292257,  7.10292344,  6.55320537,\n",
       "        6.48476367,  7.45137202,  8.4156825 ,  7.0355522 ,  6.8897717 ,\n",
       "        6.60818798,  7.41092613,  8.32385506,  6.17999733,  8.06636911,\n",
       "        6.44911468,  6.97755242,  7.91870241,  7.48263309,  6.6513063 ,\n",
       "        7.56321902,  7.84191437,  6.25367513,  5.57652075,  6.66711111,\n",
       "        5.40221889,  7.92922911,  7.54458594,  5.89194673,  6.55607266,\n",
       "        6.209496  ,  6.96786796,  7.86769574,  6.66802493,  6.14765377,\n",
       "        7.05876906,  5.997919  ,  5.76266091,  6.33517541,  7.69011066,\n",
       "        6.21372628,  6.41186147,  5.79823232,  7.7683695 ,  6.27086377,\n",
       "        6.35852524,  5.9659775 ,  5.76679078,  8.07957751,  6.93125776,\n",
       "        8.09904188,  5.79755439,  6.85131093,  7.12925014,  6.40726766,\n",
       "        8.38445981,  7.44883125,  7.65849517,  6.67201088,  6.63244437,\n",
       "        5.90788334,  6.44942653,  7.01854229,  7.60031296,  6.97098959,\n",
       "        7.6831671 ,  7.06552458,  6.73286489,  6.23962916,  7.04320902,\n",
       "        8.67491695,  5.92824013,  7.02611982,  7.61895155,  7.36018745,\n",
       "        6.7382295 ,  6.88661284,  7.76660468,  6.8143257 ,  7.85124043,\n",
       "        7.14589616,  8.40724845,  6.11220907,  9.12509849,  6.7682376 ,\n",
       "        6.85356334,  6.60839755,  5.61941959,  7.04774974,  7.13528708,\n",
       "        6.39792299,  8.91104709,  7.05416416,  8.14152185,  9.91330376,\n",
       "        8.86628265,  6.02700457,  6.6967834 ,  7.56580546,  7.11920206,\n",
       "        6.0923924 ,  6.70044215,  7.38113559,  6.41263873,  6.38870587,\n",
       "        5.90008932,  7.29088712,  6.51859592,  5.77820823,  7.20721682,\n",
       "        5.87884629,  6.04146456,  6.51877214,  7.31198536,  5.81862552,\n",
       "        6.32560979,  7.26249579,  6.17845429,  7.51965146,  5.96840228,\n",
       "        5.81999734,  6.55549748,  5.59775711,  7.40860535,  7.38903883,\n",
       "        6.26262241,  8.15885118,  8.52855489,  6.39671903,  7.04717283,\n",
       "        6.65644854,  6.59141052,  7.32980183,  6.26498713,  6.09473053,\n",
       "       10.39484947,  8.38104287,  7.72997969,  6.05723024,  9.58782697,\n",
       "        7.3748275 ,  6.97653191,  5.88213935,  7.92032981,  7.34398344,\n",
       "        8.18729403,  7.11209619,  6.60763923,  6.3543719 ,  6.55882801,\n",
       "        6.69148332,  5.64561999,  8.04578572,  6.05983122,  7.36620062,\n",
       "        7.52470606,  8.00797284,  5.82577462,  8.93022796,  8.99206228,\n",
       "        6.02615607,  7.47190258,  6.5904409 ,  7.96983114,  7.52707309,\n",
       "        7.80546678,  6.23027703,  5.53659216,  6.96248473,  8.98175855,\n",
       "        8.46811108,  7.64110946,  6.37266487,  7.02310147,  7.07828924,\n",
       "        6.05925724,  8.75103581,  6.79863211,  5.8321359 ,  8.26983215,\n",
       "        6.13954181,  7.36128892,  7.52147437,  7.20909093,  5.87205054,\n",
       "        7.47607312,  6.76347409,  6.39055003,  6.20691831,  7.16614393,\n",
       "        5.82442224,  6.60182947,  8.75324799,  6.2856781 ,  6.04331503,\n",
       "        6.55001012,  6.52203779,  6.38378283,  5.99499746,  6.59340184,\n",
       "        7.82628109,  7.39261046,  7.57205631,  6.37405763,  6.42272127,\n",
       "        7.83416914,  6.33047711,  7.01018741,  7.25606739, 12.19722196,\n",
       "        5.92787232,  6.77922967,  8.52423722,  6.65543162,  6.61698321,\n",
       "        6.65567206,  5.89805406,  6.38865689,  6.41823683,  5.7233    ,\n",
       "        7.55127575,  6.86207535,  5.29371556,  8.19157871,  7.69187276,\n",
       "        7.41499646, 44.14528504,  6.70060261,  6.07237672,  5.65360301,\n",
       "        5.67787149,  6.6215397 ,  5.97123457,  6.30844603,  7.21356339,\n",
       "        7.20410349,  6.44797179,  6.09140686,  7.31793353, 14.07681155,\n",
       "        7.91197182,  6.68108851,  6.10444422,  7.69719822,  7.96679744,\n",
       "        7.63830239,  7.65626362,  6.38046654,  6.07380458,  5.9649589 ,\n",
       "        6.75666349,  7.66758163,  8.436071  ,  6.89786618,  5.83285852,\n",
       "        6.29387055,  6.37203255,  7.14043909,  8.11972388,  6.79573122,\n",
       "        6.58402454,  5.8732993 ,  6.74868298,  7.05092653,  6.49620109,\n",
       "        7.63695412,  8.3588842 ,  7.91514809,  7.54272755,  6.41277333,\n",
       "        6.92193052,  8.11739224,  5.86918151,  6.84659607,  6.32869252,\n",
       "        5.8693765 ,  6.25116242,  7.65221408,  7.55443114,  7.02520288,\n",
       "        7.49887556,  8.22410818,  6.91458361, 10.78426156,  6.9932372 ,\n",
       "        8.66603172,  7.12118299,  8.55492578,  5.83230011,  7.6883499 ,\n",
       "        6.27600842,  7.64924548,  6.67271207,  7.07495692,  8.70939377,\n",
       "        7.26562747,  6.01564975,  5.667183  ,  6.23394032,  6.0018892 ,\n",
       "        7.40597871,  8.59294881,  6.04965086,  5.68457972,  6.51509935,\n",
       "        7.5044272 ,  6.83047134,  6.13120237,  5.51939544,  8.16966321,\n",
       "        7.17871981,  7.01888795,  5.82654326,  6.47208863,  5.85786912,\n",
       "        6.02325093,  6.26837148,  6.23676158,  6.11313097,  6.69871339,\n",
       "        7.33239052,  8.34136908,  6.072593  ,  7.25634497,  6.18707215,\n",
       "        6.56651491,  9.18549521,  6.01682122,  7.00843425,  8.27592891,\n",
       "        7.9317031 ,  8.0107902 ,  8.30242024,  7.36060038,  6.62725663,\n",
       "        5.59424814,  9.25665649,  5.99465097,  6.29523747,  7.30982716,\n",
       "        8.58020764,  7.60497534,  5.77518533,  7.62632699,  7.29143938,\n",
       "        7.47816476,  8.14651697,  7.02213981,  6.49270208,  6.58383879,\n",
       "        7.94064684,  7.97322304,  7.10895502,  8.45614238,  7.4375515 ,\n",
       "        8.01571071,  5.98423722,  7.01339699,  7.98391195,  8.55271063,\n",
       "        6.05595792,  6.31770162,  7.1513298 , 10.48486881,  6.09885835,\n",
       "        7.13652004,  9.01147448,  7.73128493,  7.72428131,  5.78020431,\n",
       "        6.43058359,  6.0007532 ,  6.22386828,  7.32934295, 10.57152978,\n",
       "        7.05301977,  7.07138554,  6.23883776,  5.90417128,  6.08722743,\n",
       "        5.83504385,  6.46927331,  7.41067806,  6.18823817,  6.82458286,\n",
       "       10.68207187,  5.95257473,  6.74965539,  7.19212156,  7.6256849 ,\n",
       "        7.1640293 ,  5.90554898,  5.72352361,  7.82177911,  5.6452133 ,\n",
       "        8.80294804,  8.00002798,  7.96184724,  6.11977261,  7.17064709,\n",
       "        7.39759293,  5.82868764,  6.13262426,  7.59050116,  6.83878565,\n",
       "        7.08143069,  6.28077578,  6.62946666,  6.64765491,  8.69697774,\n",
       "        6.17331092,  7.24862036, 12.68924252,  7.37614911,  7.48891488,\n",
       "        6.72641059,  6.54821627,  7.24095219,  7.778596  ,  6.70263389,\n",
       "        6.78079136,  6.71207883,  6.92896101,  6.19399169,  8.06127626,\n",
       "        8.29951478,  7.53575587,  6.27192294,  9.83993903,  6.4401942 ,\n",
       "        6.74147651,  7.31451986,  7.42776289,  6.55355701,  6.58189967,\n",
       "        6.24245106,  6.32655368,  6.222597  ,  6.4935678 ,  6.46442111,\n",
       "        8.31067578,  7.21892701,  6.7183992 ,  6.26125917,  6.79035546,\n",
       "        7.7711138 ,  8.20602442,  6.64171017,  7.40531594,  6.04710049,\n",
       "        5.70059646,  6.60520317,  6.52769069,  7.28936154,  6.37436181,\n",
       "        7.70210832,  6.99956358,  5.54453753,  6.97002518,  7.22919595,\n",
       "        7.71523037,  6.75854151,  6.66790733,  6.76674307,  6.30363782,\n",
       "        6.11776222,  6.84224894,  6.94886295,  7.01362491,  7.4298925 ,\n",
       "        5.53009391,  8.03595113,  6.98402196, 11.75567962,  6.60760537,\n",
       "       37.19120758,  6.22423555,  6.32480974,  7.35741664,  5.68717759,\n",
       "        6.73919219,  6.520725  ,  6.21883994,  8.31372795,  6.42853657,\n",
       "        7.9446059 ,  7.37347981,  6.14373413,  6.69958903,  7.12193997,\n",
       "        7.20639943,  7.02399139,  6.32149133,  6.11421912,  6.35855447,\n",
       "        7.84264672,  7.00727592,  6.93653554,  6.32417434,  7.64653807,\n",
       "        6.82727986,  6.67225227,  6.17093908,  8.1027882 ,  6.43911118,\n",
       "        6.08386282,  7.12974956,  8.69542048,  6.41258101,  7.96481867,\n",
       "        7.64796088,  5.56384033,  8.03818764,  6.69299636,  8.29963677,\n",
       "        6.38362502,  6.65749408,  6.91628008, 18.89832113,  6.29126674,\n",
       "        5.86223097,  5.88338377,  7.65737085,  7.98956592,  7.16914219,\n",
       "        6.65010289,  7.5176666 ,  7.5927586 ,  8.22122143,  8.24439435,\n",
       "        6.14861794,  6.21172436,  7.21493585,  5.59076111, 38.54109071,\n",
       "        6.69985338,  7.75415368,  6.65571806,  5.64685979,  7.78668096,\n",
       "        6.41005997,  8.00224595,  7.59470215,  7.38901405,  6.39932636])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "np.abs(hilbert(x_mat[0:1000,:])).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-155-3ca318cf1d25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_feat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m37\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhilbert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\scipy\\signal\\signaltools.py\u001b[0m in \u001b[0;36mhilbert\u001b[1;34m(x, N, axis)\u001b[0m\n\u001b[0;32m   1605\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"N must be positive.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1607\u001b[1;33m     \u001b[0mXf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfftpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1608\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1609\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\scipy\\fftpack\\basic.py\u001b[0m in \u001b[0;36mfft\u001b[1;34m(x, n, axis, overwrite_x)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \"\"\"\n\u001b[1;32m--> 261\u001b[1;33m     \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asfarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\scipy\\fftpack\\basic.py\u001b[0m in \u001b[0;36m_asfarray\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypecodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"AllFloat\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masfarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\lib\\type_check.py\u001b[0m in \u001b[0;36masfarray\u001b[1;34m(a, dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \"\"\"\n\u001b[1;32m--> 501\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_feat[:,37] = np.abs(hilbert(x_mat)).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3,4,5,6,7], [1,2,3,4,5,9,7]])\n",
    "b = np.array([1,2,3,4,5,6,7])\n",
    "# b.rolling(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.25,  6.  ,  9.  , 12.  , 15.  , 16.  , 12.75])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve(b, hann(7), mode=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24624,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "np.diff(x_mat, axis=1).mean(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24624,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mat.mean(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.800112"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getsizeof(x_train)/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsab\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py:501: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    plt.plot(np.fft.fft(x_mat[i,:])[:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xlog=np.zeros(shape=x_mat.shape)\n",
    "for i in range(x_mat.shape[0]):\n",
    "    xlog[i, :] = np.log(np.abs(np.fft.fft(x_mat[i,:]).real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24624, 150000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = xlog.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=xl.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_log = xl[:,1:20001].reshape([n,1000,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "dev_scaler = StandardScaler()\n",
    "def dev_scale(x): \n",
    "    return dev_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "x = np.zeros([n, 1000, 5], dtype=np.float16)\n",
    "x[:,:,0] = np.mean(x_log,axis=2)\n",
    "x[:,:,1] = np.median(x_log,axis=2)\n",
    "x[:,:,2] = np.max(x_log,axis=2)\n",
    "x[:,:,3] = np.min(x_log,axis=2)\n",
    "x[:,:,4] = np.std(x_log,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.reshape([n,1000,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xi = x[:,:,2]\n",
    "xi=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=xi[:20000,:]\n",
    "y_train = yt[:20000,:]\n",
    "x_val=xi[20000:22000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24624, 1000, 5)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 7.414 ,  7.664 ,  8.664 ,  5.566 ,  0.7964],\n",
       "        [ 6.555 ,  6.617 ,  8.38  ,  3.338 ,  1.226 ],\n",
       "        [ 6.83  ,  7.133 ,  7.938 ,  4.473 ,  0.8853],\n",
       "        ...,\n",
       "        [ 5.86  ,  5.836 ,  7.53  ,  3.46  ,  1.005 ],\n",
       "        [ 6.164 ,  6.44  ,  7.527 ,  4.402 ,  0.9116],\n",
       "        [ 5.93  ,  6.43  ,  7.652 ,  1.895 ,  1.608 ]],\n",
       "\n",
       "       [[ 7.06  ,  6.89  ,  9.02  ,  5.285 ,  1.065 ],\n",
       "        [ 6.586 ,  6.547 ,  8.05  ,  3.133 ,  1.041 ],\n",
       "        [ 6.51  ,  6.83  ,  7.902 ,  3.207 ,  1.288 ],\n",
       "        ...,\n",
       "        [ 6.51  ,  6.566 ,  7.594 ,  4.633 ,  0.805 ],\n",
       "        [ 5.93  ,  6.32  ,  7.598 ,  4.062 ,  1.156 ],\n",
       "        [ 6.035 ,  6.35  ,  7.293 ,  2.578 ,  1.117 ]],\n",
       "\n",
       "       [[ 7.387 ,  7.68  ,  8.36  ,  5.234 ,  0.893 ],\n",
       "        [ 7.13  ,  7.383 ,  8.1   ,  5.24  ,  0.756 ],\n",
       "        [ 6.594 ,  6.594 ,  7.78  ,  5.04  ,  0.729 ],\n",
       "        ...,\n",
       "        [ 6.176 ,  6.51  ,  7.367 ,  4.125 ,  0.851 ],\n",
       "        [ 6.297 ,  6.547 ,  7.418 ,  4.32  ,  0.8345],\n",
       "        [ 6.254 ,  6.72  ,  7.613 ,  3.023 ,  1.229 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 6.625 ,  6.945 ,  8.37  ,  3.145 ,  1.401 ],\n",
       "        [ 6.59  ,  7.055 ,  8.62  ,  2.78  ,  1.344 ],\n",
       "        [ 6.54  ,  6.87  ,  7.836 ,  3.455 ,  1.112 ],\n",
       "        ...,\n",
       "        [ 5.945 ,  6.453 ,  7.46  ,  1.569 ,  1.376 ],\n",
       "        [ 6.168 ,  6.63  ,  7.72  ,  3.607 ,  1.098 ],\n",
       "        [ 6.293 ,  6.43  ,  7.523 ,  3.602 ,  0.845 ]],\n",
       "\n",
       "       [[ 7.03  ,  7.48  ,  9.06  ,  4.383 ,  1.379 ],\n",
       "        [ 6.742 ,  6.637 ,  8.07  ,  4.355 ,  0.992 ],\n",
       "        [ 6.906 ,  6.992 ,  8.164 ,  5.414 ,  0.643 ],\n",
       "        ...,\n",
       "        [ 6.133 ,  6.598 ,  7.793 ,  3.145 ,  1.1455],\n",
       "        [ 5.848 ,  6.367 ,  7.414 , -0.0833,  1.912 ],\n",
       "        [ 6.344 ,  6.47  ,  7.598 ,  4.617 ,  0.7314]],\n",
       "\n",
       "       [[ 7.406 ,  7.297 ,  8.914 ,  5.117 ,  0.9263],\n",
       "        [ 6.79  ,  6.938 ,  8.02  ,  5.5   ,  0.765 ],\n",
       "        [ 6.664 ,  6.992 ,  7.84  ,  2.865 ,  1.175 ],\n",
       "        ...,\n",
       "        [ 6.54  ,  6.65  ,  7.64  ,  4.598 ,  0.833 ],\n",
       "        [ 6.61  ,  6.734 ,  7.746 ,  4.42  ,  0.7627],\n",
       "        [ 5.938 ,  5.992 ,  7.44  ,  3.031 ,  1.048 ]]], dtype=float16)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_63 (InputLayer)        (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 2)                 2002      \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 2,005\n",
      "Trainable params: 2,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 20000 samples, validate on 2000 samples\n",
      "Epoch 1/10000\n",
      "20000/20000 [==============================] - 4s 179us/step - loss: 17.8050 - mean_absolute_error: 3.4140 - mean_squared_error: 17.8050 - val_loss: 16.9013 - val_mean_absolute_error: 3.4324 - val_mean_squared_error: 16.9013\n",
      "Epoch 2/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 14.0238 - mean_absolute_error: 3.0937 - mean_squared_error: 14.0238 - val_loss: 16.9478 - val_mean_absolute_error: 3.4227 - val_mean_squared_error: 16.9478\n",
      "Epoch 3/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.9874 - mean_absolute_error: 3.0885 - mean_squared_error: 13.9874 - val_loss: 16.8476 - val_mean_absolute_error: 3.4242 - val_mean_squared_error: 16.8476\n",
      "Epoch 4/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.9624 - mean_absolute_error: 3.0853 - mean_squared_error: 13.9624 - val_loss: 16.8421 - val_mean_absolute_error: 3.4184 - val_mean_squared_error: 16.8421\n",
      "Epoch 5/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.9354 - mean_absolute_error: 3.0824 - mean_squared_error: 13.9354 - val_loss: 16.7909 - val_mean_absolute_error: 3.4164 - val_mean_squared_error: 16.7909\n",
      "Epoch 6/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.8908 - mean_absolute_error: 3.0780 - mean_squared_error: 13.8908 - val_loss: 16.8611 - val_mean_absolute_error: 3.4067 - val_mean_squared_error: 16.8611\n",
      "Epoch 7/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.8811 - mean_absolute_error: 3.0747 - mean_squared_error: 13.8811 - val_loss: 16.7307 - val_mean_absolute_error: 3.4092 - val_mean_squared_error: 16.7307\n",
      "Epoch 8/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.8555 - mean_absolute_error: 3.0715 - mean_squared_error: 13.8555 - val_loss: 16.7028 - val_mean_absolute_error: 3.4055 - val_mean_squared_error: 16.7028\n",
      "Epoch 9/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.8036 - mean_absolute_error: 3.0672 - mean_squared_error: 13.8036 - val_loss: 16.7088 - val_mean_absolute_error: 3.3994 - val_mean_squared_error: 16.7088\n",
      "Epoch 10/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.7687 - mean_absolute_error: 3.0619 - mean_squared_error: 13.7687 - val_loss: 16.6787 - val_mean_absolute_error: 3.3960 - val_mean_squared_error: 16.6787\n",
      "Epoch 11/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.7462 - mean_absolute_error: 3.0590 - mean_squared_error: 13.7462 - val_loss: 16.6277 - val_mean_absolute_error: 3.3939 - val_mean_squared_error: 16.6277\n",
      "Epoch 12/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.7299 - mean_absolute_error: 3.0585 - mean_squared_error: 13.7299 - val_loss: 16.7335 - val_mean_absolute_error: 3.3844 - val_mean_squared_error: 16.7335\n",
      "Epoch 13/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.7033 - mean_absolute_error: 3.0530 - mean_squared_error: 13.7033 - val_loss: 16.5859 - val_mean_absolute_error: 3.3858 - val_mean_squared_error: 16.5859\n",
      "Epoch 14/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.6547 - mean_absolute_error: 3.0469 - mean_squared_error: 13.6547 - val_loss: 16.4228 - val_mean_absolute_error: 3.3983 - val_mean_squared_error: 16.4228\n",
      "Epoch 15/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.6498 - mean_absolute_error: 3.0489 - mean_squared_error: 13.6498 - val_loss: 16.5905 - val_mean_absolute_error: 3.3759 - val_mean_squared_error: 16.5905\n",
      "Epoch 16/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.6061 - mean_absolute_error: 3.0417 - mean_squared_error: 13.6061 - val_loss: 16.5102 - val_mean_absolute_error: 3.3749 - val_mean_squared_error: 16.5102\n",
      "Epoch 17/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.5830 - mean_absolute_error: 3.0400 - mean_squared_error: 13.5830 - val_loss: 16.4632 - val_mean_absolute_error: 3.3726 - val_mean_squared_error: 16.4632\n",
      "Epoch 18/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.5414 - mean_absolute_error: 3.0349 - mean_squared_error: 13.5414 - val_loss: 16.5051 - val_mean_absolute_error: 3.3659 - val_mean_squared_error: 16.5051\n",
      "Epoch 19/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.5164 - mean_absolute_error: 3.0299 - mean_squared_error: 13.5164 - val_loss: 16.3334 - val_mean_absolute_error: 3.3718 - val_mean_squared_error: 16.3334\n",
      "Epoch 20/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.4860 - mean_absolute_error: 3.0280 - mean_squared_error: 13.4860 - val_loss: 16.4378 - val_mean_absolute_error: 3.3597 - val_mean_squared_error: 16.4378\n",
      "Epoch 21/10000\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 13.4595 - mean_absolute_error: 3.0247 - mean_squared_error: 13.4595 - val_loss: 16.4446 - val_mean_absolute_error: 3.3553 - val_mean_squared_error: 16.4446\n",
      "Epoch 22/10000\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 13.4275 - mean_absolute_error: 3.0178 - mean_squared_error: 13.4275 - val_loss: 16.1715 - val_mean_absolute_error: 3.3758 - val_mean_squared_error: 16.1715\n",
      "Epoch 23/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.3981 - mean_absolute_error: 3.0181 - mean_squared_error: 13.3981 - val_loss: 16.2796 - val_mean_absolute_error: 3.3536 - val_mean_squared_error: 16.2796\n",
      "Epoch 24/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.3708 - mean_absolute_error: 3.0131 - mean_squared_error: 13.3708 - val_loss: 16.2194 - val_mean_absolute_error: 3.3525 - val_mean_squared_error: 16.2194\n",
      "Epoch 25/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.3580 - mean_absolute_error: 3.0123 - mean_squared_error: 13.3580 - val_loss: 16.3193 - val_mean_absolute_error: 3.3428 - val_mean_squared_error: 16.3193\n",
      "Epoch 26/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.3311 - mean_absolute_error: 3.0067 - mean_squared_error: 13.3311 - val_loss: 16.1181 - val_mean_absolute_error: 3.3505 - val_mean_squared_error: 16.1181\n",
      "Epoch 27/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.2872 - mean_absolute_error: 3.0030 - mean_squared_error: 13.2872 - val_loss: 16.1105 - val_mean_absolute_error: 3.3451 - val_mean_squared_error: 16.1105\n",
      "Epoch 28/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.2564 - mean_absolute_error: 2.9989 - mean_squared_error: 13.2564 - val_loss: 16.1753 - val_mean_absolute_error: 3.3356 - val_mean_squared_error: 16.1753\n",
      "Epoch 29/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.2372 - mean_absolute_error: 2.9953 - mean_squared_error: 13.2372 - val_loss: 16.0561 - val_mean_absolute_error: 3.3386 - val_mean_squared_error: 16.0561\n",
      "Epoch 30/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.2070 - mean_absolute_error: 2.9917 - mean_squared_error: 13.2070 - val_loss: 15.9679 - val_mean_absolute_error: 3.3435 - val_mean_squared_error: 15.9679\n",
      "Epoch 31/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.1919 - mean_absolute_error: 2.9907 - mean_squared_error: 13.1919 - val_loss: 16.0203 - val_mean_absolute_error: 3.3306 - val_mean_squared_error: 16.0203\n",
      "Epoch 32/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.1649 - mean_absolute_error: 2.9865 - mean_squared_error: 13.1649 - val_loss: 15.9441 - val_mean_absolute_error: 3.3324 - val_mean_squared_error: 15.9441\n",
      "Epoch 33/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.1583 - mean_absolute_error: 2.9865 - mean_squared_error: 13.1583 - val_loss: 15.9271 - val_mean_absolute_error: 3.3280 - val_mean_squared_error: 15.9271\n",
      "Epoch 34/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.1099 - mean_absolute_error: 2.9809 - mean_squared_error: 13.1099 - val_loss: 16.0204 - val_mean_absolute_error: 3.3165 - val_mean_squared_error: 16.0204\n",
      "Epoch 35/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.0798 - mean_absolute_error: 2.9755 - mean_squared_error: 13.0798 - val_loss: 15.9466 - val_mean_absolute_error: 3.3156 - val_mean_squared_error: 15.9466\n",
      "Epoch 36/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.0556 - mean_absolute_error: 2.9741 - mean_squared_error: 13.0556 - val_loss: 16.0636 - val_mean_absolute_error: 3.3075 - val_mean_squared_error: 16.0636\n",
      "Epoch 37/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 13.0268 - mean_absolute_error: 2.9683 - mean_squared_error: 13.0268 - val_loss: 15.8780 - val_mean_absolute_error: 3.3105 - val_mean_squared_error: 15.8780\n",
      "Epoch 38/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.9973 - mean_absolute_error: 2.9652 - mean_squared_error: 12.9973 - val_loss: 15.8062 - val_mean_absolute_error: 3.3113 - val_mean_squared_error: 15.8062\n",
      "Epoch 39/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.9792 - mean_absolute_error: 2.9635 - mean_squared_error: 12.9792 - val_loss: 15.9027 - val_mean_absolute_error: 3.3007 - val_mean_squared_error: 15.9027\n",
      "Epoch 40/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.9511 - mean_absolute_error: 2.9589 - mean_squared_error: 12.9511 - val_loss: 15.7942 - val_mean_absolute_error: 3.3017 - val_mean_squared_error: 15.7942\n",
      "Epoch 41/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.9220 - mean_absolute_error: 2.9556 - mean_squared_error: 12.9220 - val_loss: 15.7202 - val_mean_absolute_error: 3.3030 - val_mean_squared_error: 15.7202\n",
      "Epoch 42/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.9171 - mean_absolute_error: 2.9543 - mean_squared_error: 12.9171 - val_loss: 15.6342 - val_mean_absolute_error: 3.3092 - val_mean_squared_error: 15.6342\n",
      "Epoch 43/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.9038 - mean_absolute_error: 2.9523 - mean_squared_error: 12.9038 - val_loss: 15.6080 - val_mean_absolute_error: 3.3063 - val_mean_squared_error: 15.6080\n",
      "Epoch 44/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.8631 - mean_absolute_error: 2.9476 - mean_squared_error: 12.8631 - val_loss: 15.5834 - val_mean_absolute_error: 3.3031 - val_mean_squared_error: 15.5834\n",
      "Epoch 45/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.8390 - mean_absolute_error: 2.9454 - mean_squared_error: 12.8390 - val_loss: 15.5823 - val_mean_absolute_error: 3.2956 - val_mean_squared_error: 15.5823\n",
      "Epoch 46/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.8052 - mean_absolute_error: 2.9416 - mean_squared_error: 12.8052 - val_loss: 15.7165 - val_mean_absolute_error: 3.2801 - val_mean_squared_error: 15.7165\n",
      "Epoch 47/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.7793 - mean_absolute_error: 2.9369 - mean_squared_error: 12.7793 - val_loss: 15.6703 - val_mean_absolute_error: 3.2779 - val_mean_squared_error: 15.6703\n",
      "Epoch 48/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.7585 - mean_absolute_error: 2.9339 - mean_squared_error: 12.7585 - val_loss: 15.5998 - val_mean_absolute_error: 3.2772 - val_mean_squared_error: 15.5998\n",
      "Epoch 49/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.7314 - mean_absolute_error: 2.9305 - mean_squared_error: 12.7314 - val_loss: 15.4852 - val_mean_absolute_error: 3.2833 - val_mean_squared_error: 15.4852\n",
      "Epoch 50/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.7043 - mean_absolute_error: 2.9274 - mean_squared_error: 12.7043 - val_loss: 15.5049 - val_mean_absolute_error: 3.2750 - val_mean_squared_error: 15.5049\n",
      "Epoch 51/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.6915 - mean_absolute_error: 2.9262 - mean_squared_error: 12.6915 - val_loss: 15.4664 - val_mean_absolute_error: 3.2736 - val_mean_squared_error: 15.4664\n",
      "Epoch 52/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.6584 - mean_absolute_error: 2.9210 - mean_squared_error: 12.6584 - val_loss: 15.4220 - val_mean_absolute_error: 3.2731 - val_mean_squared_error: 15.4220\n",
      "Epoch 53/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.6356 - mean_absolute_error: 2.9183 - mean_squared_error: 12.6356 - val_loss: 15.4221 - val_mean_absolute_error: 3.2673 - val_mean_squared_error: 15.4221\n",
      "Epoch 54/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.6154 - mean_absolute_error: 2.9159 - mean_squared_error: 12.6154 - val_loss: 15.3984 - val_mean_absolute_error: 3.2644 - val_mean_squared_error: 15.3984\n",
      "Epoch 55/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.5898 - mean_absolute_error: 2.9134 - mean_squared_error: 12.5898 - val_loss: 15.4257 - val_mean_absolute_error: 3.2573 - val_mean_squared_error: 15.4257\n",
      "Epoch 56/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.5657 - mean_absolute_error: 2.9096 - mean_squared_error: 12.5657 - val_loss: 15.4744 - val_mean_absolute_error: 3.2511 - val_mean_squared_error: 15.4744\n",
      "Epoch 57/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.5444 - mean_absolute_error: 2.9061 - mean_squared_error: 12.5444 - val_loss: 15.4004 - val_mean_absolute_error: 3.2504 - val_mean_squared_error: 15.4004\n",
      "Epoch 58/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.5281 - mean_absolute_error: 2.9034 - mean_squared_error: 12.5281 - val_loss: 15.2884 - val_mean_absolute_error: 3.2547 - val_mean_squared_error: 15.2884\n",
      "Epoch 59/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.5083 - mean_absolute_error: 2.9012 - mean_squared_error: 12.5083 - val_loss: 15.2580 - val_mean_absolute_error: 3.2528 - val_mean_squared_error: 15.2580\n",
      "Epoch 60/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.4870 - mean_absolute_error: 2.8993 - mean_squared_error: 12.4870 - val_loss: 15.4390 - val_mean_absolute_error: 3.2381 - val_mean_squared_error: 15.4390\n",
      "Epoch 61/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.4677 - mean_absolute_error: 2.8933 - mean_squared_error: 12.4677 - val_loss: 15.3121 - val_mean_absolute_error: 3.2389 - val_mean_squared_error: 15.3121\n",
      "Epoch 62/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.4429 - mean_absolute_error: 2.8922 - mean_squared_error: 12.4429 - val_loss: 15.2514 - val_mean_absolute_error: 3.2383 - val_mean_squared_error: 15.2514\n",
      "Epoch 63/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.4317 - mean_absolute_error: 2.8908 - mean_squared_error: 12.4317 - val_loss: 15.2765 - val_mean_absolute_error: 3.2329 - val_mean_squared_error: 15.2765\n",
      "Epoch 64/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.3893 - mean_absolute_error: 2.8843 - mean_squared_error: 12.3893 - val_loss: 15.1221 - val_mean_absolute_error: 3.2420 - val_mean_squared_error: 15.1221\n",
      "Epoch 65/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.3792 - mean_absolute_error: 2.8838 - mean_squared_error: 12.3792 - val_loss: 15.1375 - val_mean_absolute_error: 3.2342 - val_mean_squared_error: 15.1375\n",
      "Epoch 66/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.3450 - mean_absolute_error: 2.8796 - mean_squared_error: 12.3450 - val_loss: 15.1311 - val_mean_absolute_error: 3.2298 - val_mean_squared_error: 15.1311\n",
      "Epoch 67/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.3410 - mean_absolute_error: 2.8788 - mean_squared_error: 12.3410 - val_loss: 15.1643 - val_mean_absolute_error: 3.2231 - val_mean_squared_error: 15.1643\n",
      "Epoch 68/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.3044 - mean_absolute_error: 2.8733 - mean_squared_error: 12.3044 - val_loss: 15.1410 - val_mean_absolute_error: 3.2204 - val_mean_squared_error: 15.1410\n",
      "Epoch 69/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.2800 - mean_absolute_error: 2.8708 - mean_squared_error: 12.2800 - val_loss: 15.1407 - val_mean_absolute_error: 3.2166 - val_mean_squared_error: 15.1407\n",
      "Epoch 70/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.2535 - mean_absolute_error: 2.8654 - mean_squared_error: 12.2535 - val_loss: 14.9572 - val_mean_absolute_error: 3.2314 - val_mean_squared_error: 14.9572\n",
      "Epoch 71/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.2495 - mean_absolute_error: 2.8666 - mean_squared_error: 12.2495 - val_loss: 15.0322 - val_mean_absolute_error: 3.2153 - val_mean_squared_error: 15.0322\n",
      "Epoch 72/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.2202 - mean_absolute_error: 2.8621 - mean_squared_error: 12.2202 - val_loss: 14.9838 - val_mean_absolute_error: 3.2152 - val_mean_squared_error: 14.9838\n",
      "Epoch 73/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.2013 - mean_absolute_error: 2.8597 - mean_squared_error: 12.2013 - val_loss: 14.9232 - val_mean_absolute_error: 3.2174 - val_mean_squared_error: 14.9232\n",
      "Epoch 74/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.1808 - mean_absolute_error: 2.8568 - mean_squared_error: 12.1808 - val_loss: 14.9188 - val_mean_absolute_error: 3.2124 - val_mean_squared_error: 14.9188\n",
      "Epoch 75/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.1607 - mean_absolute_error: 2.8546 - mean_squared_error: 12.1607 - val_loss: 14.9543 - val_mean_absolute_error: 3.2042 - val_mean_squared_error: 14.9543\n",
      "Epoch 76/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.1454 - mean_absolute_error: 2.8524 - mean_squared_error: 12.1454 - val_loss: 15.0556 - val_mean_absolute_error: 3.1956 - val_mean_squared_error: 15.0556\n",
      "Epoch 77/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.1220 - mean_absolute_error: 2.8484 - mean_squared_error: 12.1220 - val_loss: 14.9087 - val_mean_absolute_error: 3.1992 - val_mean_squared_error: 14.9087\n",
      "Epoch 78/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.0960 - mean_absolute_error: 2.8449 - mean_squared_error: 12.0960 - val_loss: 14.8098 - val_mean_absolute_error: 3.2052 - val_mean_squared_error: 14.8098\n",
      "Epoch 79/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.0761 - mean_absolute_error: 2.8429 - mean_squared_error: 12.0761 - val_loss: 14.8730 - val_mean_absolute_error: 3.1935 - val_mean_squared_error: 14.8730\n",
      "Epoch 80/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.0588 - mean_absolute_error: 2.8394 - mean_squared_error: 12.0588 - val_loss: 14.8077 - val_mean_absolute_error: 3.1948 - val_mean_squared_error: 14.8077\n",
      "Epoch 81/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.0373 - mean_absolute_error: 2.8377 - mean_squared_error: 12.0373 - val_loss: 14.8681 - val_mean_absolute_error: 3.1861 - val_mean_squared_error: 14.8681\n",
      "Epoch 82/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 12.0291 - mean_absolute_error: 2.8356 - mean_squared_error: 12.0291 - val_loss: 14.8227 - val_mean_absolute_error: 3.1851 - val_mean_squared_error: 14.8227\n",
      "Epoch 83/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.9992 - mean_absolute_error: 2.8314 - mean_squared_error: 11.9992 - val_loss: 14.7638 - val_mean_absolute_error: 3.1854 - val_mean_squared_error: 14.7638\n",
      "Epoch 84/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.9814 - mean_absolute_error: 2.8292 - mean_squared_error: 11.9814 - val_loss: 14.7209 - val_mean_absolute_error: 3.1851 - val_mean_squared_error: 14.7209\n",
      "Epoch 85/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.9576 - mean_absolute_error: 2.8267 - mean_squared_error: 11.9576 - val_loss: 14.7690 - val_mean_absolute_error: 3.1770 - val_mean_squared_error: 14.7690\n",
      "Epoch 86/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.9419 - mean_absolute_error: 2.8240 - mean_squared_error: 11.9419 - val_loss: 14.7799 - val_mean_absolute_error: 3.1728 - val_mean_squared_error: 14.7799\n",
      "Epoch 87/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.9355 - mean_absolute_error: 2.8223 - mean_squared_error: 11.9355 - val_loss: 14.7296 - val_mean_absolute_error: 3.1719 - val_mean_squared_error: 14.7296\n",
      "Epoch 88/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.9158 - mean_absolute_error: 2.8190 - mean_squared_error: 11.9158 - val_loss: 14.7060 - val_mean_absolute_error: 3.1696 - val_mean_squared_error: 14.7060\n",
      "Epoch 89/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.8919 - mean_absolute_error: 2.8160 - mean_squared_error: 11.8919 - val_loss: 14.6935 - val_mean_absolute_error: 3.1667 - val_mean_squared_error: 14.6935\n",
      "Epoch 90/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.8629 - mean_absolute_error: 2.8124 - mean_squared_error: 11.8629 - val_loss: 14.6621 - val_mean_absolute_error: 3.1649 - val_mean_squared_error: 14.6621\n",
      "Epoch 91/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.8427 - mean_absolute_error: 2.8096 - mean_squared_error: 11.8427 - val_loss: 14.5897 - val_mean_absolute_error: 3.1666 - val_mean_squared_error: 14.5897\n",
      "Epoch 92/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.8274 - mean_absolute_error: 2.8077 - mean_squared_error: 11.8274 - val_loss: 14.6160 - val_mean_absolute_error: 3.1605 - val_mean_squared_error: 14.6160\n",
      "Epoch 93/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.8107 - mean_absolute_error: 2.8050 - mean_squared_error: 11.8107 - val_loss: 14.5569 - val_mean_absolute_error: 3.1611 - val_mean_squared_error: 14.5569\n",
      "Epoch 94/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.7988 - mean_absolute_error: 2.8035 - mean_squared_error: 11.7988 - val_loss: 14.5677 - val_mean_absolute_error: 3.1562 - val_mean_squared_error: 14.5677\n",
      "Epoch 95/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.7739 - mean_absolute_error: 2.8000 - mean_squared_error: 11.7739 - val_loss: 14.5546 - val_mean_absolute_error: 3.1534 - val_mean_squared_error: 14.5546\n",
      "Epoch 96/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.7578 - mean_absolute_error: 2.7969 - mean_squared_error: 11.7578 - val_loss: 14.4571 - val_mean_absolute_error: 3.1586 - val_mean_squared_error: 14.4571\n",
      "Epoch 97/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.7320 - mean_absolute_error: 2.7951 - mean_squared_error: 11.7320 - val_loss: 14.5964 - val_mean_absolute_error: 3.1444 - val_mean_squared_error: 14.5964\n",
      "Epoch 98/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.7203 - mean_absolute_error: 2.7928 - mean_squared_error: 11.7203 - val_loss: 14.6068 - val_mean_absolute_error: 3.1409 - val_mean_squared_error: 14.6068\n",
      "Epoch 99/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.7266 - mean_absolute_error: 2.7911 - mean_squared_error: 11.7266 - val_loss: 14.3739 - val_mean_absolute_error: 3.1558 - val_mean_squared_error: 14.3739\n",
      "Epoch 100/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.6912 - mean_absolute_error: 2.7886 - mean_squared_error: 11.6912 - val_loss: 14.4421 - val_mean_absolute_error: 3.1427 - val_mean_squared_error: 14.4421\n",
      "Epoch 101/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.6673 - mean_absolute_error: 2.7843 - mean_squared_error: 11.6673 - val_loss: 14.4192 - val_mean_absolute_error: 3.1407 - val_mean_squared_error: 14.4192\n",
      "Epoch 102/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.6494 - mean_absolute_error: 2.7829 - mean_squared_error: 11.6494 - val_loss: 14.5214 - val_mean_absolute_error: 3.1317 - val_mean_squared_error: 14.5214\n",
      "Epoch 103/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.6411 - mean_absolute_error: 2.7797 - mean_squared_error: 11.6411 - val_loss: 14.4795 - val_mean_absolute_error: 3.1302 - val_mean_squared_error: 14.4795\n",
      "Epoch 104/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.6299 - mean_absolute_error: 2.7787 - mean_squared_error: 11.6299 - val_loss: 14.4306 - val_mean_absolute_error: 3.1293 - val_mean_squared_error: 14.4306\n",
      "Epoch 105/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.6001 - mean_absolute_error: 2.7745 - mean_squared_error: 11.6001 - val_loss: 14.3230 - val_mean_absolute_error: 3.1333 - val_mean_squared_error: 14.3230\n",
      "Epoch 106/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.5933 - mean_absolute_error: 2.7737 - mean_squared_error: 11.5933 - val_loss: 14.2871 - val_mean_absolute_error: 3.1329 - val_mean_squared_error: 14.2871\n",
      "Epoch 107/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.5649 - mean_absolute_error: 2.7702 - mean_squared_error: 11.5649 - val_loss: 14.2710 - val_mean_absolute_error: 3.1304 - val_mean_squared_error: 14.2710\n",
      "Epoch 108/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.5449 - mean_absolute_error: 2.7671 - mean_squared_error: 11.5449 - val_loss: 14.2201 - val_mean_absolute_error: 3.1325 - val_mean_squared_error: 14.2201\n",
      "Epoch 109/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.5392 - mean_absolute_error: 2.7675 - mean_squared_error: 11.5392 - val_loss: 14.3651 - val_mean_absolute_error: 3.1164 - val_mean_squared_error: 14.3651\n",
      "Epoch 110/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.5123 - mean_absolute_error: 2.7611 - mean_squared_error: 11.5123 - val_loss: 14.1601 - val_mean_absolute_error: 3.1323 - val_mean_squared_error: 14.1601\n",
      "Epoch 111/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.5024 - mean_absolute_error: 2.7610 - mean_squared_error: 11.5024 - val_loss: 14.1451 - val_mean_absolute_error: 3.1294 - val_mean_squared_error: 14.1451\n",
      "Epoch 112/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.4828 - mean_absolute_error: 2.7582 - mean_squared_error: 11.4828 - val_loss: 14.1614 - val_mean_absolute_error: 3.1215 - val_mean_squared_error: 14.1614\n",
      "Epoch 113/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.4749 - mean_absolute_error: 2.7574 - mean_squared_error: 11.4749 - val_loss: 14.2241 - val_mean_absolute_error: 3.1112 - val_mean_squared_error: 14.2241\n",
      "Epoch 114/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.4540 - mean_absolute_error: 2.7534 - mean_squared_error: 11.4540 - val_loss: 14.2282 - val_mean_absolute_error: 3.1076 - val_mean_squared_error: 14.2282\n",
      "Epoch 115/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.4573 - mean_absolute_error: 2.7532 - mean_squared_error: 11.4573 - val_loss: 14.1703 - val_mean_absolute_error: 3.1082 - val_mean_squared_error: 14.1703\n",
      "Epoch 116/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.4136 - mean_absolute_error: 2.7470 - mean_squared_error: 11.4136 - val_loss: 14.0344 - val_mean_absolute_error: 3.1238 - val_mean_squared_error: 14.0344\n",
      "Epoch 117/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.4098 - mean_absolute_error: 2.7476 - mean_squared_error: 11.4098 - val_loss: 14.0590 - val_mean_absolute_error: 3.1126 - val_mean_squared_error: 14.0590\n",
      "Epoch 118/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.3850 - mean_absolute_error: 2.7445 - mean_squared_error: 11.3850 - val_loss: 14.0740 - val_mean_absolute_error: 3.1060 - val_mean_squared_error: 14.0740\n",
      "Epoch 119/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.3732 - mean_absolute_error: 2.7424 - mean_squared_error: 11.3732 - val_loss: 14.0608 - val_mean_absolute_error: 3.1034 - val_mean_squared_error: 14.0608\n",
      "Epoch 120/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.3581 - mean_absolute_error: 2.7392 - mean_squared_error: 11.3581 - val_loss: 13.9942 - val_mean_absolute_error: 3.1081 - val_mean_squared_error: 13.9942\n",
      "Epoch 121/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.3478 - mean_absolute_error: 2.7389 - mean_squared_error: 11.3478 - val_loss: 14.0526 - val_mean_absolute_error: 3.0964 - val_mean_squared_error: 14.0526\n",
      "Epoch 122/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.3157 - mean_absolute_error: 2.7337 - mean_squared_error: 11.3157 - val_loss: 14.0065 - val_mean_absolute_error: 3.0972 - val_mean_squared_error: 14.0065\n",
      "Epoch 123/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.3033 - mean_absolute_error: 2.7329 - mean_squared_error: 11.3033 - val_loss: 14.1130 - val_mean_absolute_error: 3.0854 - val_mean_squared_error: 14.1130\n",
      "Epoch 124/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.2919 - mean_absolute_error: 2.7295 - mean_squared_error: 11.2919 - val_loss: 13.9852 - val_mean_absolute_error: 3.0916 - val_mean_squared_error: 13.9852\n",
      "Epoch 125/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.2702 - mean_absolute_error: 2.7272 - mean_squared_error: 11.2702 - val_loss: 13.9260 - val_mean_absolute_error: 3.0947 - val_mean_squared_error: 13.9260\n",
      "Epoch 126/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.2609 - mean_absolute_error: 2.7266 - mean_squared_error: 11.2609 - val_loss: 14.0256 - val_mean_absolute_error: 3.0811 - val_mean_squared_error: 14.0256\n",
      "Epoch 127/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.2406 - mean_absolute_error: 2.7228 - mean_squared_error: 11.2406 - val_loss: 14.0207 - val_mean_absolute_error: 3.0782 - val_mean_squared_error: 14.0207\n",
      "Epoch 128/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.2328 - mean_absolute_error: 2.7215 - mean_squared_error: 11.2328 - val_loss: 13.9985 - val_mean_absolute_error: 3.0765 - val_mean_squared_error: 13.9985\n",
      "Epoch 129/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.2077 - mean_absolute_error: 2.7173 - mean_squared_error: 11.2077 - val_loss: 13.9735 - val_mean_absolute_error: 3.0749 - val_mean_squared_error: 13.9735\n",
      "Epoch 130/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.2067 - mean_absolute_error: 2.7166 - mean_squared_error: 11.2067 - val_loss: 13.9314 - val_mean_absolute_error: 3.0747 - val_mean_squared_error: 13.9314\n",
      "Epoch 131/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.1810 - mean_absolute_error: 2.7133 - mean_squared_error: 11.1810 - val_loss: 13.8441 - val_mean_absolute_error: 3.0797 - val_mean_squared_error: 13.8441\n",
      "Epoch 132/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.1620 - mean_absolute_error: 2.7107 - mean_squared_error: 11.1620 - val_loss: 13.8109 - val_mean_absolute_error: 3.0801 - val_mean_squared_error: 13.8109\n",
      "Epoch 133/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.1616 - mean_absolute_error: 2.7114 - mean_squared_error: 11.1616 - val_loss: 13.8290 - val_mean_absolute_error: 3.0735 - val_mean_squared_error: 13.8290\n",
      "Epoch 134/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.1363 - mean_absolute_error: 2.7071 - mean_squared_error: 11.1363 - val_loss: 13.8376 - val_mean_absolute_error: 3.0688 - val_mean_squared_error: 13.8376\n",
      "Epoch 135/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.1288 - mean_absolute_error: 2.7060 - mean_squared_error: 11.1288 - val_loss: 13.7912 - val_mean_absolute_error: 3.0700 - val_mean_squared_error: 13.7912\n",
      "Epoch 136/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.1126 - mean_absolute_error: 2.7043 - mean_squared_error: 11.1126 - val_loss: 13.8731 - val_mean_absolute_error: 3.0595 - val_mean_squared_error: 13.8731\n",
      "Epoch 137/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.1039 - mean_absolute_error: 2.7022 - mean_squared_error: 11.1039 - val_loss: 13.9056 - val_mean_absolute_error: 3.0550 - val_mean_squared_error: 13.9056\n",
      "Epoch 138/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.0887 - mean_absolute_error: 2.6974 - mean_squared_error: 11.0887 - val_loss: 13.6731 - val_mean_absolute_error: 3.0772 - val_mean_squared_error: 13.6731\n",
      "Epoch 139/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.0642 - mean_absolute_error: 2.6974 - mean_squared_error: 11.0642 - val_loss: 13.7573 - val_mean_absolute_error: 3.0587 - val_mean_squared_error: 13.7573\n",
      "Epoch 140/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.0556 - mean_absolute_error: 2.6940 - mean_squared_error: 11.0556 - val_loss: 13.7074 - val_mean_absolute_error: 3.0606 - val_mean_squared_error: 13.7074\n",
      "Epoch 141/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.0476 - mean_absolute_error: 2.6930 - mean_squared_error: 11.0476 - val_loss: 13.6508 - val_mean_absolute_error: 3.0652 - val_mean_squared_error: 13.6508\n",
      "Epoch 142/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.0213 - mean_absolute_error: 2.6904 - mean_squared_error: 11.0213 - val_loss: 13.6893 - val_mean_absolute_error: 3.0550 - val_mean_squared_error: 13.6893\n",
      "Epoch 143/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 11.0263 - mean_absolute_error: 2.6906 - mean_squared_error: 11.0263 - val_loss: 13.6648 - val_mean_absolute_error: 3.0541 - val_mean_squared_error: 13.6648\n",
      "Epoch 144/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.9943 - mean_absolute_error: 2.6861 - mean_squared_error: 10.9943 - val_loss: 13.6659 - val_mean_absolute_error: 3.0502 - val_mean_squared_error: 13.6659\n",
      "Epoch 145/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.9774 - mean_absolute_error: 2.6834 - mean_squared_error: 10.9774 - val_loss: 13.6533 - val_mean_absolute_error: 3.0480 - val_mean_squared_error: 13.6533\n",
      "Epoch 146/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.9697 - mean_absolute_error: 2.6831 - mean_squared_error: 10.9697 - val_loss: 13.8029 - val_mean_absolute_error: 3.0355 - val_mean_squared_error: 13.8029\n",
      "Epoch 147/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.9658 - mean_absolute_error: 2.6792 - mean_squared_error: 10.9658 - val_loss: 13.5769 - val_mean_absolute_error: 3.0503 - val_mean_squared_error: 13.5769\n",
      "Epoch 148/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.9380 - mean_absolute_error: 2.6773 - mean_squared_error: 10.9380 - val_loss: 13.5695 - val_mean_absolute_error: 3.0472 - val_mean_squared_error: 13.5695\n",
      "Epoch 149/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.9258 - mean_absolute_error: 2.6749 - mean_squared_error: 10.9258 - val_loss: 13.5277 - val_mean_absolute_error: 3.0503 - val_mean_squared_error: 13.5277\n",
      "Epoch 150/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.9152 - mean_absolute_error: 2.6742 - mean_squared_error: 10.9152 - val_loss: 13.6263 - val_mean_absolute_error: 3.0338 - val_mean_squared_error: 13.6263\n",
      "Epoch 151/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.9151 - mean_absolute_error: 2.6734 - mean_squared_error: 10.9151 - val_loss: 13.5337 - val_mean_absolute_error: 3.0401 - val_mean_squared_error: 13.5337\n",
      "Epoch 152/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.8983 - mean_absolute_error: 2.6699 - mean_squared_error: 10.8983 - val_loss: 13.4762 - val_mean_absolute_error: 3.0465 - val_mean_squared_error: 13.4762\n",
      "Epoch 153/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.8715 - mean_absolute_error: 2.6681 - mean_squared_error: 10.8715 - val_loss: 13.5576 - val_mean_absolute_error: 3.0301 - val_mean_squared_error: 13.5576\n",
      "Epoch 154/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.8678 - mean_absolute_error: 2.6660 - mean_squared_error: 10.8678 - val_loss: 13.5169 - val_mean_absolute_error: 3.0309 - val_mean_squared_error: 13.5169\n",
      "Epoch 155/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.8624 - mean_absolute_error: 2.6645 - mean_squared_error: 10.8624 - val_loss: 13.4421 - val_mean_absolute_error: 3.0388 - val_mean_squared_error: 13.4421\n",
      "Epoch 156/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.8377 - mean_absolute_error: 2.6625 - mean_squared_error: 10.8377 - val_loss: 13.4973 - val_mean_absolute_error: 3.0261 - val_mean_squared_error: 13.4973\n",
      "Epoch 157/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.8225 - mean_absolute_error: 2.6608 - mean_squared_error: 10.8225 - val_loss: 13.6596 - val_mean_absolute_error: 3.0139 - val_mean_squared_error: 13.6596\n",
      "Epoch 158/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.8364 - mean_absolute_error: 2.6603 - mean_squared_error: 10.8364 - val_loss: 13.5716 - val_mean_absolute_error: 3.0147 - val_mean_squared_error: 13.5716\n",
      "Epoch 159/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.8061 - mean_absolute_error: 2.6557 - mean_squared_error: 10.8061 - val_loss: 13.5352 - val_mean_absolute_error: 3.0140 - val_mean_squared_error: 13.5352\n",
      "Epoch 160/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.7951 - mean_absolute_error: 2.6557 - mean_squared_error: 10.7951 - val_loss: 13.5563 - val_mean_absolute_error: 3.0103 - val_mean_squared_error: 13.5563\n",
      "Epoch 161/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.7754 - mean_absolute_error: 2.6506 - mean_squared_error: 10.7754 - val_loss: 13.4266 - val_mean_absolute_error: 3.0168 - val_mean_squared_error: 13.4266\n",
      "Epoch 162/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.7563 - mean_absolute_error: 2.6500 - mean_squared_error: 10.7563 - val_loss: 13.4512 - val_mean_absolute_error: 3.0113 - val_mean_squared_error: 13.4512\n",
      "Epoch 163/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.7551 - mean_absolute_error: 2.6486 - mean_squared_error: 10.7551 - val_loss: 13.4054 - val_mean_absolute_error: 3.0124 - val_mean_squared_error: 13.4054\n",
      "Epoch 164/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.7477 - mean_absolute_error: 2.6489 - mean_squared_error: 10.7477 - val_loss: 13.4942 - val_mean_absolute_error: 3.0033 - val_mean_squared_error: 13.4942\n",
      "Epoch 165/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.7428 - mean_absolute_error: 2.6472 - mean_squared_error: 10.7428 - val_loss: 13.4589 - val_mean_absolute_error: 3.0025 - val_mean_squared_error: 13.4589\n",
      "Epoch 166/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.7117 - mean_absolute_error: 2.6416 - mean_squared_error: 10.7117 - val_loss: 13.3373 - val_mean_absolute_error: 3.0104 - val_mean_squared_error: 13.3373\n",
      "Epoch 167/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.6983 - mean_absolute_error: 2.6401 - mean_squared_error: 10.6983 - val_loss: 13.2872 - val_mean_absolute_error: 3.0146 - val_mean_squared_error: 13.2872\n",
      "Epoch 168/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.6944 - mean_absolute_error: 2.6406 - mean_squared_error: 10.6944 - val_loss: 13.3741 - val_mean_absolute_error: 3.0000 - val_mean_squared_error: 13.3741\n",
      "Epoch 169/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.6728 - mean_absolute_error: 2.6362 - mean_squared_error: 10.6728 - val_loss: 13.3302 - val_mean_absolute_error: 3.0010 - val_mean_squared_error: 13.3302\n",
      "Epoch 170/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.6586 - mean_absolute_error: 2.6343 - mean_squared_error: 10.6586 - val_loss: 13.2852 - val_mean_absolute_error: 3.0031 - val_mean_squared_error: 13.2852\n",
      "Epoch 171/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.6556 - mean_absolute_error: 2.6357 - mean_squared_error: 10.6556 - val_loss: 13.4711 - val_mean_absolute_error: 2.9885 - val_mean_squared_error: 13.4711\n",
      "Epoch 172/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.6343 - mean_absolute_error: 2.6307 - mean_squared_error: 10.6343 - val_loss: 13.3703 - val_mean_absolute_error: 2.9897 - val_mean_squared_error: 13.3703\n",
      "Epoch 173/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.6326 - mean_absolute_error: 2.6283 - mean_squared_error: 10.6326 - val_loss: 13.1846 - val_mean_absolute_error: 3.0094 - val_mean_squared_error: 13.1846\n",
      "Epoch 174/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.6205 - mean_absolute_error: 2.6301 - mean_squared_error: 10.6205 - val_loss: 13.3132 - val_mean_absolute_error: 2.9881 - val_mean_squared_error: 13.3132\n",
      "Epoch 175/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.6102 - mean_absolute_error: 2.6254 - mean_squared_error: 10.6102 - val_loss: 13.1688 - val_mean_absolute_error: 3.0034 - val_mean_squared_error: 13.1688\n",
      "Epoch 176/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.6052 - mean_absolute_error: 2.6269 - mean_squared_error: 10.6052 - val_loss: 13.2375 - val_mean_absolute_error: 2.9889 - val_mean_squared_error: 13.2375\n",
      "Epoch 177/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.5923 - mean_absolute_error: 2.6219 - mean_squared_error: 10.5923 - val_loss: 13.1070 - val_mean_absolute_error: 3.0127 - val_mean_squared_error: 13.1070\n",
      "Epoch 178/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.5834 - mean_absolute_error: 2.6244 - mean_squared_error: 10.5834 - val_loss: 13.1977 - val_mean_absolute_error: 2.9871 - val_mean_squared_error: 13.1977\n",
      "Epoch 179/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.5547 - mean_absolute_error: 2.6181 - mean_squared_error: 10.5547 - val_loss: 13.1537 - val_mean_absolute_error: 2.9898 - val_mean_squared_error: 13.1537\n",
      "Epoch 180/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.5616 - mean_absolute_error: 2.6196 - mean_squared_error: 10.5616 - val_loss: 13.1577 - val_mean_absolute_error: 2.9856 - val_mean_squared_error: 13.1577\n",
      "Epoch 181/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.5351 - mean_absolute_error: 2.6166 - mean_squared_error: 10.5351 - val_loss: 13.2933 - val_mean_absolute_error: 2.9726 - val_mean_squared_error: 13.2933\n",
      "Epoch 182/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.5275 - mean_absolute_error: 2.6133 - mean_squared_error: 10.5275 - val_loss: 13.1429 - val_mean_absolute_error: 2.9809 - val_mean_squared_error: 13.1429\n",
      "Epoch 183/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.5287 - mean_absolute_error: 2.6142 - mean_squared_error: 10.5287 - val_loss: 13.1625 - val_mean_absolute_error: 2.9757 - val_mean_squared_error: 13.1625\n",
      "Epoch 184/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.5068 - mean_absolute_error: 2.6110 - mean_squared_error: 10.5068 - val_loss: 13.0889 - val_mean_absolute_error: 2.9818 - val_mean_squared_error: 13.0889\n",
      "Epoch 185/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.5061 - mean_absolute_error: 2.6099 - mean_squared_error: 10.5061 - val_loss: 13.0520 - val_mean_absolute_error: 2.9846 - val_mean_squared_error: 13.0520\n",
      "Epoch 186/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.5088 - mean_absolute_error: 2.6101 - mean_squared_error: 10.5088 - val_loss: 13.0732 - val_mean_absolute_error: 2.9771 - val_mean_squared_error: 13.0732\n",
      "Epoch 187/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.4817 - mean_absolute_error: 2.6066 - mean_squared_error: 10.4817 - val_loss: 13.0841 - val_mean_absolute_error: 2.9723 - val_mean_squared_error: 13.0841\n",
      "Epoch 188/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.4620 - mean_absolute_error: 2.6035 - mean_squared_error: 10.4620 - val_loss: 13.0628 - val_mean_absolute_error: 2.9719 - val_mean_squared_error: 13.0628\n",
      "Epoch 189/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.4525 - mean_absolute_error: 2.6028 - mean_squared_error: 10.4525 - val_loss: 13.0291 - val_mean_absolute_error: 2.9734 - val_mean_squared_error: 13.0291\n",
      "Epoch 190/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.4589 - mean_absolute_error: 2.6037 - mean_squared_error: 10.4589 - val_loss: 13.0556 - val_mean_absolute_error: 2.9666 - val_mean_squared_error: 13.0556\n",
      "Epoch 191/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.4359 - mean_absolute_error: 2.5992 - mean_squared_error: 10.4359 - val_loss: 13.0262 - val_mean_absolute_error: 2.9671 - val_mean_squared_error: 13.0262\n",
      "Epoch 192/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.4150 - mean_absolute_error: 2.5953 - mean_squared_error: 10.4150 - val_loss: 12.9396 - val_mean_absolute_error: 2.9810 - val_mean_squared_error: 12.9396\n",
      "Epoch 193/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.4411 - mean_absolute_error: 2.6010 - mean_squared_error: 10.4411 - val_loss: 12.9642 - val_mean_absolute_error: 2.9700 - val_mean_squared_error: 12.9642\n",
      "Epoch 194/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.4027 - mean_absolute_error: 2.5958 - mean_squared_error: 10.4027 - val_loss: 13.0882 - val_mean_absolute_error: 2.9536 - val_mean_squared_error: 13.0882\n",
      "Epoch 195/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.3917 - mean_absolute_error: 2.5923 - mean_squared_error: 10.3917 - val_loss: 13.0318 - val_mean_absolute_error: 2.9551 - val_mean_squared_error: 13.0318\n",
      "Epoch 196/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.3735 - mean_absolute_error: 2.5904 - mean_squared_error: 10.3735 - val_loss: 12.9900 - val_mean_absolute_error: 2.9565 - val_mean_squared_error: 12.9900\n",
      "Epoch 197/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.3685 - mean_absolute_error: 2.5892 - mean_squared_error: 10.3685 - val_loss: 12.9965 - val_mean_absolute_error: 2.9531 - val_mean_squared_error: 12.9965\n",
      "Epoch 198/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.3771 - mean_absolute_error: 2.5903 - mean_squared_error: 10.3771 - val_loss: 13.0303 - val_mean_absolute_error: 2.9480 - val_mean_squared_error: 13.0303\n",
      "Epoch 199/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.3536 - mean_absolute_error: 2.5854 - mean_squared_error: 10.3536 - val_loss: 12.8866 - val_mean_absolute_error: 2.9622 - val_mean_squared_error: 12.8866\n",
      "Epoch 200/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.3431 - mean_absolute_error: 2.5853 - mean_squared_error: 10.3431 - val_loss: 12.9065 - val_mean_absolute_error: 2.9550 - val_mean_squared_error: 12.9065\n",
      "Epoch 201/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.3257 - mean_absolute_error: 2.5819 - mean_squared_error: 10.3257 - val_loss: 12.8653 - val_mean_absolute_error: 2.9588 - val_mean_squared_error: 12.8653\n",
      "Epoch 202/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.3230 - mean_absolute_error: 2.5833 - mean_squared_error: 10.3230 - val_loss: 12.9455 - val_mean_absolute_error: 2.9448 - val_mean_squared_error: 12.9455\n",
      "Epoch 203/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.3048 - mean_absolute_error: 2.5797 - mean_squared_error: 10.3048 - val_loss: 12.9563 - val_mean_absolute_error: 2.9415 - val_mean_squared_error: 12.9563\n",
      "Epoch 204/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.3059 - mean_absolute_error: 2.5789 - mean_squared_error: 10.3059 - val_loss: 12.9064 - val_mean_absolute_error: 2.9434 - val_mean_squared_error: 12.9064\n",
      "Epoch 205/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.2922 - mean_absolute_error: 2.5762 - mean_squared_error: 10.2922 - val_loss: 12.8072 - val_mean_absolute_error: 2.9562 - val_mean_squared_error: 12.8072\n",
      "Epoch 206/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.2848 - mean_absolute_error: 2.5766 - mean_squared_error: 10.2848 - val_loss: 12.8463 - val_mean_absolute_error: 2.9449 - val_mean_squared_error: 12.8463\n",
      "Epoch 207/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.2753 - mean_absolute_error: 2.5754 - mean_squared_error: 10.2753 - val_loss: 12.9234 - val_mean_absolute_error: 2.9348 - val_mean_squared_error: 12.9234\n",
      "Epoch 208/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.2668 - mean_absolute_error: 2.5722 - mean_squared_error: 10.2668 - val_loss: 12.8093 - val_mean_absolute_error: 2.9442 - val_mean_squared_error: 12.8093\n",
      "Epoch 209/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.2694 - mean_absolute_error: 2.5722 - mean_squared_error: 10.2694 - val_loss: 12.7845 - val_mean_absolute_error: 2.9452 - val_mean_squared_error: 12.7845\n",
      "Epoch 210/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.2421 - mean_absolute_error: 2.5705 - mean_squared_error: 10.2421 - val_loss: 12.9111 - val_mean_absolute_error: 2.9292 - val_mean_squared_error: 12.9111\n",
      "Epoch 211/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.2331 - mean_absolute_error: 2.5679 - mean_squared_error: 10.2331 - val_loss: 12.9955 - val_mean_absolute_error: 2.9245 - val_mean_squared_error: 12.9955\n",
      "Epoch 212/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.2270 - mean_absolute_error: 2.5649 - mean_squared_error: 10.2270 - val_loss: 12.7832 - val_mean_absolute_error: 2.9357 - val_mean_squared_error: 12.7832\n",
      "Epoch 213/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.2154 - mean_absolute_error: 2.5640 - mean_squared_error: 10.2154 - val_loss: 12.7439 - val_mean_absolute_error: 2.9390 - val_mean_squared_error: 12.7439\n",
      "Epoch 214/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.2080 - mean_absolute_error: 2.5634 - mean_squared_error: 10.2080 - val_loss: 12.7649 - val_mean_absolute_error: 2.9324 - val_mean_squared_error: 12.7649\n",
      "Epoch 215/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.2025 - mean_absolute_error: 2.5643 - mean_squared_error: 10.2025 - val_loss: 12.8680 - val_mean_absolute_error: 2.9215 - val_mean_squared_error: 12.8680\n",
      "Epoch 216/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.1855 - mean_absolute_error: 2.5590 - mean_squared_error: 10.1855 - val_loss: 12.7340 - val_mean_absolute_error: 2.9309 - val_mean_squared_error: 12.7340\n",
      "Epoch 217/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.1805 - mean_absolute_error: 2.5594 - mean_squared_error: 10.1805 - val_loss: 12.7450 - val_mean_absolute_error: 2.9266 - val_mean_squared_error: 12.7450\n",
      "Epoch 218/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.1677 - mean_absolute_error: 2.5575 - mean_squared_error: 10.1677 - val_loss: 12.7363 - val_mean_absolute_error: 2.9250 - val_mean_squared_error: 12.7363\n",
      "Epoch 219/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.1542 - mean_absolute_error: 2.5561 - mean_squared_error: 10.1542 - val_loss: 12.7852 - val_mean_absolute_error: 2.9182 - val_mean_squared_error: 12.7852\n",
      "Epoch 220/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.1484 - mean_absolute_error: 2.5531 - mean_squared_error: 10.1484 - val_loss: 12.6604 - val_mean_absolute_error: 2.9315 - val_mean_squared_error: 12.6604\n",
      "Epoch 221/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.1417 - mean_absolute_error: 2.5537 - mean_squared_error: 10.1417 - val_loss: 12.7324 - val_mean_absolute_error: 2.9179 - val_mean_squared_error: 12.7324\n",
      "Epoch 222/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.1321 - mean_absolute_error: 2.5514 - mean_squared_error: 10.1321 - val_loss: 12.6683 - val_mean_absolute_error: 2.9231 - val_mean_squared_error: 12.6683\n",
      "Epoch 223/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.1213 - mean_absolute_error: 2.5510 - mean_squared_error: 10.1213 - val_loss: 12.7077 - val_mean_absolute_error: 2.9155 - val_mean_squared_error: 12.7077\n",
      "Epoch 224/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.1166 - mean_absolute_error: 2.5494 - mean_squared_error: 10.1166 - val_loss: 12.7087 - val_mean_absolute_error: 2.9132 - val_mean_squared_error: 12.7087\n",
      "Epoch 225/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.1193 - mean_absolute_error: 2.5493 - mean_squared_error: 10.1193 - val_loss: 12.6761 - val_mean_absolute_error: 2.9139 - val_mean_squared_error: 12.6761\n",
      "Epoch 226/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.0969 - mean_absolute_error: 2.5466 - mean_squared_error: 10.0969 - val_loss: 12.7374 - val_mean_absolute_error: 2.9072 - val_mean_squared_error: 12.7374\n",
      "Epoch 227/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.0939 - mean_absolute_error: 2.5447 - mean_squared_error: 10.0939 - val_loss: 12.6540 - val_mean_absolute_error: 2.9114 - val_mean_squared_error: 12.6540\n",
      "Epoch 228/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.0790 - mean_absolute_error: 2.5439 - mean_squared_error: 10.0790 - val_loss: 12.6490 - val_mean_absolute_error: 2.9096 - val_mean_squared_error: 12.6490\n",
      "Epoch 229/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.0704 - mean_absolute_error: 2.5413 - mean_squared_error: 10.0704 - val_loss: 12.5961 - val_mean_absolute_error: 2.9141 - val_mean_squared_error: 12.5961\n",
      "Epoch 230/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.0599 - mean_absolute_error: 2.5404 - mean_squared_error: 10.0599 - val_loss: 12.6219 - val_mean_absolute_error: 2.9077 - val_mean_squared_error: 12.6219\n",
      "Epoch 231/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.0528 - mean_absolute_error: 2.5383 - mean_squared_error: 10.0528 - val_loss: 12.5532 - val_mean_absolute_error: 2.9164 - val_mean_squared_error: 12.5532\n",
      "Epoch 232/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.0475 - mean_absolute_error: 2.5388 - mean_squared_error: 10.0475 - val_loss: 12.5899 - val_mean_absolute_error: 2.9067 - val_mean_squared_error: 12.5899\n",
      "Epoch 233/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.0352 - mean_absolute_error: 2.5360 - mean_squared_error: 10.0352 - val_loss: 12.5406 - val_mean_absolute_error: 2.9123 - val_mean_squared_error: 12.5406\n",
      "Epoch 234/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.0368 - mean_absolute_error: 2.5374 - mean_squared_error: 10.0368 - val_loss: 12.5528 - val_mean_absolute_error: 2.9069 - val_mean_squared_error: 12.5528\n",
      "Epoch 235/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.0218 - mean_absolute_error: 2.5337 - mean_squared_error: 10.0218 - val_loss: 12.5410 - val_mean_absolute_error: 2.9060 - val_mean_squared_error: 12.5410\n",
      "Epoch 236/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.0127 - mean_absolute_error: 2.5328 - mean_squared_error: 10.0127 - val_loss: 12.5637 - val_mean_absolute_error: 2.9000 - val_mean_squared_error: 12.5637\n",
      "Epoch 237/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.0087 - mean_absolute_error: 2.5319 - mean_squared_error: 10.0087 - val_loss: 12.5930 - val_mean_absolute_error: 2.8952 - val_mean_squared_error: 12.5930\n",
      "Epoch 238/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 10.0104 - mean_absolute_error: 2.5307 - mean_squared_error: 10.0104 - val_loss: 12.4530 - val_mean_absolute_error: 2.9208 - val_mean_squared_error: 12.4530\n",
      "Epoch 239/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.9951 - mean_absolute_error: 2.5314 - mean_squared_error: 9.9951 - val_loss: 12.5065 - val_mean_absolute_error: 2.9004 - val_mean_squared_error: 12.5065\n",
      "Epoch 240/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.9850 - mean_absolute_error: 2.5288 - mean_squared_error: 9.9850 - val_loss: 12.5654 - val_mean_absolute_error: 2.8914 - val_mean_squared_error: 12.5654\n",
      "Epoch 241/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.9724 - mean_absolute_error: 2.5260 - mean_squared_error: 9.9724 - val_loss: 12.5257 - val_mean_absolute_error: 2.8928 - val_mean_squared_error: 12.5257\n",
      "Epoch 242/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.9684 - mean_absolute_error: 2.5252 - mean_squared_error: 9.9684 - val_loss: 12.5181 - val_mean_absolute_error: 2.8915 - val_mean_squared_error: 12.5181\n",
      "Epoch 243/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.9580 - mean_absolute_error: 2.5245 - mean_squared_error: 9.9580 - val_loss: 12.5952 - val_mean_absolute_error: 2.8842 - val_mean_squared_error: 12.5952\n",
      "Epoch 244/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.9556 - mean_absolute_error: 2.5227 - mean_squared_error: 9.9556 - val_loss: 12.5069 - val_mean_absolute_error: 2.8884 - val_mean_squared_error: 12.5069\n",
      "Epoch 245/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.9638 - mean_absolute_error: 2.5242 - mean_squared_error: 9.9638 - val_loss: 12.4589 - val_mean_absolute_error: 2.8919 - val_mean_squared_error: 12.4589\n",
      "Epoch 246/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.9407 - mean_absolute_error: 2.5215 - mean_squared_error: 9.9407 - val_loss: 12.5226 - val_mean_absolute_error: 2.8831 - val_mean_squared_error: 12.5226\n",
      "Epoch 247/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.9271 - mean_absolute_error: 2.5177 - mean_squared_error: 9.9271 - val_loss: 12.4219 - val_mean_absolute_error: 2.8929 - val_mean_squared_error: 12.4219\n",
      "Epoch 248/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.9116 - mean_absolute_error: 2.5190 - mean_squared_error: 9.9116 - val_loss: 12.7455 - val_mean_absolute_error: 2.8751 - val_mean_squared_error: 12.7455\n",
      "Epoch 249/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.9226 - mean_absolute_error: 2.5168 - mean_squared_error: 9.9226 - val_loss: 12.5894 - val_mean_absolute_error: 2.8752 - val_mean_squared_error: 12.5894\n",
      "Epoch 250/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.9065 - mean_absolute_error: 2.5137 - mean_squared_error: 9.9065 - val_loss: 12.4237 - val_mean_absolute_error: 2.8846 - val_mean_squared_error: 12.4237\n",
      "Epoch 251/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.9162 - mean_absolute_error: 2.5160 - mean_squared_error: 9.9162 - val_loss: 12.4129 - val_mean_absolute_error: 2.8838 - val_mean_squared_error: 12.4129\n",
      "Epoch 252/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.8942 - mean_absolute_error: 2.5144 - mean_squared_error: 9.8942 - val_loss: 12.5038 - val_mean_absolute_error: 2.8739 - val_mean_squared_error: 12.5038\n",
      "Epoch 253/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.8837 - mean_absolute_error: 2.5105 - mean_squared_error: 9.8837 - val_loss: 12.3598 - val_mean_absolute_error: 2.8880 - val_mean_squared_error: 12.3598\n",
      "Epoch 254/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.8853 - mean_absolute_error: 2.5125 - mean_squared_error: 9.8853 - val_loss: 12.4120 - val_mean_absolute_error: 2.8773 - val_mean_squared_error: 12.4120\n",
      "Epoch 255/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.8692 - mean_absolute_error: 2.5105 - mean_squared_error: 9.8692 - val_loss: 12.4489 - val_mean_absolute_error: 2.8722 - val_mean_squared_error: 12.4489\n",
      "Epoch 256/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.8663 - mean_absolute_error: 2.5074 - mean_squared_error: 9.8663 - val_loss: 12.3444 - val_mean_absolute_error: 2.8824 - val_mean_squared_error: 12.3444\n",
      "Epoch 257/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.8597 - mean_absolute_error: 2.5090 - mean_squared_error: 9.8597 - val_loss: 12.4926 - val_mean_absolute_error: 2.8668 - val_mean_squared_error: 12.4926\n",
      "Epoch 258/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.8561 - mean_absolute_error: 2.5067 - mean_squared_error: 9.8561 - val_loss: 12.4059 - val_mean_absolute_error: 2.8701 - val_mean_squared_error: 12.4059\n",
      "Epoch 259/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.8392 - mean_absolute_error: 2.5045 - mean_squared_error: 9.8392 - val_loss: 12.3896 - val_mean_absolute_error: 2.8697 - val_mean_squared_error: 12.3896\n",
      "Epoch 260/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.8362 - mean_absolute_error: 2.5029 - mean_squared_error: 9.8362 - val_loss: 12.3396 - val_mean_absolute_error: 2.8733 - val_mean_squared_error: 12.3396\n",
      "Epoch 261/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.8357 - mean_absolute_error: 2.5048 - mean_squared_error: 9.8357 - val_loss: 12.4460 - val_mean_absolute_error: 2.8629 - val_mean_squared_error: 12.4460\n",
      "Epoch 262/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.8337 - mean_absolute_error: 2.5018 - mean_squared_error: 9.8337 - val_loss: 12.3213 - val_mean_absolute_error: 2.8713 - val_mean_squared_error: 12.3213\n",
      "Epoch 263/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.8122 - mean_absolute_error: 2.5004 - mean_squared_error: 9.8122 - val_loss: 12.3157 - val_mean_absolute_error: 2.8699 - val_mean_squared_error: 12.3157\n",
      "Epoch 264/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.8178 - mean_absolute_error: 2.5014 - mean_squared_error: 9.8178 - val_loss: 12.3976 - val_mean_absolute_error: 2.8608 - val_mean_squared_error: 12.3976\n",
      "Epoch 265/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.8050 - mean_absolute_error: 2.4988 - mean_squared_error: 9.8050 - val_loss: 12.3663 - val_mean_absolute_error: 2.8611 - val_mean_squared_error: 12.3663\n",
      "Epoch 266/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.7894 - mean_absolute_error: 2.4968 - mean_squared_error: 9.7894 - val_loss: 12.3845 - val_mean_absolute_error: 2.8584 - val_mean_squared_error: 12.3845\n",
      "Epoch 267/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.7929 - mean_absolute_error: 2.4972 - mean_squared_error: 9.7929 - val_loss: 12.3800 - val_mean_absolute_error: 2.8572 - val_mean_squared_error: 12.3800\n",
      "Epoch 268/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.7916 - mean_absolute_error: 2.4948 - mean_squared_error: 9.7916 - val_loss: 12.2354 - val_mean_absolute_error: 2.8719 - val_mean_squared_error: 12.2354\n",
      "Epoch 269/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.7883 - mean_absolute_error: 2.4984 - mean_squared_error: 9.7883 - val_loss: 12.4337 - val_mean_absolute_error: 2.8524 - val_mean_squared_error: 12.4337\n",
      "Epoch 270/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.7807 - mean_absolute_error: 2.4950 - mean_squared_error: 9.7807 - val_loss: 12.4742 - val_mean_absolute_error: 2.8505 - val_mean_squared_error: 12.4742\n",
      "Epoch 271/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.7695 - mean_absolute_error: 2.4910 - mean_squared_error: 9.7695 - val_loss: 12.2299 - val_mean_absolute_error: 2.8650 - val_mean_squared_error: 12.2299\n",
      "Epoch 272/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.7517 - mean_absolute_error: 2.4904 - mean_squared_error: 9.7517 - val_loss: 12.2247 - val_mean_absolute_error: 2.8635 - val_mean_squared_error: 12.2247\n",
      "Epoch 273/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.7520 - mean_absolute_error: 2.4897 - mean_squared_error: 9.7520 - val_loss: 12.1843 - val_mean_absolute_error: 2.8703 - val_mean_squared_error: 12.1843\n",
      "Epoch 274/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.7512 - mean_absolute_error: 2.4923 - mean_squared_error: 9.7512 - val_loss: 12.4921 - val_mean_absolute_error: 2.8461 - val_mean_squared_error: 12.4921\n",
      "Epoch 275/10000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 9.7514 - mean_absolute_error: 2.4891 - mean_squared_error: 9.7514 - val_loss: 12.3008 - val_mean_absolute_error: 2.8499 - val_mean_squared_error: 12.3008\n",
      "Epoch 276/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.7236 - mean_absolute_error: 2.4859 - mean_squared_error: 9.7236 - val_loss: 12.3167 - val_mean_absolute_error: 2.8475 - val_mean_squared_error: 12.3167\n",
      "Epoch 277/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.7200 - mean_absolute_error: 2.4845 - mean_squared_error: 9.7200 - val_loss: 12.2525 - val_mean_absolute_error: 2.8504 - val_mean_squared_error: 12.2525\n",
      "Epoch 278/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.7169 - mean_absolute_error: 2.4828 - mean_squared_error: 9.7169 - val_loss: 12.1489 - val_mean_absolute_error: 2.8645 - val_mean_squared_error: 12.1489\n",
      "Epoch 279/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.7208 - mean_absolute_error: 2.4853 - mean_squared_error: 9.7208 - val_loss: 12.1811 - val_mean_absolute_error: 2.8550 - val_mean_squared_error: 12.1811\n",
      "Epoch 280/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.7008 - mean_absolute_error: 2.4822 - mean_squared_error: 9.7008 - val_loss: 12.2291 - val_mean_absolute_error: 2.8475 - val_mean_squared_error: 12.2291\n",
      "Epoch 281/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.7034 - mean_absolute_error: 2.4823 - mean_squared_error: 9.7034 - val_loss: 12.2392 - val_mean_absolute_error: 2.8451 - val_mean_squared_error: 12.2392\n",
      "Epoch 282/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6963 - mean_absolute_error: 2.4797 - mean_squared_error: 9.6963 - val_loss: 12.1667 - val_mean_absolute_error: 2.8509 - val_mean_squared_error: 12.1667\n",
      "Epoch 283/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6842 - mean_absolute_error: 2.4798 - mean_squared_error: 9.6842 - val_loss: 12.2105 - val_mean_absolute_error: 2.8442 - val_mean_squared_error: 12.2105\n",
      "Epoch 284/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6839 - mean_absolute_error: 2.4806 - mean_squared_error: 9.6839 - val_loss: 12.3468 - val_mean_absolute_error: 2.8367 - val_mean_squared_error: 12.3468\n",
      "Epoch 285/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6779 - mean_absolute_error: 2.4763 - mean_squared_error: 9.6779 - val_loss: 12.1511 - val_mean_absolute_error: 2.8472 - val_mean_squared_error: 12.1511\n",
      "Epoch 286/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6688 - mean_absolute_error: 2.4765 - mean_squared_error: 9.6688 - val_loss: 12.1321 - val_mean_absolute_error: 2.8480 - val_mean_squared_error: 12.1321\n",
      "Epoch 287/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6610 - mean_absolute_error: 2.4767 - mean_squared_error: 9.6610 - val_loss: 12.1825 - val_mean_absolute_error: 2.8403 - val_mean_squared_error: 12.1825\n",
      "Epoch 288/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6586 - mean_absolute_error: 2.4748 - mean_squared_error: 9.6586 - val_loss: 12.1772 - val_mean_absolute_error: 2.8392 - val_mean_squared_error: 12.1772\n",
      "Epoch 289/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6489 - mean_absolute_error: 2.4726 - mean_squared_error: 9.6489 - val_loss: 12.1105 - val_mean_absolute_error: 2.8452 - val_mean_squared_error: 12.1105\n",
      "Epoch 290/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6735 - mean_absolute_error: 2.4772 - mean_squared_error: 9.6735 - val_loss: 12.2114 - val_mean_absolute_error: 2.8339 - val_mean_squared_error: 12.2114\n",
      "Epoch 291/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6409 - mean_absolute_error: 2.4699 - mean_squared_error: 9.6409 - val_loss: 12.0544 - val_mean_absolute_error: 2.8530 - val_mean_squared_error: 12.0544\n",
      "Epoch 292/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6343 - mean_absolute_error: 2.4745 - mean_squared_error: 9.6343 - val_loss: 12.3738 - val_mean_absolute_error: 2.8287 - val_mean_squared_error: 12.3738\n",
      "Epoch 293/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6422 - mean_absolute_error: 2.4691 - mean_squared_error: 9.6422 - val_loss: 12.1212 - val_mean_absolute_error: 2.8365 - val_mean_squared_error: 12.1212\n",
      "Epoch 294/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6255 - mean_absolute_error: 2.4686 - mean_squared_error: 9.6255 - val_loss: 12.0800 - val_mean_absolute_error: 2.8399 - val_mean_squared_error: 12.0800\n",
      "Epoch 295/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6142 - mean_absolute_error: 2.4679 - mean_squared_error: 9.6142 - val_loss: 12.0700 - val_mean_absolute_error: 2.8396 - val_mean_squared_error: 12.0700\n",
      "Epoch 296/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6159 - mean_absolute_error: 2.4700 - mean_squared_error: 9.6159 - val_loss: 12.2857 - val_mean_absolute_error: 2.8252 - val_mean_squared_error: 12.2857\n",
      "Epoch 297/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6119 - mean_absolute_error: 2.4642 - mean_squared_error: 9.6119 - val_loss: 12.0597 - val_mean_absolute_error: 2.8373 - val_mean_squared_error: 12.0597\n",
      "Epoch 298/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6005 - mean_absolute_error: 2.4658 - mean_squared_error: 9.6005 - val_loss: 12.0798 - val_mean_absolute_error: 2.8327 - val_mean_squared_error: 12.0798\n",
      "Epoch 299/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6035 - mean_absolute_error: 2.4661 - mean_squared_error: 9.6035 - val_loss: 12.1158 - val_mean_absolute_error: 2.8278 - val_mean_squared_error: 12.1158\n",
      "Epoch 300/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5990 - mean_absolute_error: 2.4629 - mean_squared_error: 9.5990 - val_loss: 12.0124 - val_mean_absolute_error: 2.8398 - val_mean_squared_error: 12.0124\n",
      "Epoch 301/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.6106 - mean_absolute_error: 2.4658 - mean_squared_error: 9.6106 - val_loss: 11.9948 - val_mean_absolute_error: 2.8419 - val_mean_squared_error: 11.9948\n",
      "Epoch 302/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5806 - mean_absolute_error: 2.4633 - mean_squared_error: 9.5806 - val_loss: 12.0777 - val_mean_absolute_error: 2.8266 - val_mean_squared_error: 12.0777\n",
      "Epoch 303/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5738 - mean_absolute_error: 2.4609 - mean_squared_error: 9.5738 - val_loss: 12.1119 - val_mean_absolute_error: 2.8228 - val_mean_squared_error: 12.1119\n",
      "Epoch 304/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5670 - mean_absolute_error: 2.4588 - mean_squared_error: 9.5670 - val_loss: 12.0212 - val_mean_absolute_error: 2.8300 - val_mean_squared_error: 12.0212\n",
      "Epoch 305/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5622 - mean_absolute_error: 2.4609 - mean_squared_error: 9.5622 - val_loss: 12.1352 - val_mean_absolute_error: 2.8194 - val_mean_squared_error: 12.1352\n",
      "Epoch 306/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5559 - mean_absolute_error: 2.4570 - mean_squared_error: 9.5559 - val_loss: 12.0214 - val_mean_absolute_error: 2.8265 - val_mean_squared_error: 12.0214\n",
      "Epoch 307/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5615 - mean_absolute_error: 2.4597 - mean_squared_error: 9.5615 - val_loss: 12.0992 - val_mean_absolute_error: 2.8187 - val_mean_squared_error: 12.0992\n",
      "Epoch 308/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5449 - mean_absolute_error: 2.4559 - mean_squared_error: 9.5449 - val_loss: 12.0986 - val_mean_absolute_error: 2.8176 - val_mean_squared_error: 12.0986\n",
      "Epoch 309/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5485 - mean_absolute_error: 2.4566 - mean_squared_error: 9.5485 - val_loss: 12.0792 - val_mean_absolute_error: 2.8174 - val_mean_squared_error: 12.0792\n",
      "Epoch 310/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5464 - mean_absolute_error: 2.4559 - mean_squared_error: 9.5464 - val_loss: 12.0514 - val_mean_absolute_error: 2.8177 - val_mean_squared_error: 12.0514\n",
      "Epoch 311/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5338 - mean_absolute_error: 2.4539 - mean_squared_error: 9.5338 - val_loss: 12.0066 - val_mean_absolute_error: 2.8203 - val_mean_squared_error: 12.0066\n",
      "Epoch 312/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5318 - mean_absolute_error: 2.4544 - mean_squared_error: 9.5318 - val_loss: 12.0254 - val_mean_absolute_error: 2.8171 - val_mean_squared_error: 12.0254\n",
      "Epoch 313/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5299 - mean_absolute_error: 2.4536 - mean_squared_error: 9.5299 - val_loss: 12.0788 - val_mean_absolute_error: 2.8131 - val_mean_squared_error: 12.0788\n",
      "Epoch 314/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5138 - mean_absolute_error: 2.4506 - mean_squared_error: 9.5138 - val_loss: 12.0659 - val_mean_absolute_error: 2.8125 - val_mean_squared_error: 12.0659\n",
      "Epoch 315/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5076 - mean_absolute_error: 2.4495 - mean_squared_error: 9.5076 - val_loss: 11.9840 - val_mean_absolute_error: 2.8168 - val_mean_squared_error: 11.9840\n",
      "Epoch 316/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5090 - mean_absolute_error: 2.4498 - mean_squared_error: 9.5090 - val_loss: 11.9388 - val_mean_absolute_error: 2.8213 - val_mean_squared_error: 11.9388\n",
      "Epoch 317/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5117 - mean_absolute_error: 2.4501 - mean_squared_error: 9.5117 - val_loss: 11.9566 - val_mean_absolute_error: 2.8171 - val_mean_squared_error: 11.9566\n",
      "Epoch 318/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4926 - mean_absolute_error: 2.4484 - mean_squared_error: 9.4926 - val_loss: 12.0480 - val_mean_absolute_error: 2.8091 - val_mean_squared_error: 12.0480\n",
      "Epoch 319/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4909 - mean_absolute_error: 2.4467 - mean_squared_error: 9.4909 - val_loss: 12.0096 - val_mean_absolute_error: 2.8098 - val_mean_squared_error: 12.0096\n",
      "Epoch 320/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4847 - mean_absolute_error: 2.4460 - mean_squared_error: 9.4847 - val_loss: 11.9888 - val_mean_absolute_error: 2.8099 - val_mean_squared_error: 11.9888\n",
      "Epoch 321/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4976 - mean_absolute_error: 2.4470 - mean_squared_error: 9.4976 - val_loss: 11.9406 - val_mean_absolute_error: 2.8130 - val_mean_squared_error: 11.9406\n",
      "Epoch 322/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4833 - mean_absolute_error: 2.4457 - mean_squared_error: 9.4833 - val_loss: 11.9624 - val_mean_absolute_error: 2.8094 - val_mean_squared_error: 11.9624\n",
      "Epoch 323/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4793 - mean_absolute_error: 2.4438 - mean_squared_error: 9.4793 - val_loss: 11.9274 - val_mean_absolute_error: 2.8116 - val_mean_squared_error: 11.9274\n",
      "Epoch 324/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4671 - mean_absolute_error: 2.4435 - mean_squared_error: 9.4671 - val_loss: 11.9630 - val_mean_absolute_error: 2.8070 - val_mean_squared_error: 11.9630\n",
      "Epoch 325/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4637 - mean_absolute_error: 2.4427 - mean_squared_error: 9.4637 - val_loss: 12.0066 - val_mean_absolute_error: 2.8037 - val_mean_squared_error: 12.0066\n",
      "Epoch 326/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4610 - mean_absolute_error: 2.4407 - mean_squared_error: 9.4610 - val_loss: 11.9070 - val_mean_absolute_error: 2.8097 - val_mean_squared_error: 11.9070\n",
      "Epoch 327/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4647 - mean_absolute_error: 2.4434 - mean_squared_error: 9.4647 - val_loss: 12.0210 - val_mean_absolute_error: 2.8013 - val_mean_squared_error: 12.0210\n",
      "Epoch 328/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.5123 - mean_absolute_error: 2.4494 - mean_squared_error: 9.5123 - val_loss: 12.1152 - val_mean_absolute_error: 2.7990 - val_mean_squared_error: 12.1152\n",
      "Epoch 329/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4605 - mean_absolute_error: 2.4398 - mean_squared_error: 9.4605 - val_loss: 11.9110 - val_mean_absolute_error: 2.8052 - val_mean_squared_error: 11.9110\n",
      "Epoch 330/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4496 - mean_absolute_error: 2.4399 - mean_squared_error: 9.4496 - val_loss: 11.9087 - val_mean_absolute_error: 2.8042 - val_mean_squared_error: 11.9087\n",
      "Epoch 331/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4358 - mean_absolute_error: 2.4363 - mean_squared_error: 9.4358 - val_loss: 11.8216 - val_mean_absolute_error: 2.8167 - val_mean_squared_error: 11.8216\n",
      "Epoch 332/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4302 - mean_absolute_error: 2.4379 - mean_squared_error: 9.4302 - val_loss: 11.8916 - val_mean_absolute_error: 2.8033 - val_mean_squared_error: 11.8916\n",
      "Epoch 333/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4266 - mean_absolute_error: 2.4352 - mean_squared_error: 9.4266 - val_loss: 11.8346 - val_mean_absolute_error: 2.8097 - val_mean_squared_error: 11.8346\n",
      "Epoch 334/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4283 - mean_absolute_error: 2.4375 - mean_squared_error: 9.4283 - val_loss: 11.9203 - val_mean_absolute_error: 2.7989 - val_mean_squared_error: 11.9203\n",
      "Epoch 335/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4158 - mean_absolute_error: 2.4333 - mean_squared_error: 9.4158 - val_loss: 11.8209 - val_mean_absolute_error: 2.8089 - val_mean_squared_error: 11.8209\n",
      "Epoch 336/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4101 - mean_absolute_error: 2.4343 - mean_squared_error: 9.4101 - val_loss: 11.8945 - val_mean_absolute_error: 2.7985 - val_mean_squared_error: 11.8945\n",
      "Epoch 337/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4096 - mean_absolute_error: 2.4327 - mean_squared_error: 9.4096 - val_loss: 11.8679 - val_mean_absolute_error: 2.7995 - val_mean_squared_error: 11.8679\n",
      "Epoch 338/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4021 - mean_absolute_error: 2.4323 - mean_squared_error: 9.4021 - val_loss: 11.9032 - val_mean_absolute_error: 2.7959 - val_mean_squared_error: 11.9032\n",
      "Epoch 339/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.4056 - mean_absolute_error: 2.4303 - mean_squared_error: 9.4056 - val_loss: 11.7679 - val_mean_absolute_error: 2.8147 - val_mean_squared_error: 11.7679\n",
      "Epoch 340/10000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 9.4038 - mean_absolute_error: 2.4315 - mean_squared_error: 9.4038 - val_loss: 11.7867 - val_mean_absolute_error: 2.8070 - val_mean_squared_error: 11.7867\n",
      "Epoch 341/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3975 - mean_absolute_error: 2.4338 - mean_squared_error: 9.3975 - val_loss: 11.9848 - val_mean_absolute_error: 2.7902 - val_mean_squared_error: 11.9848\n",
      "Epoch 342/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3945 - mean_absolute_error: 2.4297 - mean_squared_error: 9.3945 - val_loss: 11.8544 - val_mean_absolute_error: 2.7950 - val_mean_squared_error: 11.8544\n",
      "Epoch 343/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3825 - mean_absolute_error: 2.4271 - mean_squared_error: 9.3825 - val_loss: 11.7633 - val_mean_absolute_error: 2.8069 - val_mean_squared_error: 11.7633\n",
      "Epoch 344/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3883 - mean_absolute_error: 2.4306 - mean_squared_error: 9.3883 - val_loss: 11.8635 - val_mean_absolute_error: 2.7923 - val_mean_squared_error: 11.8635\n",
      "Epoch 345/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3754 - mean_absolute_error: 2.4270 - mean_squared_error: 9.3754 - val_loss: 11.8136 - val_mean_absolute_error: 2.7953 - val_mean_squared_error: 11.8136\n",
      "Epoch 346/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3681 - mean_absolute_error: 2.4264 - mean_squared_error: 9.3681 - val_loss: 11.8071 - val_mean_absolute_error: 2.7948 - val_mean_squared_error: 11.8071\n",
      "Epoch 347/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3656 - mean_absolute_error: 2.4270 - mean_squared_error: 9.3656 - val_loss: 11.9771 - val_mean_absolute_error: 2.7859 - val_mean_squared_error: 11.9771\n",
      "Epoch 348/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3637 - mean_absolute_error: 2.4238 - mean_squared_error: 9.3637 - val_loss: 11.7984 - val_mean_absolute_error: 2.7934 - val_mean_squared_error: 11.7984\n",
      "Epoch 349/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3677 - mean_absolute_error: 2.4262 - mean_squared_error: 9.3677 - val_loss: 11.8758 - val_mean_absolute_error: 2.7869 - val_mean_squared_error: 11.8758\n",
      "Epoch 350/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3528 - mean_absolute_error: 2.4235 - mean_squared_error: 9.3528 - val_loss: 11.8379 - val_mean_absolute_error: 2.7880 - val_mean_squared_error: 11.8379\n",
      "Epoch 351/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3540 - mean_absolute_error: 2.4241 - mean_squared_error: 9.3540 - val_loss: 11.8471 - val_mean_absolute_error: 2.7865 - val_mean_squared_error: 11.8471\n",
      "Epoch 352/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3534 - mean_absolute_error: 2.4219 - mean_squared_error: 9.3534 - val_loss: 11.7194 - val_mean_absolute_error: 2.8007 - val_mean_squared_error: 11.7194\n",
      "Epoch 353/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3590 - mean_absolute_error: 2.4254 - mean_squared_error: 9.3590 - val_loss: 11.9432 - val_mean_absolute_error: 2.7821 - val_mean_squared_error: 11.9432\n",
      "Epoch 354/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3360 - mean_absolute_error: 2.4193 - mean_squared_error: 9.3360 - val_loss: 11.7813 - val_mean_absolute_error: 2.7884 - val_mean_squared_error: 11.7813\n",
      "Epoch 355/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3525 - mean_absolute_error: 2.4247 - mean_squared_error: 9.3525 - val_loss: 11.8683 - val_mean_absolute_error: 2.7822 - val_mean_squared_error: 11.8683\n",
      "Epoch 356/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3384 - mean_absolute_error: 2.4204 - mean_squared_error: 9.3384 - val_loss: 11.8312 - val_mean_absolute_error: 2.7829 - val_mean_squared_error: 11.8312\n",
      "Epoch 357/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3302 - mean_absolute_error: 2.4191 - mean_squared_error: 9.3302 - val_loss: 11.7598 - val_mean_absolute_error: 2.7873 - val_mean_squared_error: 11.7598\n",
      "Epoch 358/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3309 - mean_absolute_error: 2.4210 - mean_squared_error: 9.3309 - val_loss: 11.8663 - val_mean_absolute_error: 2.7800 - val_mean_squared_error: 11.8663\n",
      "Epoch 359/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3171 - mean_absolute_error: 2.4176 - mean_squared_error: 9.3171 - val_loss: 11.8704 - val_mean_absolute_error: 2.7791 - val_mean_squared_error: 11.8704\n",
      "Epoch 360/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3174 - mean_absolute_error: 2.4177 - mean_squared_error: 9.3174 - val_loss: 11.8726 - val_mean_absolute_error: 2.7784 - val_mean_squared_error: 11.8726\n",
      "Epoch 361/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3228 - mean_absolute_error: 2.4181 - mean_squared_error: 9.3228 - val_loss: 11.8500 - val_mean_absolute_error: 2.7782 - val_mean_squared_error: 11.8500\n",
      "Epoch 362/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3191 - mean_absolute_error: 2.4164 - mean_squared_error: 9.3191 - val_loss: 11.8152 - val_mean_absolute_error: 2.7786 - val_mean_squared_error: 11.8152\n",
      "Epoch 363/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3029 - mean_absolute_error: 2.4141 - mean_squared_error: 9.3029 - val_loss: 11.7209 - val_mean_absolute_error: 2.7849 - val_mean_squared_error: 11.7209\n",
      "Epoch 364/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3047 - mean_absolute_error: 2.4162 - mean_squared_error: 9.3047 - val_loss: 11.8264 - val_mean_absolute_error: 2.7767 - val_mean_squared_error: 11.8264\n",
      "Epoch 365/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3225 - mean_absolute_error: 2.4166 - mean_squared_error: 9.3225 - val_loss: 11.7325 - val_mean_absolute_error: 2.7816 - val_mean_squared_error: 11.7325\n",
      "Epoch 366/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.3263 - mean_absolute_error: 2.4183 - mean_squared_error: 9.3263 - val_loss: 11.7553 - val_mean_absolute_error: 2.7787 - val_mean_squared_error: 11.7553\n",
      "Epoch 367/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2946 - mean_absolute_error: 2.4133 - mean_squared_error: 9.2946 - val_loss: 11.6723 - val_mean_absolute_error: 2.7868 - val_mean_squared_error: 11.6723\n",
      "Epoch 368/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2996 - mean_absolute_error: 2.4150 - mean_squared_error: 9.2996 - val_loss: 11.7491 - val_mean_absolute_error: 2.7774 - val_mean_squared_error: 11.7491\n",
      "Epoch 369/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2829 - mean_absolute_error: 2.4112 - mean_squared_error: 9.2829 - val_loss: 11.6926 - val_mean_absolute_error: 2.7815 - val_mean_squared_error: 11.6926\n",
      "Epoch 370/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2871 - mean_absolute_error: 2.4121 - mean_squared_error: 9.2871 - val_loss: 11.6921 - val_mean_absolute_error: 2.7805 - val_mean_squared_error: 11.6921\n",
      "Epoch 371/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2786 - mean_absolute_error: 2.4111 - mean_squared_error: 9.2786 - val_loss: 11.7261 - val_mean_absolute_error: 2.7764 - val_mean_squared_error: 11.7261\n",
      "Epoch 372/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2867 - mean_absolute_error: 2.4125 - mean_squared_error: 9.2867 - val_loss: 11.8381 - val_mean_absolute_error: 2.7711 - val_mean_squared_error: 11.8381\n",
      "Epoch 373/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2898 - mean_absolute_error: 2.4119 - mean_squared_error: 9.2898 - val_loss: 11.7829 - val_mean_absolute_error: 2.7716 - val_mean_squared_error: 11.7829\n",
      "Epoch 374/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2663 - mean_absolute_error: 2.4067 - mean_squared_error: 9.2663 - val_loss: 11.6159 - val_mean_absolute_error: 2.7886 - val_mean_squared_error: 11.6159\n",
      "Epoch 375/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2892 - mean_absolute_error: 2.4154 - mean_squared_error: 9.2892 - val_loss: 11.7594 - val_mean_absolute_error: 2.7711 - val_mean_squared_error: 11.7594\n",
      "Epoch 376/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2590 - mean_absolute_error: 2.4063 - mean_squared_error: 9.2590 - val_loss: 11.6499 - val_mean_absolute_error: 2.7792 - val_mean_squared_error: 11.6499\n",
      "Epoch 377/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2586 - mean_absolute_error: 2.4089 - mean_squared_error: 9.2586 - val_loss: 11.7181 - val_mean_absolute_error: 2.7719 - val_mean_squared_error: 11.7181\n",
      "Epoch 378/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2763 - mean_absolute_error: 2.4097 - mean_squared_error: 9.2763 - val_loss: 11.6965 - val_mean_absolute_error: 2.7725 - val_mean_squared_error: 11.6965\n",
      "Epoch 379/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2590 - mean_absolute_error: 2.4063 - mean_squared_error: 9.2590 - val_loss: 11.6618 - val_mean_absolute_error: 2.7746 - val_mean_squared_error: 11.6618\n",
      "Epoch 380/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2592 - mean_absolute_error: 2.4076 - mean_squared_error: 9.2592 - val_loss: 11.6862 - val_mean_absolute_error: 2.7716 - val_mean_squared_error: 11.6862\n",
      "Epoch 381/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2424 - mean_absolute_error: 2.4040 - mean_squared_error: 9.2424 - val_loss: 11.6350 - val_mean_absolute_error: 2.7757 - val_mean_squared_error: 11.6350\n",
      "Epoch 382/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2420 - mean_absolute_error: 2.4052 - mean_squared_error: 9.2420 - val_loss: 11.6999 - val_mean_absolute_error: 2.7690 - val_mean_squared_error: 11.6999\n",
      "Epoch 383/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2420 - mean_absolute_error: 2.4052 - mean_squared_error: 9.2420 - val_loss: 11.7502 - val_mean_absolute_error: 2.7660 - val_mean_squared_error: 11.7502\n",
      "Epoch 384/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2540 - mean_absolute_error: 2.4062 - mean_squared_error: 9.2540 - val_loss: 11.7153 - val_mean_absolute_error: 2.7666 - val_mean_squared_error: 11.7153\n",
      "Epoch 385/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2369 - mean_absolute_error: 2.4037 - mean_squared_error: 9.2369 - val_loss: 11.7838 - val_mean_absolute_error: 2.7641 - val_mean_squared_error: 11.7838\n",
      "Epoch 386/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2351 - mean_absolute_error: 2.4027 - mean_squared_error: 9.2351 - val_loss: 11.7120 - val_mean_absolute_error: 2.7654 - val_mean_squared_error: 11.7120\n",
      "Epoch 387/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2225 - mean_absolute_error: 2.4007 - mean_squared_error: 9.2225 - val_loss: 11.6613 - val_mean_absolute_error: 2.7676 - val_mean_squared_error: 11.6613\n",
      "Epoch 388/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2287 - mean_absolute_error: 2.4017 - mean_squared_error: 9.2287 - val_loss: 11.6459 - val_mean_absolute_error: 2.7680 - val_mean_squared_error: 11.6459\n",
      "Epoch 389/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2411 - mean_absolute_error: 2.4026 - mean_squared_error: 9.2411 - val_loss: 11.6447 - val_mean_absolute_error: 2.7673 - val_mean_squared_error: 11.6447\n",
      "Epoch 390/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2143 - mean_absolute_error: 2.3994 - mean_squared_error: 9.2143 - val_loss: 11.5941 - val_mean_absolute_error: 2.7716 - val_mean_squared_error: 11.5941\n",
      "Epoch 391/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2103 - mean_absolute_error: 2.3989 - mean_squared_error: 9.2103 - val_loss: 11.5955 - val_mean_absolute_error: 2.7705 - val_mean_squared_error: 11.5955\n",
      "Epoch 392/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2132 - mean_absolute_error: 2.3996 - mean_squared_error: 9.2132 - val_loss: 11.5792 - val_mean_absolute_error: 2.7716 - val_mean_squared_error: 11.5792\n",
      "Epoch 393/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2042 - mean_absolute_error: 2.3985 - mean_squared_error: 9.2042 - val_loss: 11.5981 - val_mean_absolute_error: 2.7683 - val_mean_squared_error: 11.5981\n",
      "Epoch 394/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2071 - mean_absolute_error: 2.3989 - mean_squared_error: 9.2071 - val_loss: 11.6381 - val_mean_absolute_error: 2.7639 - val_mean_squared_error: 11.6381\n",
      "Epoch 395/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2146 - mean_absolute_error: 2.4005 - mean_squared_error: 9.2146 - val_loss: 11.7445 - val_mean_absolute_error: 2.7592 - val_mean_squared_error: 11.7445\n",
      "Epoch 396/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2021 - mean_absolute_error: 2.3943 - mean_squared_error: 9.2021 - val_loss: 11.5325 - val_mean_absolute_error: 2.7761 - val_mean_squared_error: 11.5325\n",
      "Epoch 397/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1999 - mean_absolute_error: 2.3961 - mean_squared_error: 9.1999 - val_loss: 11.5458 - val_mean_absolute_error: 2.7717 - val_mean_squared_error: 11.5458\n",
      "Epoch 398/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2004 - mean_absolute_error: 2.3956 - mean_squared_error: 9.2004 - val_loss: 11.5057 - val_mean_absolute_error: 2.7828 - val_mean_squared_error: 11.5057\n",
      "Epoch 399/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2204 - mean_absolute_error: 2.4020 - mean_squared_error: 9.2204 - val_loss: 11.6527 - val_mean_absolute_error: 2.7594 - val_mean_squared_error: 11.6527\n",
      "Epoch 400/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1915 - mean_absolute_error: 2.3940 - mean_squared_error: 9.1915 - val_loss: 11.5316 - val_mean_absolute_error: 2.7709 - val_mean_squared_error: 11.5316\n",
      "Epoch 401/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2063 - mean_absolute_error: 2.3981 - mean_squared_error: 9.2063 - val_loss: 11.6935 - val_mean_absolute_error: 2.7568 - val_mean_squared_error: 11.6935\n",
      "Epoch 402/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.2096 - mean_absolute_error: 2.3963 - mean_squared_error: 9.2096 - val_loss: 11.5755 - val_mean_absolute_error: 2.7628 - val_mean_squared_error: 11.5755\n",
      "Epoch 403/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1726 - mean_absolute_error: 2.3928 - mean_squared_error: 9.1726 - val_loss: 11.5803 - val_mean_absolute_error: 2.7615 - val_mean_squared_error: 11.5803\n",
      "Epoch 404/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1733 - mean_absolute_error: 2.3934 - mean_squared_error: 9.1733 - val_loss: 11.6458 - val_mean_absolute_error: 2.7566 - val_mean_squared_error: 11.6458\n",
      "Epoch 405/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1728 - mean_absolute_error: 2.3922 - mean_squared_error: 9.1728 - val_loss: 11.6130 - val_mean_absolute_error: 2.7576 - val_mean_squared_error: 11.6130\n",
      "Epoch 406/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1669 - mean_absolute_error: 2.3909 - mean_squared_error: 9.1669 - val_loss: 11.5647 - val_mean_absolute_error: 2.7606 - val_mean_squared_error: 11.5647\n",
      "Epoch 407/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1794 - mean_absolute_error: 2.3930 - mean_squared_error: 9.1794 - val_loss: 11.5794 - val_mean_absolute_error: 2.7585 - val_mean_squared_error: 11.5794\n",
      "Epoch 408/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1686 - mean_absolute_error: 2.3913 - mean_squared_error: 9.1686 - val_loss: 11.5459 - val_mean_absolute_error: 2.7609 - val_mean_squared_error: 11.5459\n",
      "Epoch 409/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1593 - mean_absolute_error: 2.3904 - mean_squared_error: 9.1593 - val_loss: 11.5213 - val_mean_absolute_error: 2.7630 - val_mean_squared_error: 11.5213\n",
      "Epoch 410/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1657 - mean_absolute_error: 2.3936 - mean_squared_error: 9.1657 - val_loss: 11.7166 - val_mean_absolute_error: 2.7519 - val_mean_squared_error: 11.7166\n",
      "Epoch 411/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1682 - mean_absolute_error: 2.3897 - mean_squared_error: 9.1682 - val_loss: 11.6084 - val_mean_absolute_error: 2.7541 - val_mean_squared_error: 11.6084\n",
      "Epoch 412/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1494 - mean_absolute_error: 2.3881 - mean_squared_error: 9.1494 - val_loss: 11.5567 - val_mean_absolute_error: 2.7567 - val_mean_squared_error: 11.5567\n",
      "Epoch 413/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1443 - mean_absolute_error: 2.3875 - mean_squared_error: 9.1443 - val_loss: 11.5304 - val_mean_absolute_error: 2.7585 - val_mean_squared_error: 11.5304\n",
      "Epoch 414/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1611 - mean_absolute_error: 2.3920 - mean_squared_error: 9.1611 - val_loss: 11.7802 - val_mean_absolute_error: 2.7503 - val_mean_squared_error: 11.7802\n",
      "Epoch 415/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1614 - mean_absolute_error: 2.3870 - mean_squared_error: 9.1614 - val_loss: 11.5113 - val_mean_absolute_error: 2.7590 - val_mean_squared_error: 11.5113\n",
      "Epoch 416/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1730 - mean_absolute_error: 2.3908 - mean_squared_error: 9.1730 - val_loss: 11.4837 - val_mean_absolute_error: 2.7622 - val_mean_squared_error: 11.4837\n",
      "Epoch 417/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1406 - mean_absolute_error: 2.3870 - mean_squared_error: 9.1406 - val_loss: 11.4879 - val_mean_absolute_error: 2.7605 - val_mean_squared_error: 11.4879\n",
      "Epoch 418/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1389 - mean_absolute_error: 2.3860 - mean_squared_error: 9.1389 - val_loss: 11.4697 - val_mean_absolute_error: 2.7627 - val_mean_squared_error: 11.4697\n",
      "Epoch 419/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1354 - mean_absolute_error: 2.3876 - mean_squared_error: 9.1354 - val_loss: 11.5679 - val_mean_absolute_error: 2.7514 - val_mean_squared_error: 11.5679\n",
      "Epoch 420/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1339 - mean_absolute_error: 2.3850 - mean_squared_error: 9.1339 - val_loss: 11.4987 - val_mean_absolute_error: 2.7564 - val_mean_squared_error: 11.4987\n",
      "Epoch 421/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1446 - mean_absolute_error: 2.3877 - mean_squared_error: 9.1446 - val_loss: 11.5296 - val_mean_absolute_error: 2.7526 - val_mean_squared_error: 11.5296\n",
      "Epoch 422/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1325 - mean_absolute_error: 2.3851 - mean_squared_error: 9.1325 - val_loss: 11.4906 - val_mean_absolute_error: 2.7558 - val_mean_squared_error: 11.4906\n",
      "Epoch 423/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1335 - mean_absolute_error: 2.3869 - mean_squared_error: 9.1335 - val_loss: 11.5607 - val_mean_absolute_error: 2.7494 - val_mean_squared_error: 11.5607\n",
      "Epoch 424/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1228 - mean_absolute_error: 2.3827 - mean_squared_error: 9.1228 - val_loss: 11.5198 - val_mean_absolute_error: 2.7514 - val_mean_squared_error: 11.5198\n",
      "Epoch 425/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1177 - mean_absolute_error: 2.3825 - mean_squared_error: 9.1177 - val_loss: 11.4911 - val_mean_absolute_error: 2.7534 - val_mean_squared_error: 11.4911\n",
      "Epoch 426/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1177 - mean_absolute_error: 2.3835 - mean_squared_error: 9.1177 - val_loss: 11.5418 - val_mean_absolute_error: 2.7487 - val_mean_squared_error: 11.5418\n",
      "Epoch 427/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1133 - mean_absolute_error: 2.3823 - mean_squared_error: 9.1133 - val_loss: 11.5285 - val_mean_absolute_error: 2.7489 - val_mean_squared_error: 11.5285\n",
      "Epoch 428/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1095 - mean_absolute_error: 2.3804 - mean_squared_error: 9.1095 - val_loss: 11.4730 - val_mean_absolute_error: 2.7532 - val_mean_squared_error: 11.4730\n",
      "Epoch 429/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1306 - mean_absolute_error: 2.3842 - mean_squared_error: 9.1306 - val_loss: 11.5193 - val_mean_absolute_error: 2.7484 - val_mean_squared_error: 11.5193\n",
      "Epoch 430/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1116 - mean_absolute_error: 2.3821 - mean_squared_error: 9.1116 - val_loss: 11.5653 - val_mean_absolute_error: 2.7454 - val_mean_squared_error: 11.5653\n",
      "Epoch 431/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1357 - mean_absolute_error: 2.3848 - mean_squared_error: 9.1357 - val_loss: 11.5199 - val_mean_absolute_error: 2.7471 - val_mean_squared_error: 11.5199\n",
      "Epoch 432/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1030 - mean_absolute_error: 2.3792 - mean_squared_error: 9.1030 - val_loss: 11.4589 - val_mean_absolute_error: 2.7518 - val_mean_squared_error: 11.4589\n",
      "Epoch 433/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1042 - mean_absolute_error: 2.3804 - mean_squared_error: 9.1042 - val_loss: 11.4853 - val_mean_absolute_error: 2.7484 - val_mean_squared_error: 11.4853\n",
      "Epoch 434/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1095 - mean_absolute_error: 2.3787 - mean_squared_error: 9.1095 - val_loss: 11.4498 - val_mean_absolute_error: 2.7514 - val_mean_squared_error: 11.4498\n",
      "Epoch 435/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1192 - mean_absolute_error: 2.3849 - mean_squared_error: 9.1192 - val_loss: 11.6988 - val_mean_absolute_error: 2.7416 - val_mean_squared_error: 11.6988\n",
      "Epoch 436/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1128 - mean_absolute_error: 2.3777 - mean_squared_error: 9.1128 - val_loss: 11.4712 - val_mean_absolute_error: 2.7477 - val_mean_squared_error: 11.4712\n",
      "Epoch 437/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0903 - mean_absolute_error: 2.3780 - mean_squared_error: 9.0903 - val_loss: 11.4668 - val_mean_absolute_error: 2.7475 - val_mean_squared_error: 11.4668\n",
      "Epoch 438/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0854 - mean_absolute_error: 2.3775 - mean_squared_error: 9.0854 - val_loss: 11.4667 - val_mean_absolute_error: 2.7468 - val_mean_squared_error: 11.4667\n",
      "Epoch 439/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0939 - mean_absolute_error: 2.3784 - mean_squared_error: 9.0939 - val_loss: 11.4577 - val_mean_absolute_error: 2.7470 - val_mean_squared_error: 11.4577\n",
      "Epoch 440/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0918 - mean_absolute_error: 2.3774 - mean_squared_error: 9.0918 - val_loss: 11.4041 - val_mean_absolute_error: 2.7535 - val_mean_squared_error: 11.4041\n",
      "Epoch 441/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.1035 - mean_absolute_error: 2.3822 - mean_squared_error: 9.1035 - val_loss: 11.5667 - val_mean_absolute_error: 2.7401 - val_mean_squared_error: 11.5667\n",
      "Epoch 442/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0786 - mean_absolute_error: 2.3760 - mean_squared_error: 9.0786 - val_loss: 11.5791 - val_mean_absolute_error: 2.7393 - val_mean_squared_error: 11.5791\n",
      "Epoch 443/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0794 - mean_absolute_error: 2.3750 - mean_squared_error: 9.0794 - val_loss: 11.4773 - val_mean_absolute_error: 2.7431 - val_mean_squared_error: 11.4773\n",
      "Epoch 444/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0925 - mean_absolute_error: 2.3773 - mean_squared_error: 9.0925 - val_loss: 11.4821 - val_mean_absolute_error: 2.7422 - val_mean_squared_error: 11.4821\n",
      "Epoch 445/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0685 - mean_absolute_error: 2.3750 - mean_squared_error: 9.0685 - val_loss: 11.5337 - val_mean_absolute_error: 2.7392 - val_mean_squared_error: 11.5337\n",
      "Epoch 446/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0706 - mean_absolute_error: 2.3750 - mean_squared_error: 9.0706 - val_loss: 11.5407 - val_mean_absolute_error: 2.7386 - val_mean_squared_error: 11.5407\n",
      "Epoch 447/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0671 - mean_absolute_error: 2.3732 - mean_squared_error: 9.0671 - val_loss: 11.4895 - val_mean_absolute_error: 2.7402 - val_mean_squared_error: 11.4895\n",
      "Epoch 448/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0632 - mean_absolute_error: 2.3724 - mean_squared_error: 9.0632 - val_loss: 11.4295 - val_mean_absolute_error: 2.7440 - val_mean_squared_error: 11.4295\n",
      "Epoch 449/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0615 - mean_absolute_error: 2.3737 - mean_squared_error: 9.0615 - val_loss: 11.4646 - val_mean_absolute_error: 2.7406 - val_mean_squared_error: 11.4646\n",
      "Epoch 450/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0652 - mean_absolute_error: 2.3723 - mean_squared_error: 9.0652 - val_loss: 11.4170 - val_mean_absolute_error: 2.7440 - val_mean_squared_error: 11.4170\n",
      "Epoch 451/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0662 - mean_absolute_error: 2.3740 - mean_squared_error: 9.0662 - val_loss: 11.4983 - val_mean_absolute_error: 2.7378 - val_mean_squared_error: 11.4983\n",
      "Epoch 452/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0598 - mean_absolute_error: 2.3731 - mean_squared_error: 9.0598 - val_loss: 11.6449 - val_mean_absolute_error: 2.7352 - val_mean_squared_error: 11.6449\n",
      "Epoch 453/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0713 - mean_absolute_error: 2.3700 - mean_squared_error: 9.0713 - val_loss: 11.3430 - val_mean_absolute_error: 2.7556 - val_mean_squared_error: 11.3430\n",
      "Epoch 454/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0680 - mean_absolute_error: 2.3750 - mean_squared_error: 9.0680 - val_loss: 11.4138 - val_mean_absolute_error: 2.7419 - val_mean_squared_error: 11.4138\n",
      "Epoch 455/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0517 - mean_absolute_error: 2.3722 - mean_squared_error: 9.0517 - val_loss: 11.5148 - val_mean_absolute_error: 2.7354 - val_mean_squared_error: 11.5148\n",
      "Epoch 456/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0605 - mean_absolute_error: 2.3711 - mean_squared_error: 9.0605 - val_loss: 11.3888 - val_mean_absolute_error: 2.7434 - val_mean_squared_error: 11.3888\n",
      "Epoch 457/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0435 - mean_absolute_error: 2.3703 - mean_squared_error: 9.0435 - val_loss: 11.4392 - val_mean_absolute_error: 2.7381 - val_mean_squared_error: 11.4392\n",
      "Epoch 458/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0416 - mean_absolute_error: 2.3690 - mean_squared_error: 9.0416 - val_loss: 11.4114 - val_mean_absolute_error: 2.7398 - val_mean_squared_error: 11.4114\n",
      "Epoch 459/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0393 - mean_absolute_error: 2.3702 - mean_squared_error: 9.0393 - val_loss: 11.5026 - val_mean_absolute_error: 2.7341 - val_mean_squared_error: 11.5026\n",
      "Epoch 460/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0551 - mean_absolute_error: 2.3678 - mean_squared_error: 9.0551 - val_loss: 11.3312 - val_mean_absolute_error: 2.7508 - val_mean_squared_error: 11.3312\n",
      "Epoch 461/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0510 - mean_absolute_error: 2.3737 - mean_squared_error: 9.0510 - val_loss: 11.4960 - val_mean_absolute_error: 2.7334 - val_mean_squared_error: 11.4960\n",
      "Epoch 462/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0418 - mean_absolute_error: 2.3668 - mean_squared_error: 9.0418 - val_loss: 11.3327 - val_mean_absolute_error: 2.7483 - val_mean_squared_error: 11.3327\n",
      "Epoch 463/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0569 - mean_absolute_error: 2.3722 - mean_squared_error: 9.0569 - val_loss: 11.3783 - val_mean_absolute_error: 2.7401 - val_mean_squared_error: 11.3783\n",
      "Epoch 464/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0373 - mean_absolute_error: 2.3685 - mean_squared_error: 9.0373 - val_loss: 11.3917 - val_mean_absolute_error: 2.7382 - val_mean_squared_error: 11.3917\n",
      "Epoch 465/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0504 - mean_absolute_error: 2.3728 - mean_squared_error: 9.0504 - val_loss: 11.6424 - val_mean_absolute_error: 2.7309 - val_mean_squared_error: 11.6424\n",
      "Epoch 466/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0739 - mean_absolute_error: 2.3704 - mean_squared_error: 9.0739 - val_loss: 11.4340 - val_mean_absolute_error: 2.7340 - val_mean_squared_error: 11.4340\n",
      "Epoch 467/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0260 - mean_absolute_error: 2.3668 - mean_squared_error: 9.0260 - val_loss: 11.4436 - val_mean_absolute_error: 2.7330 - val_mean_squared_error: 11.4436\n",
      "Epoch 468/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0392 - mean_absolute_error: 2.3665 - mean_squared_error: 9.0392 - val_loss: 11.3403 - val_mean_absolute_error: 2.7419 - val_mean_squared_error: 11.3403\n",
      "Epoch 469/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0234 - mean_absolute_error: 2.3679 - mean_squared_error: 9.0234 - val_loss: 11.4429 - val_mean_absolute_error: 2.7322 - val_mean_squared_error: 11.4429\n",
      "Epoch 470/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0268 - mean_absolute_error: 2.3665 - mean_squared_error: 9.0268 - val_loss: 11.4056 - val_mean_absolute_error: 2.7339 - val_mean_squared_error: 11.4056\n",
      "Epoch 471/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0221 - mean_absolute_error: 2.3642 - mean_squared_error: 9.0221 - val_loss: 11.3179 - val_mean_absolute_error: 2.7436 - val_mean_squared_error: 11.3179\n",
      "Epoch 472/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0229 - mean_absolute_error: 2.3689 - mean_squared_error: 9.0229 - val_loss: 11.5730 - val_mean_absolute_error: 2.7284 - val_mean_squared_error: 11.5730\n",
      "Epoch 473/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0444 - mean_absolute_error: 2.3673 - mean_squared_error: 9.0444 - val_loss: 11.4424 - val_mean_absolute_error: 2.7305 - val_mean_squared_error: 11.4424\n",
      "Epoch 474/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0142 - mean_absolute_error: 2.3641 - mean_squared_error: 9.0142 - val_loss: 11.3899 - val_mean_absolute_error: 2.7331 - val_mean_squared_error: 11.3899\n",
      "Epoch 475/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0215 - mean_absolute_error: 2.3655 - mean_squared_error: 9.0215 - val_loss: 11.4430 - val_mean_absolute_error: 2.7296 - val_mean_squared_error: 11.4430\n",
      "Epoch 476/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0090 - mean_absolute_error: 2.3616 - mean_squared_error: 9.0090 - val_loss: 11.3457 - val_mean_absolute_error: 2.7361 - val_mean_squared_error: 11.3457\n",
      "Epoch 477/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0124 - mean_absolute_error: 2.3641 - mean_squared_error: 9.0124 - val_loss: 11.3518 - val_mean_absolute_error: 2.7349 - val_mean_squared_error: 11.3518\n",
      "Epoch 478/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0037 - mean_absolute_error: 2.3629 - mean_squared_error: 9.0037 - val_loss: 11.3663 - val_mean_absolute_error: 2.7330 - val_mean_squared_error: 11.3663\n",
      "Epoch 479/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0123 - mean_absolute_error: 2.3636 - mean_squared_error: 9.0123 - val_loss: 11.3472 - val_mean_absolute_error: 2.7342 - val_mean_squared_error: 11.3472\n",
      "Epoch 480/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0057 - mean_absolute_error: 2.3631 - mean_squared_error: 9.0057 - val_loss: 11.3742 - val_mean_absolute_error: 2.7314 - val_mean_squared_error: 11.3742\n",
      "Epoch 481/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0001 - mean_absolute_error: 2.3619 - mean_squared_error: 9.0001 - val_loss: 11.3899 - val_mean_absolute_error: 2.7299 - val_mean_squared_error: 11.3899\n",
      "Epoch 482/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0061 - mean_absolute_error: 2.3623 - mean_squared_error: 9.0061 - val_loss: 11.3998 - val_mean_absolute_error: 2.7289 - val_mean_squared_error: 11.3998\n",
      "Epoch 483/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0010 - mean_absolute_error: 2.3617 - mean_squared_error: 9.0010 - val_loss: 11.4185 - val_mean_absolute_error: 2.7274 - val_mean_squared_error: 11.4185\n",
      "Epoch 484/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0327 - mean_absolute_error: 2.3658 - mean_squared_error: 9.0327 - val_loss: 11.5813 - val_mean_absolute_error: 2.7247 - val_mean_squared_error: 11.5813\n",
      "Epoch 485/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0188 - mean_absolute_error: 2.3598 - mean_squared_error: 9.0188 - val_loss: 11.2865 - val_mean_absolute_error: 2.7392 - val_mean_squared_error: 11.2865\n",
      "Epoch 486/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0116 - mean_absolute_error: 2.3656 - mean_squared_error: 9.0116 - val_loss: 11.4660 - val_mean_absolute_error: 2.7249 - val_mean_squared_error: 11.4660\n",
      "Epoch 487/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0131 - mean_absolute_error: 2.3617 - mean_squared_error: 9.0131 - val_loss: 11.3384 - val_mean_absolute_error: 2.7310 - val_mean_squared_error: 11.3384\n",
      "Epoch 488/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0021 - mean_absolute_error: 2.3623 - mean_squared_error: 9.0021 - val_loss: 11.4241 - val_mean_absolute_error: 2.7253 - val_mean_squared_error: 11.4241\n",
      "Epoch 489/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0056 - mean_absolute_error: 2.3597 - mean_squared_error: 9.0056 - val_loss: 11.2823 - val_mean_absolute_error: 2.7371 - val_mean_squared_error: 11.2823\n",
      "Epoch 490/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9954 - mean_absolute_error: 2.3608 - mean_squared_error: 8.9954 - val_loss: 11.2723 - val_mean_absolute_error: 2.7385 - val_mean_squared_error: 11.2723\n",
      "Epoch 491/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0032 - mean_absolute_error: 2.3642 - mean_squared_error: 9.0032 - val_loss: 11.3717 - val_mean_absolute_error: 2.7268 - val_mean_squared_error: 11.3717\n",
      "Epoch 492/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9856 - mean_absolute_error: 2.3602 - mean_squared_error: 8.9856 - val_loss: 11.4605 - val_mean_absolute_error: 2.7230 - val_mean_squared_error: 11.4605\n",
      "Epoch 493/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9835 - mean_absolute_error: 2.3578 - mean_squared_error: 8.9835 - val_loss: 11.3823 - val_mean_absolute_error: 2.7253 - val_mean_squared_error: 11.3823\n",
      "Epoch 494/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 9.0028 - mean_absolute_error: 2.3596 - mean_squared_error: 9.0028 - val_loss: 11.2744 - val_mean_absolute_error: 2.7352 - val_mean_squared_error: 11.2744\n",
      "Epoch 495/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9843 - mean_absolute_error: 2.3591 - mean_squared_error: 8.9843 - val_loss: 11.3464 - val_mean_absolute_error: 2.7267 - val_mean_squared_error: 11.3464\n",
      "Epoch 496/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9752 - mean_absolute_error: 2.3576 - mean_squared_error: 8.9752 - val_loss: 11.4063 - val_mean_absolute_error: 2.7231 - val_mean_squared_error: 11.4063\n",
      "Epoch 497/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9818 - mean_absolute_error: 2.3576 - mean_squared_error: 8.9818 - val_loss: 11.3240 - val_mean_absolute_error: 2.7275 - val_mean_squared_error: 11.3240\n",
      "Epoch 498/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9760 - mean_absolute_error: 2.3577 - mean_squared_error: 8.9760 - val_loss: 11.3591 - val_mean_absolute_error: 2.7247 - val_mean_squared_error: 11.3591\n",
      "Epoch 499/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9779 - mean_absolute_error: 2.3564 - mean_squared_error: 8.9779 - val_loss: 11.3010 - val_mean_absolute_error: 2.7287 - val_mean_squared_error: 11.3010\n",
      "Epoch 500/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9740 - mean_absolute_error: 2.3567 - mean_squared_error: 8.9740 - val_loss: 11.2939 - val_mean_absolute_error: 2.7290 - val_mean_squared_error: 11.2939\n",
      "Epoch 501/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9672 - mean_absolute_error: 2.3563 - mean_squared_error: 8.9672 - val_loss: 11.3112 - val_mean_absolute_error: 2.7268 - val_mean_squared_error: 11.3112\n",
      "Epoch 502/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9633 - mean_absolute_error: 2.3562 - mean_squared_error: 8.9633 - val_loss: 11.3714 - val_mean_absolute_error: 2.7225 - val_mean_squared_error: 11.3714\n",
      "Epoch 503/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9629 - mean_absolute_error: 2.3547 - mean_squared_error: 8.9629 - val_loss: 11.3331 - val_mean_absolute_error: 2.7243 - val_mean_squared_error: 11.3331\n",
      "Epoch 504/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9627 - mean_absolute_error: 2.3561 - mean_squared_error: 8.9627 - val_loss: 11.3909 - val_mean_absolute_error: 2.7210 - val_mean_squared_error: 11.3909\n",
      "Epoch 505/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9728 - mean_absolute_error: 2.3547 - mean_squared_error: 8.9728 - val_loss: 11.2190 - val_mean_absolute_error: 2.7420 - val_mean_squared_error: 11.2190\n",
      "Epoch 506/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9712 - mean_absolute_error: 2.3588 - mean_squared_error: 8.9712 - val_loss: 11.4323 - val_mean_absolute_error: 2.7191 - val_mean_squared_error: 11.4323\n",
      "Epoch 507/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9688 - mean_absolute_error: 2.3560 - mean_squared_error: 8.9688 - val_loss: 11.4107 - val_mean_absolute_error: 2.7193 - val_mean_squared_error: 11.4107\n",
      "Epoch 508/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9647 - mean_absolute_error: 2.3527 - mean_squared_error: 8.9647 - val_loss: 11.2300 - val_mean_absolute_error: 2.7350 - val_mean_squared_error: 11.2300\n",
      "Epoch 509/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9622 - mean_absolute_error: 2.3565 - mean_squared_error: 8.9622 - val_loss: 11.3079 - val_mean_absolute_error: 2.7236 - val_mean_squared_error: 11.3079\n",
      "Epoch 510/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9522 - mean_absolute_error: 2.3536 - mean_squared_error: 8.9522 - val_loss: 11.2877 - val_mean_absolute_error: 2.7249 - val_mean_squared_error: 11.2877\n",
      "Epoch 511/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9749 - mean_absolute_error: 2.3571 - mean_squared_error: 8.9749 - val_loss: 11.3696 - val_mean_absolute_error: 2.7195 - val_mean_squared_error: 11.3696\n",
      "Epoch 512/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9561 - mean_absolute_error: 2.3546 - mean_squared_error: 8.9561 - val_loss: 11.4385 - val_mean_absolute_error: 2.7172 - val_mean_squared_error: 11.4385\n",
      "Epoch 513/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9568 - mean_absolute_error: 2.3519 - mean_squared_error: 8.9568 - val_loss: 11.2878 - val_mean_absolute_error: 2.7236 - val_mean_squared_error: 11.2878\n",
      "Epoch 514/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9530 - mean_absolute_error: 2.3529 - mean_squared_error: 8.9530 - val_loss: 11.2794 - val_mean_absolute_error: 2.7239 - val_mean_squared_error: 11.2794\n",
      "Epoch 515/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9493 - mean_absolute_error: 2.3521 - mean_squared_error: 8.9493 - val_loss: 11.2405 - val_mean_absolute_error: 2.7283 - val_mean_squared_error: 11.2405\n",
      "Epoch 516/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9552 - mean_absolute_error: 2.3532 - mean_squared_error: 8.9552 - val_loss: 11.2216 - val_mean_absolute_error: 2.7313 - val_mean_squared_error: 11.2216\n",
      "Epoch 517/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9471 - mean_absolute_error: 2.3521 - mean_squared_error: 8.9471 - val_loss: 11.2109 - val_mean_absolute_error: 2.7334 - val_mean_squared_error: 11.2109\n",
      "Epoch 518/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9464 - mean_absolute_error: 2.3518 - mean_squared_error: 8.9464 - val_loss: 11.2093 - val_mean_absolute_error: 2.7331 - val_mean_squared_error: 11.2093\n",
      "Epoch 519/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9489 - mean_absolute_error: 2.3562 - mean_squared_error: 8.9489 - val_loss: 11.4731 - val_mean_absolute_error: 2.7151 - val_mean_squared_error: 11.4731\n",
      "Epoch 520/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9689 - mean_absolute_error: 2.3533 - mean_squared_error: 8.9689 - val_loss: 11.2450 - val_mean_absolute_error: 2.7250 - val_mean_squared_error: 11.2450\n",
      "Epoch 521/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9343 - mean_absolute_error: 2.3526 - mean_squared_error: 8.9343 - val_loss: 11.4350 - val_mean_absolute_error: 2.7148 - val_mean_squared_error: 11.4350\n",
      "Epoch 522/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9370 - mean_absolute_error: 2.3495 - mean_squared_error: 8.9370 - val_loss: 11.3045 - val_mean_absolute_error: 2.7190 - val_mean_squared_error: 11.3045\n",
      "Epoch 523/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9403 - mean_absolute_error: 2.3507 - mean_squared_error: 8.9403 - val_loss: 11.2892 - val_mean_absolute_error: 2.7196 - val_mean_squared_error: 11.2892\n",
      "Epoch 524/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9340 - mean_absolute_error: 2.3505 - mean_squared_error: 8.9340 - val_loss: 11.3159 - val_mean_absolute_error: 2.7177 - val_mean_squared_error: 11.3159\n",
      "Epoch 525/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9336 - mean_absolute_error: 2.3491 - mean_squared_error: 8.9336 - val_loss: 11.2468 - val_mean_absolute_error: 2.7225 - val_mean_squared_error: 11.2468\n",
      "Epoch 526/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9348 - mean_absolute_error: 2.3509 - mean_squared_error: 8.9348 - val_loss: 11.3553 - val_mean_absolute_error: 2.7153 - val_mean_squared_error: 11.3553\n",
      "Epoch 527/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9314 - mean_absolute_error: 2.3496 - mean_squared_error: 8.9314 - val_loss: 11.3666 - val_mean_absolute_error: 2.7146 - val_mean_squared_error: 11.3666\n",
      "Epoch 528/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9285 - mean_absolute_error: 2.3479 - mean_squared_error: 8.9285 - val_loss: 11.2770 - val_mean_absolute_error: 2.7187 - val_mean_squared_error: 11.2770\n",
      "Epoch 529/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9344 - mean_absolute_error: 2.3490 - mean_squared_error: 8.9344 - val_loss: 11.1895 - val_mean_absolute_error: 2.7306 - val_mean_squared_error: 11.1895\n",
      "Epoch 530/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9281 - mean_absolute_error: 2.3500 - mean_squared_error: 8.9281 - val_loss: 11.2380 - val_mean_absolute_error: 2.7213 - val_mean_squared_error: 11.2380\n",
      "Epoch 531/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9272 - mean_absolute_error: 2.3492 - mean_squared_error: 8.9272 - val_loss: 11.2146 - val_mean_absolute_error: 2.7240 - val_mean_squared_error: 11.2146\n",
      "Epoch 532/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9403 - mean_absolute_error: 2.3501 - mean_squared_error: 8.9403 - val_loss: 11.2081 - val_mean_absolute_error: 2.7246 - val_mean_squared_error: 11.2081\n",
      "Epoch 533/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9725 - mean_absolute_error: 2.3547 - mean_squared_error: 8.9725 - val_loss: 11.2303 - val_mean_absolute_error: 2.7210 - val_mean_squared_error: 11.2303\n",
      "Epoch 534/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9289 - mean_absolute_error: 2.3486 - mean_squared_error: 8.9289 - val_loss: 11.2354 - val_mean_absolute_error: 2.7200 - val_mean_squared_error: 11.2354\n",
      "Epoch 535/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9151 - mean_absolute_error: 2.3489 - mean_squared_error: 8.9151 - val_loss: 11.3787 - val_mean_absolute_error: 2.7121 - val_mean_squared_error: 11.3787\n",
      "Epoch 536/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9200 - mean_absolute_error: 2.3465 - mean_squared_error: 8.9200 - val_loss: 11.2759 - val_mean_absolute_error: 2.7160 - val_mean_squared_error: 11.2759\n",
      "Epoch 537/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9150 - mean_absolute_error: 2.3462 - mean_squared_error: 8.9150 - val_loss: 11.2253 - val_mean_absolute_error: 2.7199 - val_mean_squared_error: 11.2253\n",
      "Epoch 538/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9194 - mean_absolute_error: 2.3471 - mean_squared_error: 8.9194 - val_loss: 11.1963 - val_mean_absolute_error: 2.7236 - val_mean_squared_error: 11.1963\n",
      "Epoch 539/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9192 - mean_absolute_error: 2.3475 - mean_squared_error: 8.9192 - val_loss: 11.2197 - val_mean_absolute_error: 2.7197 - val_mean_squared_error: 11.2197\n",
      "Epoch 540/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9253 - mean_absolute_error: 2.3469 - mean_squared_error: 8.9253 - val_loss: 11.1515 - val_mean_absolute_error: 2.7362 - val_mean_squared_error: 11.1515\n",
      "Epoch 541/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9237 - mean_absolute_error: 2.3493 - mean_squared_error: 8.9237 - val_loss: 11.2095 - val_mean_absolute_error: 2.7202 - val_mean_squared_error: 11.2095\n",
      "Epoch 542/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9169 - mean_absolute_error: 2.3492 - mean_squared_error: 8.9169 - val_loss: 11.3717 - val_mean_absolute_error: 2.7104 - val_mean_squared_error: 11.3717\n",
      "Epoch 543/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9101 - mean_absolute_error: 2.3438 - mean_squared_error: 8.9101 - val_loss: 11.2266 - val_mean_absolute_error: 2.7174 - val_mean_squared_error: 11.2266\n",
      "Epoch 544/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9083 - mean_absolute_error: 2.3453 - mean_squared_error: 8.9083 - val_loss: 11.2353 - val_mean_absolute_error: 2.7162 - val_mean_squared_error: 11.2353\n",
      "Epoch 545/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9137 - mean_absolute_error: 2.3464 - mean_squared_error: 8.9137 - val_loss: 11.2404 - val_mean_absolute_error: 2.7155 - val_mean_squared_error: 11.2404\n",
      "Epoch 546/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9180 - mean_absolute_error: 2.3474 - mean_squared_error: 8.9180 - val_loss: 11.3160 - val_mean_absolute_error: 2.7110 - val_mean_squared_error: 11.3160\n",
      "Epoch 547/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9367 - mean_absolute_error: 2.3461 - mean_squared_error: 8.9367 - val_loss: 11.1566 - val_mean_absolute_error: 2.7276 - val_mean_squared_error: 11.1566\n",
      "Epoch 548/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9018 - mean_absolute_error: 2.3466 - mean_squared_error: 8.9018 - val_loss: 11.2981 - val_mean_absolute_error: 2.7111 - val_mean_squared_error: 11.2981\n",
      "Epoch 549/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8977 - mean_absolute_error: 2.3413 - mean_squared_error: 8.8977 - val_loss: 11.1561 - val_mean_absolute_error: 2.7263 - val_mean_squared_error: 11.1561\n",
      "Epoch 550/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9052 - mean_absolute_error: 2.3463 - mean_squared_error: 8.9052 - val_loss: 11.2434 - val_mean_absolute_error: 2.7136 - val_mean_squared_error: 11.2434\n",
      "Epoch 551/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9080 - mean_absolute_error: 2.3456 - mean_squared_error: 8.9080 - val_loss: 11.3198 - val_mean_absolute_error: 2.7095 - val_mean_squared_error: 11.3198\n",
      "Epoch 552/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9007 - mean_absolute_error: 2.3431 - mean_squared_error: 8.9007 - val_loss: 11.2229 - val_mean_absolute_error: 2.7146 - val_mean_squared_error: 11.2229\n",
      "Epoch 553/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8964 - mean_absolute_error: 2.3426 - mean_squared_error: 8.8964 - val_loss: 11.2086 - val_mean_absolute_error: 2.7156 - val_mean_squared_error: 11.2086\n",
      "Epoch 554/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8946 - mean_absolute_error: 2.3438 - mean_squared_error: 8.8946 - val_loss: 11.2814 - val_mean_absolute_error: 2.7102 - val_mean_squared_error: 11.2814\n",
      "Epoch 555/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9036 - mean_absolute_error: 2.3432 - mean_squared_error: 8.9036 - val_loss: 11.2200 - val_mean_absolute_error: 2.7138 - val_mean_squared_error: 11.2200\n",
      "Epoch 556/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9843 - mean_absolute_error: 2.3551 - mean_squared_error: 8.9843 - val_loss: 11.4020 - val_mean_absolute_error: 2.7070 - val_mean_squared_error: 11.4020\n",
      "Epoch 557/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8999 - mean_absolute_error: 2.3415 - mean_squared_error: 8.8999 - val_loss: 11.1798 - val_mean_absolute_error: 2.7175 - val_mean_squared_error: 11.1798\n",
      "Epoch 558/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8910 - mean_absolute_error: 2.3445 - mean_squared_error: 8.8910 - val_loss: 11.3685 - val_mean_absolute_error: 2.7069 - val_mean_squared_error: 11.3685\n",
      "Epoch 559/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9129 - mean_absolute_error: 2.3432 - mean_squared_error: 8.9129 - val_loss: 11.2146 - val_mean_absolute_error: 2.7130 - val_mean_squared_error: 11.2146\n",
      "Epoch 560/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.9144 - mean_absolute_error: 2.3464 - mean_squared_error: 8.9144 - val_loss: 11.2445 - val_mean_absolute_error: 2.7105 - val_mean_squared_error: 11.2445\n",
      "Epoch 561/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8914 - mean_absolute_error: 2.3414 - mean_squared_error: 8.8914 - val_loss: 11.1819 - val_mean_absolute_error: 2.7157 - val_mean_squared_error: 11.1819\n",
      "Epoch 562/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8859 - mean_absolute_error: 2.3417 - mean_squared_error: 8.8859 - val_loss: 11.2177 - val_mean_absolute_error: 2.7118 - val_mean_squared_error: 11.2177\n",
      "Epoch 563/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8879 - mean_absolute_error: 2.3408 - mean_squared_error: 8.8879 - val_loss: 11.1449 - val_mean_absolute_error: 2.7210 - val_mean_squared_error: 11.1449\n",
      "Epoch 564/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8874 - mean_absolute_error: 2.3436 - mean_squared_error: 8.8874 - val_loss: 11.3016 - val_mean_absolute_error: 2.7069 - val_mean_squared_error: 11.3016\n",
      "Epoch 565/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8990 - mean_absolute_error: 2.3431 - mean_squared_error: 8.8990 - val_loss: 11.2074 - val_mean_absolute_error: 2.7117 - val_mean_squared_error: 11.2074\n",
      "Epoch 566/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8868 - mean_absolute_error: 2.3417 - mean_squared_error: 8.8868 - val_loss: 11.2354 - val_mean_absolute_error: 2.7093 - val_mean_squared_error: 11.2354\n",
      "Epoch 567/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8828 - mean_absolute_error: 2.3423 - mean_squared_error: 8.8828 - val_loss: 11.3882 - val_mean_absolute_error: 2.7049 - val_mean_squared_error: 11.3882\n",
      "Epoch 568/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8839 - mean_absolute_error: 2.3394 - mean_squared_error: 8.8839 - val_loss: 11.1893 - val_mean_absolute_error: 2.7124 - val_mean_squared_error: 11.1893\n",
      "Epoch 569/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8803 - mean_absolute_error: 2.3398 - mean_squared_error: 8.8803 - val_loss: 11.1523 - val_mean_absolute_error: 2.7168 - val_mean_squared_error: 11.1523\n",
      "Epoch 570/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8936 - mean_absolute_error: 2.3404 - mean_squared_error: 8.8936 - val_loss: 11.1325 - val_mean_absolute_error: 2.7202 - val_mean_squared_error: 11.1325\n",
      "Epoch 571/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8902 - mean_absolute_error: 2.3432 - mean_squared_error: 8.8902 - val_loss: 11.2343 - val_mean_absolute_error: 2.7080 - val_mean_squared_error: 11.2343\n",
      "Epoch 572/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8791 - mean_absolute_error: 2.3402 - mean_squared_error: 8.8791 - val_loss: 11.2299 - val_mean_absolute_error: 2.7080 - val_mean_squared_error: 11.2299\n",
      "Epoch 573/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8852 - mean_absolute_error: 2.3409 - mean_squared_error: 8.8852 - val_loss: 11.2368 - val_mean_absolute_error: 2.7073 - val_mean_squared_error: 11.2368\n",
      "Epoch 574/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8870 - mean_absolute_error: 2.3421 - mean_squared_error: 8.8870 - val_loss: 11.3475 - val_mean_absolute_error: 2.7039 - val_mean_squared_error: 11.3475\n",
      "Epoch 575/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8901 - mean_absolute_error: 2.3388 - mean_squared_error: 8.8901 - val_loss: 11.1226 - val_mean_absolute_error: 2.7200 - val_mean_squared_error: 11.1226\n",
      "Epoch 576/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8965 - mean_absolute_error: 2.3449 - mean_squared_error: 8.8965 - val_loss: 11.2985 - val_mean_absolute_error: 2.7043 - val_mean_squared_error: 11.2985\n",
      "Epoch 577/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8697 - mean_absolute_error: 2.3364 - mean_squared_error: 8.8697 - val_loss: 11.1442 - val_mean_absolute_error: 2.7149 - val_mean_squared_error: 11.1442\n",
      "Epoch 578/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8761 - mean_absolute_error: 2.3402 - mean_squared_error: 8.8761 - val_loss: 11.1741 - val_mean_absolute_error: 2.7108 - val_mean_squared_error: 11.1741\n",
      "Epoch 579/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8761 - mean_absolute_error: 2.3387 - mean_squared_error: 8.8761 - val_loss: 11.1633 - val_mean_absolute_error: 2.7116 - val_mean_squared_error: 11.1633\n",
      "Epoch 580/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8709 - mean_absolute_error: 2.3398 - mean_squared_error: 8.8709 - val_loss: 11.2615 - val_mean_absolute_error: 2.7045 - val_mean_squared_error: 11.2615\n",
      "Epoch 581/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8726 - mean_absolute_error: 2.3383 - mean_squared_error: 8.8726 - val_loss: 11.2582 - val_mean_absolute_error: 2.7044 - val_mean_squared_error: 11.2582\n",
      "Epoch 582/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8896 - mean_absolute_error: 2.3402 - mean_squared_error: 8.8896 - val_loss: 11.1330 - val_mean_absolute_error: 2.7147 - val_mean_squared_error: 11.1330\n",
      "Epoch 583/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8669 - mean_absolute_error: 2.3382 - mean_squared_error: 8.8669 - val_loss: 11.1268 - val_mean_absolute_error: 2.7154 - val_mean_squared_error: 11.1268\n",
      "Epoch 584/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8838 - mean_absolute_error: 2.3426 - mean_squared_error: 8.8838 - val_loss: 11.2734 - val_mean_absolute_error: 2.7033 - val_mean_squared_error: 11.2734\n",
      "Epoch 585/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8694 - mean_absolute_error: 2.3369 - mean_squared_error: 8.8694 - val_loss: 11.1848 - val_mean_absolute_error: 2.7077 - val_mean_squared_error: 11.1848\n",
      "Epoch 586/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8786 - mean_absolute_error: 2.3375 - mean_squared_error: 8.8786 - val_loss: 11.1009 - val_mean_absolute_error: 2.7200 - val_mean_squared_error: 11.1009\n",
      "Epoch 587/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8998 - mean_absolute_error: 2.3419 - mean_squared_error: 8.8998 - val_loss: 11.1029 - val_mean_absolute_error: 2.7189 - val_mean_squared_error: 11.1029\n",
      "Epoch 588/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8791 - mean_absolute_error: 2.3426 - mean_squared_error: 8.8791 - val_loss: 11.3757 - val_mean_absolute_error: 2.7013 - val_mean_squared_error: 11.3757\n",
      "Epoch 589/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8805 - mean_absolute_error: 2.3353 - mean_squared_error: 8.8805 - val_loss: 11.0783 - val_mean_absolute_error: 2.7281 - val_mean_squared_error: 11.0783\n",
      "Epoch 590/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8834 - mean_absolute_error: 2.3417 - mean_squared_error: 8.8834 - val_loss: 11.1232 - val_mean_absolute_error: 2.7133 - val_mean_squared_error: 11.1232\n",
      "Epoch 591/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8662 - mean_absolute_error: 2.3377 - mean_squared_error: 8.8662 - val_loss: 11.1959 - val_mean_absolute_error: 2.7052 - val_mean_squared_error: 11.1959\n",
      "Epoch 592/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8569 - mean_absolute_error: 2.3355 - mean_squared_error: 8.8569 - val_loss: 11.1792 - val_mean_absolute_error: 2.7062 - val_mean_squared_error: 11.1792\n",
      "Epoch 593/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8602 - mean_absolute_error: 2.3371 - mean_squared_error: 8.8602 - val_loss: 11.2253 - val_mean_absolute_error: 2.7031 - val_mean_squared_error: 11.2253\n",
      "Epoch 594/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8602 - mean_absolute_error: 2.3360 - mean_squared_error: 8.8602 - val_loss: 11.1572 - val_mean_absolute_error: 2.7077 - val_mean_squared_error: 11.1572\n",
      "Epoch 595/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8796 - mean_absolute_error: 2.3377 - mean_squared_error: 8.8796 - val_loss: 11.1119 - val_mean_absolute_error: 2.7133 - val_mean_squared_error: 11.1119\n",
      "Epoch 596/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8563 - mean_absolute_error: 2.3365 - mean_squared_error: 8.8563 - val_loss: 11.1417 - val_mean_absolute_error: 2.7087 - val_mean_squared_error: 11.1417\n",
      "Epoch 597/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8504 - mean_absolute_error: 2.3355 - mean_squared_error: 8.8504 - val_loss: 11.1962 - val_mean_absolute_error: 2.7037 - val_mean_squared_error: 11.1962\n",
      "Epoch 598/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8527 - mean_absolute_error: 2.3353 - mean_squared_error: 8.8527 - val_loss: 11.2077 - val_mean_absolute_error: 2.7029 - val_mean_squared_error: 11.2077\n",
      "Epoch 599/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8479 - mean_absolute_error: 2.3342 - mean_squared_error: 8.8479 - val_loss: 11.1562 - val_mean_absolute_error: 2.7064 - val_mean_squared_error: 11.1562\n",
      "Epoch 600/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8478 - mean_absolute_error: 2.3350 - mean_squared_error: 8.8478 - val_loss: 11.1842 - val_mean_absolute_error: 2.7038 - val_mean_squared_error: 11.1842\n",
      "Epoch 601/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8511 - mean_absolute_error: 2.3353 - mean_squared_error: 8.8511 - val_loss: 11.2510 - val_mean_absolute_error: 2.7005 - val_mean_squared_error: 11.2510\n",
      "Epoch 602/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8632 - mean_absolute_error: 2.3372 - mean_squared_error: 8.8632 - val_loss: 11.3815 - val_mean_absolute_error: 2.6992 - val_mean_squared_error: 11.3815\n",
      "Epoch 603/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8523 - mean_absolute_error: 2.3322 - mean_squared_error: 8.8523 - val_loss: 11.1469 - val_mean_absolute_error: 2.7061 - val_mean_squared_error: 11.1469\n",
      "Epoch 604/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8518 - mean_absolute_error: 2.3348 - mean_squared_error: 8.8518 - val_loss: 11.1445 - val_mean_absolute_error: 2.7061 - val_mean_squared_error: 11.1445\n",
      "Epoch 605/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8480 - mean_absolute_error: 2.3334 - mean_squared_error: 8.8480 - val_loss: 11.0904 - val_mean_absolute_error: 2.7136 - val_mean_squared_error: 11.0904\n",
      "Epoch 606/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8661 - mean_absolute_error: 2.3377 - mean_squared_error: 8.8661 - val_loss: 11.1396 - val_mean_absolute_error: 2.7060 - val_mean_squared_error: 11.1396\n",
      "Epoch 607/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8870 - mean_absolute_error: 2.3413 - mean_squared_error: 8.8870 - val_loss: 11.2834 - val_mean_absolute_error: 2.6989 - val_mean_squared_error: 11.2834\n",
      "Epoch 608/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8541 - mean_absolute_error: 2.3330 - mean_squared_error: 8.8541 - val_loss: 11.1266 - val_mean_absolute_error: 2.7069 - val_mean_squared_error: 11.1266\n",
      "Epoch 609/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8427 - mean_absolute_error: 2.3341 - mean_squared_error: 8.8427 - val_loss: 11.1985 - val_mean_absolute_error: 2.7010 - val_mean_squared_error: 11.1985\n",
      "Epoch 610/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8443 - mean_absolute_error: 2.3335 - mean_squared_error: 8.8443 - val_loss: 11.2006 - val_mean_absolute_error: 2.7007 - val_mean_squared_error: 11.2006\n",
      "Epoch 611/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8402 - mean_absolute_error: 2.3341 - mean_squared_error: 8.8402 - val_loss: 11.2892 - val_mean_absolute_error: 2.6981 - val_mean_squared_error: 11.2892\n",
      "Epoch 612/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8535 - mean_absolute_error: 2.3331 - mean_squared_error: 8.8535 - val_loss: 11.1895 - val_mean_absolute_error: 2.7008 - val_mean_squared_error: 11.1895\n",
      "Epoch 613/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8504 - mean_absolute_error: 2.3350 - mean_squared_error: 8.8504 - val_loss: 11.2283 - val_mean_absolute_error: 2.6991 - val_mean_squared_error: 11.2283\n",
      "Epoch 614/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8406 - mean_absolute_error: 2.3320 - mean_squared_error: 8.8406 - val_loss: 11.1248 - val_mean_absolute_error: 2.7054 - val_mean_squared_error: 11.1248\n",
      "Epoch 615/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8461 - mean_absolute_error: 2.3332 - mean_squared_error: 8.8461 - val_loss: 11.0919 - val_mean_absolute_error: 2.7095 - val_mean_squared_error: 11.0919\n",
      "Epoch 616/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8356 - mean_absolute_error: 2.3343 - mean_squared_error: 8.8356 - val_loss: 11.2486 - val_mean_absolute_error: 2.6980 - val_mean_squared_error: 11.2486\n",
      "Epoch 617/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8331 - mean_absolute_error: 2.3309 - mean_squared_error: 8.8331 - val_loss: 11.1447 - val_mean_absolute_error: 2.7028 - val_mean_squared_error: 11.1447\n",
      "Epoch 618/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8510 - mean_absolute_error: 2.3321 - mean_squared_error: 8.8510 - val_loss: 11.0413 - val_mean_absolute_error: 2.7255 - val_mean_squared_error: 11.0413\n",
      "Epoch 619/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8597 - mean_absolute_error: 2.3372 - mean_squared_error: 8.8597 - val_loss: 11.0995 - val_mean_absolute_error: 2.7070 - val_mean_squared_error: 11.0995\n",
      "Epoch 620/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8386 - mean_absolute_error: 2.3345 - mean_squared_error: 8.8386 - val_loss: 11.2606 - val_mean_absolute_error: 2.6971 - val_mean_squared_error: 11.2606\n",
      "Epoch 621/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8785 - mean_absolute_error: 2.3335 - mean_squared_error: 8.8785 - val_loss: 11.0375 - val_mean_absolute_error: 2.7256 - val_mean_squared_error: 11.0375\n",
      "Epoch 622/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8573 - mean_absolute_error: 2.3363 - mean_squared_error: 8.8573 - val_loss: 11.1047 - val_mean_absolute_error: 2.7055 - val_mean_squared_error: 11.1047\n",
      "Epoch 623/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8426 - mean_absolute_error: 2.3316 - mean_squared_error: 8.8426 - val_loss: 11.0497 - val_mean_absolute_error: 2.7164 - val_mean_squared_error: 11.0497\n",
      "Epoch 624/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8320 - mean_absolute_error: 2.3335 - mean_squared_error: 8.8320 - val_loss: 11.2457 - val_mean_absolute_error: 2.6968 - val_mean_squared_error: 11.2457\n",
      "Epoch 625/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8331 - mean_absolute_error: 2.3307 - mean_squared_error: 8.8331 - val_loss: 11.1423 - val_mean_absolute_error: 2.7011 - val_mean_squared_error: 11.1423\n",
      "Epoch 626/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8318 - mean_absolute_error: 2.3301 - mean_squared_error: 8.8318 - val_loss: 11.0912 - val_mean_absolute_error: 2.7061 - val_mean_squared_error: 11.0912\n",
      "Epoch 627/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8310 - mean_absolute_error: 2.3324 - mean_squared_error: 8.8310 - val_loss: 11.1616 - val_mean_absolute_error: 2.6994 - val_mean_squared_error: 11.1616\n",
      "Epoch 628/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8302 - mean_absolute_error: 2.3303 - mean_squared_error: 8.8302 - val_loss: 11.1029 - val_mean_absolute_error: 2.7041 - val_mean_squared_error: 11.1029\n",
      "Epoch 629/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8315 - mean_absolute_error: 2.3325 - mean_squared_error: 8.8315 - val_loss: 11.1374 - val_mean_absolute_error: 2.7006 - val_mean_squared_error: 11.1374\n",
      "Epoch 630/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8247 - mean_absolute_error: 2.3293 - mean_squared_error: 8.8247 - val_loss: 11.0865 - val_mean_absolute_error: 2.7056 - val_mean_squared_error: 11.0865\n",
      "Epoch 631/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8269 - mean_absolute_error: 2.3312 - mean_squared_error: 8.8269 - val_loss: 11.1180 - val_mean_absolute_error: 2.7018 - val_mean_squared_error: 11.1180\n",
      "Epoch 632/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8460 - mean_absolute_error: 2.3323 - mean_squared_error: 8.8460 - val_loss: 11.1177 - val_mean_absolute_error: 2.7016 - val_mean_squared_error: 11.1177\n",
      "Epoch 633/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8564 - mean_absolute_error: 2.3341 - mean_squared_error: 8.8564 - val_loss: 11.0519 - val_mean_absolute_error: 2.7112 - val_mean_squared_error: 11.0519\n",
      "Epoch 634/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8418 - mean_absolute_error: 2.3372 - mean_squared_error: 8.8418 - val_loss: 11.4209 - val_mean_absolute_error: 2.6959 - val_mean_squared_error: 11.4209\n",
      "Epoch 635/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8346 - mean_absolute_error: 2.3285 - mean_squared_error: 8.8346 - val_loss: 11.0818 - val_mean_absolute_error: 2.7048 - val_mean_squared_error: 11.0818\n",
      "Epoch 636/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8208 - mean_absolute_error: 2.3301 - mean_squared_error: 8.8208 - val_loss: 11.1322 - val_mean_absolute_error: 2.6995 - val_mean_squared_error: 11.1322\n",
      "Epoch 637/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8368 - mean_absolute_error: 2.3316 - mean_squared_error: 8.8368 - val_loss: 11.1689 - val_mean_absolute_error: 2.6971 - val_mean_squared_error: 11.1689\n",
      "Epoch 638/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8256 - mean_absolute_error: 2.3318 - mean_squared_error: 8.8256 - val_loss: 11.2947 - val_mean_absolute_error: 2.6942 - val_mean_squared_error: 11.2947\n",
      "Epoch 639/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8297 - mean_absolute_error: 2.3290 - mean_squared_error: 8.8297 - val_loss: 11.1122 - val_mean_absolute_error: 2.7005 - val_mean_squared_error: 11.1122\n",
      "Epoch 640/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8218 - mean_absolute_error: 2.3291 - mean_squared_error: 8.8218 - val_loss: 11.0910 - val_mean_absolute_error: 2.7024 - val_mean_squared_error: 11.0910\n",
      "Epoch 641/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8356 - mean_absolute_error: 2.3332 - mean_squared_error: 8.8356 - val_loss: 11.2204 - val_mean_absolute_error: 2.6948 - val_mean_squared_error: 11.2204\n",
      "Epoch 642/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8169 - mean_absolute_error: 2.3275 - mean_squared_error: 8.8169 - val_loss: 11.1096 - val_mean_absolute_error: 2.7001 - val_mean_squared_error: 11.1096\n",
      "Epoch 643/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8327 - mean_absolute_error: 2.3307 - mean_squared_error: 8.8327 - val_loss: 11.1218 - val_mean_absolute_error: 2.6989 - val_mean_squared_error: 11.1218\n",
      "Epoch 644/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8409 - mean_absolute_error: 2.3350 - mean_squared_error: 8.8409 - val_loss: 11.3509 - val_mean_absolute_error: 2.6937 - val_mean_squared_error: 11.3509\n",
      "Epoch 645/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8290 - mean_absolute_error: 2.3289 - mean_squared_error: 8.8290 - val_loss: 11.2256 - val_mean_absolute_error: 2.6941 - val_mean_squared_error: 11.2256\n",
      "Epoch 646/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8176 - mean_absolute_error: 2.3271 - mean_squared_error: 8.8176 - val_loss: 11.0453 - val_mean_absolute_error: 2.7079 - val_mean_squared_error: 11.0453\n",
      "Epoch 647/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8103 - mean_absolute_error: 2.3285 - mean_squared_error: 8.8103 - val_loss: 11.0807 - val_mean_absolute_error: 2.7019 - val_mean_squared_error: 11.0807\n",
      "Epoch 648/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8189 - mean_absolute_error: 2.3289 - mean_squared_error: 8.8189 - val_loss: 11.0707 - val_mean_absolute_error: 2.7028 - val_mean_squared_error: 11.0707\n",
      "Epoch 649/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8147 - mean_absolute_error: 2.3298 - mean_squared_error: 8.8147 - val_loss: 11.1623 - val_mean_absolute_error: 2.6954 - val_mean_squared_error: 11.1623\n",
      "Epoch 650/10000\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 8.8182 - mean_absolute_error: 2.3278 - mean_squared_error: 8.8182 - val_loss: 11.0556 - val_mean_absolute_error: 2.7046 - val_mean_squared_error: 11.0556\n",
      "Epoch 651/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8119 - mean_absolute_error: 2.3287 - mean_squared_error: 8.8119 - val_loss: 11.1262 - val_mean_absolute_error: 2.6970 - val_mean_squared_error: 11.1262\n",
      "Epoch 652/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8115 - mean_absolute_error: 2.3270 - mean_squared_error: 8.8115 - val_loss: 11.0809 - val_mean_absolute_error: 2.7006 - val_mean_squared_error: 11.0809\n",
      "Epoch 653/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8121 - mean_absolute_error: 2.3274 - mean_squared_error: 8.8121 - val_loss: 11.0519 - val_mean_absolute_error: 2.7043 - val_mean_squared_error: 11.0519\n",
      "Epoch 654/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8136 - mean_absolute_error: 2.3292 - mean_squared_error: 8.8136 - val_loss: 11.1240 - val_mean_absolute_error: 2.6966 - val_mean_squared_error: 11.1240\n",
      "Epoch 655/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8155 - mean_absolute_error: 2.3265 - mean_squared_error: 8.8155 - val_loss: 11.0777 - val_mean_absolute_error: 2.7003 - val_mean_squared_error: 11.0777\n",
      "Epoch 656/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8163 - mean_absolute_error: 2.3282 - mean_squared_error: 8.8163 - val_loss: 11.0630 - val_mean_absolute_error: 2.7018 - val_mean_squared_error: 11.0630\n",
      "Epoch 657/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8176 - mean_absolute_error: 2.3288 - mean_squared_error: 8.8176 - val_loss: 11.0993 - val_mean_absolute_error: 2.6978 - val_mean_squared_error: 11.0993\n",
      "Epoch 658/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8037 - mean_absolute_error: 2.3271 - mean_squared_error: 8.8037 - val_loss: 11.1789 - val_mean_absolute_error: 2.6935 - val_mean_squared_error: 11.1789\n",
      "Epoch 659/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.7988 - mean_absolute_error: 2.3254 - mean_squared_error: 8.7988 - val_loss: 11.1406 - val_mean_absolute_error: 2.6948 - val_mean_squared_error: 11.1406\n",
      "Epoch 660/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8110 - mean_absolute_error: 2.3262 - mean_squared_error: 8.8110 - val_loss: 11.0427 - val_mean_absolute_error: 2.7039 - val_mean_squared_error: 11.0427\n",
      "Epoch 661/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8218 - mean_absolute_error: 2.3284 - mean_squared_error: 8.8218 - val_loss: 11.0410 - val_mean_absolute_error: 2.7039 - val_mean_squared_error: 11.0410\n",
      "Epoch 662/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8049 - mean_absolute_error: 2.3272 - mean_squared_error: 8.8049 - val_loss: 11.0929 - val_mean_absolute_error: 2.6974 - val_mean_squared_error: 11.0929\n",
      "Epoch 663/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8432 - mean_absolute_error: 2.3324 - mean_squared_error: 8.8432 - val_loss: 11.1493 - val_mean_absolute_error: 2.6938 - val_mean_squared_error: 11.1493\n",
      "Epoch 664/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8100 - mean_absolute_error: 2.3266 - mean_squared_error: 8.8100 - val_loss: 11.0762 - val_mean_absolute_error: 2.6985 - val_mean_squared_error: 11.0762\n",
      "Epoch 665/10000\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 8.8012 - mean_absolute_error: 2.3280 - mean_squared_error: 8.8012 - val_loss: 11.2706 - val_mean_absolute_error: 2.6911 - val_mean_squared_error: 11.2706\n",
      "Epoch 666/10000\n",
      " 7500/20000 [==========>...................] - ETA: 0s - loss: 8.8909 - mean_absolute_error: 2.3387 - mean_squared_error: 8.8909"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-316-62cd18711fed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mae'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2653\u001b[0m                 array_vals.append(\n\u001b[0;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[1;32m-> 2655\u001b[1;33m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[0;32m   2656\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \"\"\"\n\u001b[1;32m--> 501\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Dense, Conv1D, Conv2D, Flatten, Dropout, Input, Bidirectional\n",
    "\n",
    "inputs = Input(shape=x_train.shape[1:])\n",
    "X = Dense(2)(inputs)\n",
    "# X = Dropout(0.25)(X)\n",
    "predictions = Dense(1)(X)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "print(model.summary())\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.00001, decay=1e-6), metrics=['mae','mean_squared_error'])\n",
    "model.fit(x_train, y_train, epochs=10000, batch_size=2500, verbose=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 800, 5)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 16)                896       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 913\n",
      "Trainable params: 913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 20000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "20000/20000 [==============================] - 284s 14ms/step - loss: 14.6835 - mean_absolute_error: 3.1077 - mean_squared_error: 14.6835 - val_loss: 15.8525 - val_mean_absolute_error: 3.3142 - val_mean_squared_error: 15.8525\n",
      "Epoch 2/100\n",
      "20000/20000 [==============================] - 280s 14ms/step - loss: 13.0936 - mean_absolute_error: 2.9933 - mean_squared_error: 13.0936 - val_loss: 15.8560 - val_mean_absolute_error: 3.3139 - val_mean_squared_error: 15.8560\n",
      "Epoch 3/100\n",
      " 9250/20000 [============>.................] - ETA: 2:27 - loss: 12.9994 - mean_absolute_error: 2.9791 - mean_squared_error: 12.9994"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-189-94c23fa992b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mae'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Conv1D, Conv2D, Flatten, Dropout, Input, Bidirectional\n",
    "\n",
    "inputs = Input(shape=x_train.shape[1:])\n",
    "X = Bidirectional(LSTM(units=8, return_sequences=False))(inputs)\n",
    "# X = Flatten(X)\n",
    "predictions = Dense(1)(X)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "print(model.summary())\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(), metrics=['mae','mean_squared_error'])\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=250, verbose=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv1d_41: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-322-ae839fc88129>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mae'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer conv1d_41: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Conv1D, Conv2D, Flatten, Dropout\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "\n",
    "#add model layers\n",
    "model.add(Conv2D(16, kernel_size=(1,5), activation='relu', input_shape=(200,5,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Conv1D(4, kernel_size=3, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(), metrics=['mae','mean_squared_error'])\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=64, verbose=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "20000/20000 [==============================] - 13s 632us/step - loss: 44.6518 - mean_absolute_error: 5.6182 - mean_squared_error: 44.6518 - val_loss: 51.4370 - val_mean_absolute_error: 5.9779 - val_mean_squared_error: 51.4370\n",
      "Epoch 2/100\n",
      "20000/20000 [==============================] - 8s 404us/step - loss: 44.6518 - mean_absolute_error: 5.6182 - mean_squared_error: 44.6518 - val_loss: 51.4370 - val_mean_absolute_error: 5.9779 - val_mean_squared_error: 51.4370\n",
      "Epoch 3/100\n",
      "20000/20000 [==============================] - 8s 401us/step - loss: 44.6518 - mean_absolute_error: 5.6182 - mean_squared_error: 44.6518 - val_loss: 51.4370 - val_mean_absolute_error: 5.9779 - val_mean_squared_error: 51.4370\n",
      "Epoch 4/100\n",
      "18500/20000 [==========================>...] - ETA: 0s - loss: 44.6194 - mean_absolute_error: 5.6105 - mean_squared_error: 44.6194"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-326-7595d2d81100>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mae'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jsab\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, Activation, CuDNNLSTM\n",
    "from keras.optimizers import SGD\n",
    "# create and fit the LSTM network\n",
    "mod = Sequential()\n",
    "mod.add(Bidirectional(CuDNNLSTM(units=24, return_sequences=True, input_shape=x_train.shape[1:])))\n",
    "mod.add(CuDNNLSTM(units=2, return_sequences=False))\n",
    "mod.add(Dense(1, activation='relu'))\n",
    "mod.compile(loss='mean_squared_error', optimizer=SGD(), metrics=['mae','mean_squared_error'])\n",
    "mod.fit(x_train, y_train, epochs=100, batch_size=500, verbose=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.097053 ],\n",
       "       [2.7425199],\n",
       "       [2.9276323],\n",
       "       ...,\n",
       "       [3.5980787],\n",
       "       [4.600548 ],\n",
       "       [8.837812 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.9028196],\n",
       "       [3.3967416],\n",
       "       [3.6990693],\n",
       "       ...,\n",
       "       [5.9858127],\n",
       "       [2.9790916],\n",
       "       [7.1291265]], dtype=float32)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  0., -2., ...,  6.,  9.,  8.],\n",
       "       [ 5.,  8.,  8., ...,  2.,  1.,  3.],\n",
       "       [ 8.,  2.,  3., ..., -1.,  2.,  5.],\n",
       "       ...,\n",
       "       [ 3.,  0.,  0., ...,  3.,  2.,  5.],\n",
       "       [ 3., -3.,  3., ...,  1.,  1.,  3.],\n",
       "       [ 6.,  5.,  5., ...,  2.,  1.,  3.]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624, 150000)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000,)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mat[1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "x_test = np.zeros([len(files), n_obs, 4])\n",
    "for i in range(len(files)):\n",
    "    if i%500==0:\n",
    "        print(i)\n",
    "    for j in range(n_obs):\n",
    "        x_test[i,j,0] = np.max(test_mat[i, j*step_size:(j+1)*step_size])\n",
    "        x_test[i,j,1] = np.min(test_mat[i, j*step_size:(j+1)*step_size])\n",
    "        x_test[i,j,2] = np.mean(test_mat[i, j*step_size:(j+1)*step_size])\n",
    "        x_test[i,j,3] = np.std(test_mat[i, j*step_size:(j+1)*step_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.zeros([len(files), int(size/step_size),5])\n",
    "x_test[:, :, 0] = np.max(test_mat.reshape([2624,int(size/step_size),step_size]),axis=2)\n",
    "x_test[:, :, 1] = np.min(test_mat.reshape([2624,int(size/step_size),step_size]),axis=2)\n",
    "x_test[:, :, 2] = np.mean(test_mat.reshape([2624,int(size/step_size),step_size]),axis=2)\n",
    "x_test[:, :, 3] = np.std(test_mat.reshape([2624,int(size/step_size),step_size]),axis=2)\n",
    "x_test[:, :, 4] = scipy.stats.kurtosis(test_mat.reshape([2624,int(size/step_size),step_size]),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624, 100, 4)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.3751645, 6.6565156, 6.468862 , ..., 3.238063 , 2.5696244,\n",
       "       9.150722 ], dtype=float32)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'seg_id': seq, 'time_to_failure': preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../output/submission_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
